{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13a6924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Environment Variables Loaded:\n",
      "AWS_ACCESS_KEY_ID: ***dmin\n",
      "AWS_SECRET_ACCESS_KEY: ***dmin\n",
      "AWS_DEFAULT_REGION: NOT SET\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\" Environment Variables Loaded:\")\n",
    "print(f\"AWS_ACCESS_KEY_ID: {'***' + os.getenv('MINIO_ACCESS_KEY', 'NOT SET')[-4:] if os.getenv('MINIO_ACCESS_KEY') else 'NOT SET'}\")\n",
    "print(f\"AWS_SECRET_ACCESS_KEY: {'***' + os.getenv('MINIO_SECRET_ACCESS_KEY', 'NOT SET')[-4:] if os.getenv('MINIO_SECRET_ACCESS_KEY') else 'NOT SET'}\")\n",
    "print(f\"AWS_DEFAULT_REGION: {os.getenv('AWS_DEFAULT_REGION', 'NOT SET')}\")\n",
    "\n",
    "file_path = 'C:/Users/ldmag/Documents/GitHub/Code-Assignments-Projects/Projects/MLOps Drift Detection and Pipeline Optimization/data/Telco-Churn.csv'\n",
    "BASE = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cfd72",
   "metadata": {},
   "source": [
    "## Train a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abeaa0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are for training a relatively robust random forest model; no adversarial injection\n",
    "\n",
    "def load_and_preprocess_data(df_filepath):\n",
    "    df = pd.read_csv(df_filepath)\n",
    "\n",
    "    dataset: PandasDataset = mlflow.data.from_pandas(df)\n",
    "\n",
    "    print('Loaded Telco data to dataframe')\n",
    "\n",
    "    numeric = []\n",
    "    categorical = []\n",
    "    numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "    categorical_features = [\n",
    "            'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "            'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "            'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
    "            'PaperlessBilling', 'PaymentMethod', 'SeniorCitizen'\n",
    "        ]\n",
    "\n",
    "    df.drop(columns=['customerID'])\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df[numeric_features] = imputer.fit_transform(df[numeric_features])\n",
    "\n",
    "    if 'MonthlyCharges' in df.columns and 'TotalCharges' in df.columns:\n",
    "        df['monthly_total_ratio'] = df['MonthlyCharges'] / (df['TotalCharges'] + 1)\n",
    "        numeric.append('monthly_total_ratio')\n",
    "        print(\"Added monthly_total_ratio\")\n",
    "    \n",
    "    if 'TotalCharges' in df.columns and 'tenure' in df.columns:\n",
    "        df['charge_per_month'] = df['TotalCharges'] / (df['tenure'] + 1)\n",
    "        numeric.append('charge_per_month')\n",
    "        print(\"Added charge_per_month\")\n",
    "    \n",
    "    # Service engagement score (aggregated feature)\n",
    "    service_cols = ['PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup', \n",
    "                   'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "    available_services = [col for col in service_cols if col in df.columns]\n",
    "    \n",
    "    if available_services:\n",
    "        service_count = sum((df[col] == 'Yes').astype(int) for col in available_services)\n",
    "        df['service_engagement'] = service_count\n",
    "        numeric.append('service_engagement')\n",
    "        print(f\"Added service_engagement from {len(available_services)} services\")\n",
    "    \n",
    "    # Binned features (less sensitive to outliers)\n",
    "    if 'tenure' in df.columns:\n",
    "        df['tenure_tier'] = pd.qcut(df['tenure'], \n",
    "                                         q=4, labels=['New', 'Short', 'Medium', 'Long'], \n",
    "                                         duplicates='drop').astype(str)\n",
    "        categorical.append('tenure_tier')\n",
    "        print(\"Added tenure_tier\")\n",
    "    \n",
    "    if 'MonthlyCharges' in df.columns:\n",
    "        df['value_tier'] = pd.qcut(df['MonthlyCharges'], \n",
    "                                        q=3, labels=['Budget', 'Standard', 'Premium'], \n",
    "                                        duplicates='drop').astype(str)\n",
    "        categorical.append('value_tier')\n",
    "        print(\"Added value_tier\")\n",
    "    \n",
    "    # Composite stability score\n",
    "    stability_score = np.zeros(len(df))\n",
    "    if 'Contract' in df.columns:\n",
    "        stability_score += (df['Contract'] == 'Two year').astype(int) * 2\n",
    "        stability_score += (df['Contract'] == 'One year').astype(int) * 1\n",
    "    \n",
    "    if 'PaymentMethod' in df.columns:\n",
    "        auto_pay = df['PaymentMethod'].str.contains('automatic', case=False, na=False)\n",
    "        stability_score += auto_pay.astype(int)\n",
    "    \n",
    "    df['stability_score'] = stability_score\n",
    "    numeric.append('stability_score')\n",
    "    print(\"Added stability_score\")\n",
    "    \n",
    "    print(f\"Added {len(numeric)} numeric and {len(categorical)} categorical features\")\n",
    "\n",
    "    target = 'Churn'\n",
    "    y = df[target].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    numeric_features = [f for f in numeric_features if f in X.columns]\n",
    "    categorical_features = [f for f in categorical_features if f in X.columns]\n",
    "\n",
    "    categorical_columns = categorical + categorical_features\n",
    "    numeric_columns = numeric + numeric_features\n",
    "\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "    numerical_transformer = RobustScaler()\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numeric_columns),\n",
    "            ('cat', categorical_transformer, categorical_columns)\n",
    "        ]\n",
    "    )\n",
    "    return X, y, preprocessor\n",
    "\n",
    "def train_randomforest_baseline(X, y, preprocessor, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    dataset: PandasDataset = mlflow.data.from_pandas(X_train)\n",
    "\n",
    "    classifier = RandomForestClassifier(\n",
    "        n_estimators=150,\n",
    "        max_depth=12,\n",
    "        min_samples_split=5, \n",
    "        min_samples_leaf=3,  \n",
    "        random_state=42, \n",
    "        class_weight='balanced')\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"telco-baseline\")\n",
    "\n",
    "    with mlflow.start_run(run_name='trainRandomForest'):\n",
    "        mlflow.log_param('n_estimators', 150)\n",
    "        mlflow.log_param('max_depth', 12)\n",
    "        mlflow.log_param('class_weight', 'balanced')\n",
    "        mlflow.log_param('is_drift', False)\n",
    "        mlflow.log_param('train_size', len(X_train))\n",
    "        mlflow.log_param('test_size', len(X_test))\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        from mlflow.models.signature import infer_signature\n",
    "        signature = infer_signature(X_train, y_train)\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            pipeline, \n",
    "            'RandomForest',\n",
    "            signature=signature, \n",
    "            registered_model_name='telco-baseline'\n",
    "        )\n",
    "\n",
    "        mlflow.log_input(dataset, context='training')\n",
    "\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_prob = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        test_auc = roc_auc_score(y_test, y_prob)\n",
    "        test_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        mlflow.log_metric('test_accuracy', test_accuracy)\n",
    "        mlflow.log_metric('test_auc', test_auc)\n",
    "        mlflow.log_metric('test_f1', test_f1)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764b3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Telco data to dataframe\n",
      "Added monthly_total_ratio\n",
      "Added charge_per_month\n",
      "Added service_engagement from 8 services\n",
      "Added tenure_tier\n",
      "Added value_tier\n",
      "Added stability_score\n",
      "Added 4 numeric and 2 categorical features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:25:49 INFO mlflow.tracking.fluent: Experiment with name 'telco-baseline' does not exist. Creating a new experiment.\n",
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/11/02 18:25:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Successfully registered model 'telco-baseline'.\n",
      "2025/11/02 18:25:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: telco-baseline, version 1\n",
      "Created version '1' of model 'telco-baseline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run trainRandomForest at: http://localhost:5000/#/experiments/1/runs/1dd28bbd7e1c40469a399dbc40fe0707\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "X, y, preprocessor = load_and_preprocess_data(file_path)\n",
    "pipeline = train_randomforest_baseline(X, y, preprocessor, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcdb06",
   "metadata": {},
   "source": [
    "## Introducing drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4a6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_numeric_covariate_drift(X, drift_threshold, numeric_cols, drift_info):\n",
    "    \"\"\"Apply covariate drift to numeric features.\"\"\"\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        if col not in X.columns:\n",
    "            continue\n",
    "            \n",
    "        col_mean = X[col].mean()\n",
    "        col_std = X[col].std()\n",
    "        \n",
    "        if pd.isna(col_mean) or pd.isna(col_std) or col_std == 0:\n",
    "            continue\n",
    "        \n",
    "        drift_type = i % 4\n",
    "        \n",
    "        if drift_type == 0:  # Mean shift\n",
    "            shift_amount = drift_threshold * col_mean * 0.3\n",
    "            X[col] = X[col] + shift_amount\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col, 'type': 'mean_shift', 'amount': shift_amount\n",
    "            })\n",
    "        elif drift_type == 1:  # Variance increase\n",
    "            noise = np.random.normal(0, drift_threshold * col_std * 0.5, len(X))\n",
    "            X[col] = X[col] + noise\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col, 'type': 'variance_increase', 'noise_std': drift_threshold * col_std * 0.5\n",
    "            })\n",
    "        elif drift_type == 2:  # Multiplicative shift\n",
    "            scale_factor = 1 + drift_threshold * 0.2 * np.random.choice([-1, 1])\n",
    "            X[col] = X[col] * scale_factor\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col, 'type': 'multiplicative_shift', 'factor': scale_factor\n",
    "            })\n",
    "        else:  # Add outliers\n",
    "            outlier_fraction = 0.1 * drift_threshold\n",
    "            n_outliers = int(outlier_fraction * len(X))\n",
    "            if n_outliers > 0:\n",
    "                outlier_indices = np.random.choice(X.index, n_outliers, replace=False)\n",
    "                outlier_multiplier = 3 + 2 * drift_threshold\n",
    "                X.loc[outlier_indices, col] = X.loc[outlier_indices, col] * outlier_multiplier\n",
    "                drift_info['covariate_shifts'].append({\n",
    "                    'feature': col, 'type': 'outliers', 'n_outliers': n_outliers\n",
    "                })\n",
    "    \n",
    "    # Special handling for Telco features\n",
    "    if 'tenure' in X.columns:\n",
    "        tenure_increase = drift_threshold * 5\n",
    "        X['tenure'] = X['tenure'] + np.random.normal(tenure_increase, 2, len(X))\n",
    "        X['tenure'] = X['tenure'].clip(lower=0)\n",
    "        drift_info['covariate_shifts'].append({\n",
    "            'feature': 'tenure', 'type': 'market_shift', 'increase_months': tenure_increase\n",
    "        })\n",
    "    \n",
    "    if 'MonthlyCharges' in X.columns:\n",
    "        inflation_rate = 1 + drift_threshold * 0.15\n",
    "        X['MonthlyCharges'] = X['MonthlyCharges'] * inflation_rate\n",
    "        drift_info['covariate_shifts'].append({\n",
    "            'feature': 'MonthlyCharges', 'type': 'inflation', 'rate': inflation_rate\n",
    "        })\n",
    "    \n",
    "    if 'TotalCharges' in X.columns and 'tenure' in X.columns and 'MonthlyCharges' in X.columns:\n",
    "        X['TotalCharges'] = X['tenure'] * X['MonthlyCharges'] * \\\n",
    "                           (1 + np.random.normal(0, 0.1 * drift_threshold, len(X)))\n",
    "        X['TotalCharges'] = X['TotalCharges'].clip(lower=0)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def _apply_categorical_covariate_drift(X, drift_threshold, categorical_cols, drift_info):\n",
    "    \"\"\"Apply covariate drift to categorical features.\"\"\"\n",
    "    for col in categorical_cols[:min(5, len(categorical_cols))]:\n",
    "        if col not in X.columns:\n",
    "            continue\n",
    "        \n",
    "        unique_vals = X[col].unique()\n",
    "        if len(unique_vals) < 2:\n",
    "            continue\n",
    "        \n",
    "        if col == 'InternetService' and 'Fiber optic' in unique_vals and 'DSL' in unique_vals:\n",
    "            mask_fiber = X[col] == 'DSL'\n",
    "            n_to_shift = int(len(X) * 0.2 * drift_threshold)\n",
    "            if mask_fiber.sum() > 0:\n",
    "                shift_indices = np.random.choice(\n",
    "                    X[mask_fiber].index[:n_to_shift], \n",
    "                    size=min(n_to_shift, mask_fiber.sum()), \n",
    "                    replace=False\n",
    "                )\n",
    "                X.loc[shift_indices, col] = 'Fiber optic'\n",
    "                drift_info['covariate_shifts'].append({\n",
    "                    'feature': col,\n",
    "                    'type': 'category_probability_shift',\n",
    "                    'shift': f'DSL -> Fiber optic ({len(shift_indices)} samples)'\n",
    "                })\n",
    "        elif len(unique_vals) >= 2:\n",
    "            value_counts = X[col].value_counts()\n",
    "            if len(value_counts) >= 2:\n",
    "                most_common = value_counts.index[0]\n",
    "                least_common = value_counts.index[-1]\n",
    "                \n",
    "                n_to_shift = int(len(X) * 0.15 * drift_threshold)\n",
    "                mask = X[col] == most_common\n",
    "                if mask.sum() > 0:\n",
    "                    shift_indices = np.random.choice(\n",
    "                        X[mask].index, \n",
    "                        size=min(n_to_shift, mask.sum()), \n",
    "                        replace=False\n",
    "                    )\n",
    "                    X.loc[shift_indices, col] = least_common\n",
    "                    drift_info['covariate_shifts'].append({\n",
    "                        'feature': col,\n",
    "                        'type': 'category_distribution_shift',\n",
    "                        'shift': f'{most_common} -> {least_common} ({len(shift_indices)} samples)'\n",
    "                    })\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def _apply_concept_drift(X, y, drift_threshold, drift_info):\n",
    "    \"\"\"Apply concept drift to target labels.\"\"\"\n",
    "    # 1. High-value customer retention\n",
    "    if 'MonthlyCharges' in X.columns:\n",
    "        high_charge_threshold = X['MonthlyCharges'].quantile(0.75)\n",
    "        high_charge_mask = X['MonthlyCharges'] > high_charge_threshold\n",
    "        n_to_flip = int(high_charge_mask.sum() * 0.3 * drift_threshold)\n",
    "        if n_to_flip > 0:\n",
    "            flip_indices = np.random.choice(\n",
    "                X[high_charge_mask].index, \n",
    "                size=min(n_to_flip, high_charge_mask.sum()), \n",
    "                replace=False\n",
    "            )\n",
    "            y.loc[flip_indices] = 1 - y.loc[flip_indices]\n",
    "            drift_info['concept_shifts'].append({\n",
    "                'type': 'high_value_retention',\n",
    "                'description': 'High MonthlyCharges customers now less likely to churn',\n",
    "                'n_samples': len(flip_indices)\n",
    "            })\n",
    "    \n",
    "    # 2. Tenure fatigue\n",
    "    if 'tenure' in X.columns:\n",
    "        long_tenure_threshold = X['tenure'].quantile(0.8)\n",
    "        long_tenure_mask = (X['tenure'] > long_tenure_threshold) & (y == 0)\n",
    "        n_to_flip = int(long_tenure_mask.sum() * 0.2 * drift_threshold)\n",
    "        if n_to_flip > 0:\n",
    "            flip_indices = np.random.choice(\n",
    "                X[long_tenure_mask].index, \n",
    "                size=min(n_to_flip, long_tenure_mask.sum()), \n",
    "                replace=False\n",
    "            )\n",
    "            y.loc[flip_indices] = 1\n",
    "            drift_info['concept_shifts'].append({\n",
    "                'type': 'tenure_fatigue',\n",
    "                'description': 'Very long tenure customers more likely to churn',\n",
    "                'n_samples': len(flip_indices)\n",
    "            })\n",
    "    \n",
    "    # 3. Service overwhelm\n",
    "    if 'service_engagement' in X.columns:\n",
    "        high_engagement_threshold = X['service_engagement'].quantile(0.7)\n",
    "        high_engagement_mask = (X['service_engagement'] > high_engagement_threshold) & (y == 0)\n",
    "        n_to_flip = int(high_engagement_mask.sum() * 0.25 * drift_threshold)\n",
    "        if n_to_flip > 0:\n",
    "            flip_indices = np.random.choice(\n",
    "                X[high_engagement_mask].index, \n",
    "                size=min(n_to_flip, high_engagement_mask.sum()), \n",
    "                replace=False\n",
    "            )\n",
    "            y.loc[flip_indices] = 1\n",
    "            drift_info['concept_shifts'].append({\n",
    "                'type': 'service_overwhelm',\n",
    "                'description': 'High service engagement customers more likely to churn',\n",
    "                'n_samples': len(flip_indices)\n",
    "            })\n",
    "    \n",
    "    # 4. Contract regret\n",
    "    if 'Contract' in X.columns:\n",
    "        two_year_mask = (X['Contract'] == 'Two year') & (y == 0)\n",
    "        n_to_flip = int(two_year_mask.sum() * 0.15 * drift_threshold)\n",
    "        if n_to_flip > 0:\n",
    "            flip_indices = np.random.choice(\n",
    "                X[two_year_mask].index, \n",
    "                size=min(n_to_flip, two_year_mask.sum()), \n",
    "                replace=False\n",
    "            )\n",
    "            y.loc[flip_indices] = 1\n",
    "            drift_info['concept_shifts'].append({\n",
    "                'type': 'contract_regret',\n",
    "                'description': 'Two year contract customers more likely to churn',\n",
    "                'n_samples': len(flip_indices)\n",
    "            })\n",
    "    \n",
    "    # 5. Base rate shift\n",
    "    base_rate_shift = drift_threshold * 0.1\n",
    "    if base_rate_shift > 0:\n",
    "        current_churn_rate = y.mean()\n",
    "        target_churn_rate = min(1.0, current_churn_rate + base_rate_shift)\n",
    "        \n",
    "        n_current_churn = y.sum()\n",
    "        n_target_churn = int(len(y) * target_churn_rate)\n",
    "        n_to_change = abs(n_target_churn - n_current_churn)\n",
    "        \n",
    "        if n_target_churn > n_current_churn and n_to_change > 0:\n",
    "            non_churners = X[y == 0].index\n",
    "            if len(non_churners) > 0:\n",
    "                flip_indices = np.random.choice(\n",
    "                    non_churners, \n",
    "                    size=min(n_to_change, len(non_churners)), \n",
    "                    replace=False\n",
    "                )\n",
    "                y.loc[flip_indices] = 1\n",
    "        elif n_to_change > 0:\n",
    "            churners = X[y == 1].index\n",
    "            if len(churners) > 0:\n",
    "                flip_indices = np.random.choice(\n",
    "                    churners, \n",
    "                    size=min(n_to_change, len(churners)), \n",
    "                    replace=False\n",
    "                )\n",
    "                y.loc[flip_indices] = 0\n",
    "        \n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'base_rate_shift',\n",
    "            'description': f'Overall churn rate shifted from {current_churn_rate:.3f} to {target_churn_rate:.3f}',\n",
    "            'shift_amount': base_rate_shift\n",
    "        })\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def simulate_drift(X, y, drift_threshold=0.5, drift_type='combined', \n",
    "                   covariate_weight=1.0, concept_weight=1.0, random_state=42):\n",
    "    \"\"\"\n",
    "    Unified drift simulation function supporting all drift types.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Original feature dataframe\n",
    "    y : pd.Series\n",
    "        Original target labels\n",
    "    drift_threshold : float\n",
    "        Controls overall drift intensity (0.0 to 1.0)\n",
    "    drift_type : str\n",
    "        Type of drift: 'combined', 'covariate', or 'concept'\n",
    "    covariate_weight : float\n",
    "        Weight for covariate drift component (0.0 to 1.0)\n",
    "    concept_weight : float\n",
    "        Weight for concept drift component (0.0 to 1.0)\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X_drifted : pd.DataFrame\n",
    "        Drifted feature dataframe\n",
    "    y_drifted : pd.Series\n",
    "        Drifted target labels\n",
    "    drift_info : dict\n",
    "        Information about applied drifts\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    X_drifted = X.copy()\n",
    "    y_drifted = y.copy()\n",
    "    \n",
    "    drift_info = {\n",
    "        'covariate_shifts': [],\n",
    "        'concept_shifts': [],\n",
    "        'threshold': drift_threshold,\n",
    "        'drift_type': drift_type,\n",
    "        'covariate_weight': covariate_weight,\n",
    "        'concept_weight': concept_weight\n",
    "    }\n",
    "    \n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\"Simulating {drift_type} drift with threshold: {drift_threshold:.2f}\")\n",
    "    if drift_type == 'combined':\n",
    "        print(f\"Covariate weight: {covariate_weight:.2f}, Concept weight: {concept_weight:.2f}\")\n",
    "    print(f\"Applying to {len(numeric_cols)} numeric and {len(categorical_cols)} categorical features\")\n",
    "    \n",
    "    # Apply covariate drift\n",
    "    if drift_type in ['combined', 'covariate'] and covariate_weight > 0:\n",
    "        effective_threshold = drift_threshold * covariate_weight\n",
    "        X_drifted = _apply_numeric_covariate_drift(X_drifted, effective_threshold, numeric_cols, drift_info)\n",
    "        X_drifted = _apply_categorical_covariate_drift(X_drifted, effective_threshold, categorical_cols, drift_info)\n",
    "    \n",
    "    # Apply concept drift\n",
    "    if drift_type in ['combined', 'concept'] and concept_weight > 0:\n",
    "        effective_threshold = drift_threshold * concept_weight\n",
    "        y_drifted = _apply_concept_drift(X_drifted, y_drifted, effective_threshold, drift_info)\n",
    "    \n",
    "    print(f\"Applied {len(drift_info['covariate_shifts'])} covariate shifts\")\n",
    "    print(f\"Applied {len(drift_info['concept_shifts'])} concept shifts\")\n",
    "    print(f\"Final churn rate: {y_drifted.mean():.3f} (original: {y.mean():.3f})\")\n",
    "    \n",
    "    return X_drifted, y_drifted, drift_info\n",
    "\n",
    "def create_drift_visualizations(X_original, y_original, X_drifted, y_drifted, \n",
    "                                metrics_original, metrics_drifted, drift_threshold, \n",
    "                                save_dir='drift_plots'):\n",
    "    import os\n",
    "    from sklearn.metrics import roc_curve\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plot_paths = []\n",
    "    \n",
    "    # 1. ROC Curve Comparison\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Get predictions for ROC curves (assuming they're passed or calculated)\n",
    "    # For now, we'll create a placeholder - in practice, predictions should be passed\n",
    "    try:\n",
    "        if 'y_prob_original' in metrics_original and 'y_prob_drifted' in metrics_drifted:\n",
    "            fpr_orig, tpr_orig, _ = roc_curve(y_original, metrics_original['y_prob_original'])\n",
    "            fpr_drift, tpr_drift, _ = roc_curve(y_drifted, metrics_drifted['y_prob_drifted'])\n",
    "            \n",
    "            ax.plot(fpr_orig, tpr_orig, label=f'Original (AUC={metrics_original[\"auc\"]:.3f})', linewidth=2)\n",
    "            ax.plot(fpr_drift, tpr_drift, label=f'Drifted (AUC={metrics_drifted[\"auc\"]:.3f})', linewidth=2)\n",
    "            ax.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1)\n",
    "            ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "            ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "            ax.set_title(f'ROC Curve Comparison (Drift Threshold: {drift_threshold})', fontsize=14, fontweight='bold')\n",
    "            ax.legend(loc='lower right', fontsize=10)\n",
    "            ax.grid(alpha=0.3)\n",
    "    except:\n",
    "        pass  # Skip if predictions not available\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    roc_path = os.path.join(save_dir, 'roc_curve_comparison.png')\n",
    "    plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plot_paths.append(roc_path)\n",
    "    \n",
    "    # 2. Metric Degradation Bar Chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    original_vals = [metrics_original.get(m, 0) for m in metrics_to_plot]\n",
    "    drifted_vals = [metrics_drifted.get(m, 0) for m in metrics_to_plot]\n",
    "    degradations = [orig - drift for orig, drift in zip(original_vals, drifted_vals)]\n",
    "    \n",
    "    x = np.arange(len(metrics_to_plot))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, original_vals, width, label='Original', alpha=0.8, color='#2ecc71')\n",
    "    bars2 = ax.bar(x + width/2, drifted_vals, width, label='Drifted', alpha=0.8, color='#e74c3c')\n",
    "    \n",
    "    # Add degradation percentages on bars\n",
    "    for i, (orig, drift, deg) in enumerate(zip(original_vals, drifted_vals, degradations)):\n",
    "        if orig > 0:\n",
    "            pct = (deg / orig) * 100\n",
    "            ax.text(i, max(orig, drift) + 0.02, f'{pct:.1f}%', \n",
    "                   ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Metrics', fontsize=12)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title(f'Model Performance Degradation (Drift Threshold: {drift_threshold})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics_to_plot, fontsize=11)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    metric_path = os.path.join(save_dir, 'metric_degradation.png')\n",
    "    plt.savefig(metric_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plot_paths.append(metric_path)\n",
    "    \n",
    "    # 3. Feature Distribution Comparison (for key numeric features)\n",
    "    numeric_cols = X_original.select_dtypes(include=[np.number]).columns[:6]  # Top 6 numeric features\n",
    "    \n",
    "    if len(numeric_cols) > 0:\n",
    "        n_cols = min(3, len(numeric_cols))\n",
    "        n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "        axes = axes.flatten() if len(numeric_cols) > 1 else [axes]\n",
    "        \n",
    "        for idx, col in enumerate(numeric_cols):\n",
    "            if idx >= len(axes):\n",
    "                break\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            ax.hist(X_original[col].dropna(), bins=30, alpha=0.6, label='Original', \n",
    "                   color='#2ecc71', density=True)\n",
    "            ax.hist(X_drifted[col].dropna(), bins=30, alpha=0.6, label='Drifted', \n",
    "                   color='#e74c3c', density=True)\n",
    "            ax.set_xlabel(col, fontsize=10)\n",
    "            ax.set_ylabel('Density', fontsize=10)\n",
    "            ax.set_title(f'{col} Distribution', fontsize=11, fontweight='bold')\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(alpha=0.3)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for idx in range(len(numeric_cols), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Feature Distribution Drift (Drift Threshold: {drift_threshold})', \n",
    "                    fontsize=14, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        dist_path = os.path.join(save_dir, 'feature_distributions.png')\n",
    "        plt.savefig(dist_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plot_paths.append(dist_path)\n",
    "    \n",
    "    # 4. Churn Rate Comparison\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    churn_original = y_original.mean()\n",
    "    churn_drifted = y_drifted.mean()\n",
    "    \n",
    "    categories = ['Original', 'Drifted']\n",
    "    churn_rates = [churn_original, churn_drifted]\n",
    "    colors = ['#2ecc71', '#e74c3c']\n",
    "    \n",
    "    bars = ax.bar(categories, churn_rates, color=colors, alpha=0.8, width=0.6)\n",
    "    ax.set_ylabel('Churn Rate', fontsize=12)\n",
    "    ax.set_title(f'Churn Rate Shift (Drift Threshold: {drift_threshold})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_ylim([0, max(churn_rates) * 1.2])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, rate in zip(bars, churn_rates):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{rate:.3f}',\n",
    "               ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Add change annotation\n",
    "    change = churn_drifted - churn_original\n",
    "    change_pct = (change / churn_original) * 100 if churn_original > 0 else 0\n",
    "    ax.annotate(f'Change: {change:+.3f} ({change_pct:+.1f}%)',\n",
    "               xy=(1, churn_drifted), xytext=(1.3, churn_drifted + 0.05),\n",
    "               arrowprops=dict(arrowstyle='->', color='black', lw=1.5),\n",
    "               fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    churn_path = os.path.join(save_dir, 'churn_rate_shift.png')\n",
    "    plt.savefig(churn_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plot_paths.append(churn_path)\n",
    "    \n",
    "    return plot_paths\n",
    "\n",
    "# Backward-compatible wrapper functions\n",
    "def simulate_drifted_data(X, y, drift_threshold=0.5, random_state=42):\n",
    "    \"\"\"Combined drift (original function signature maintained).\"\"\"\n",
    "    return simulate_drift(X, y, drift_threshold=drift_threshold, \n",
    "                         drift_type='combined', random_state=random_state)\n",
    "\n",
    "\n",
    "def simulate_covariate_drift_only(X, y, drift_threshold=0.5, random_state=42):\n",
    "    \"\"\"Covariate drift only (original function signature maintained).\"\"\"\n",
    "    return simulate_drift(X, y, drift_threshold=drift_threshold, \n",
    "                         drift_type='covariate', random_state=random_state)\n",
    "\n",
    "\n",
    "def simulate_concept_drift_only(X, y, drift_threshold=0.5, random_state=42):\n",
    "    \"\"\"Concept drift only (original function signature maintained).\"\"\"\n",
    "    return simulate_drift(X, y, drift_threshold=drift_threshold, \n",
    "                         drift_type='concept', random_state=random_state)\n",
    "\n",
    "\n",
    "def simulate_selective_drift(X, y, drift_threshold=0.5, \n",
    "                            covariate_ratio=0.75, concept_ratio=0.25, \n",
    "                            random_state=42):\n",
    "    \"\"\"Selective drift with custom ratios (original function signature maintained).\"\"\"\n",
    "    return simulate_drift(X, y, drift_threshold=drift_threshold, \n",
    "                         drift_type='combined',\n",
    "                         covariate_weight=covariate_ratio,\n",
    "                         concept_weight=concept_ratio,\n",
    "                         random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e7c109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef simulate_drifted_data(X, y, drift_threshold=0.5, random_state=42):\\n    \"\"\"\\n    Simulate drifted data with both covariate shift and concept shift.\\n\\n    Parameters:\\n    -----------\\n    X : pd.DataFrame\\n        Original feature dataframe (before preprocessing)\\n    y : pd.Series\\n        Original target labels (0/1)\\n    drift_threshold : float\\n        Controls the intensity of drift (0.0 to 1.0)\\n        - 0.0: No drift\\n        - 0.5: Moderate drift\\n        - 1.0: Severe drift\\n    random_state : int\\n        Random seed for reproducibility\\n\\n    Returns:\\n    --------\\n    X_drifted : pd.DataFrame\\n        Drifted feature dataframe\\n    y_drifted : pd.Series\\n        Drifted target labels (after concept shift)\\n    drift_info : dict\\n        Information about what drift was applied\\n    \"\"\"\\n    np.random.seed(random_state)\\n    X_drifted = X.copy()\\n    y_drifted = y.copy()\\n\\n    drift_info = {\\n        \\'covariate_shifts\\': [],\\n        \\'concept_shifts\\': [],\\n        \\'threshold\\': drift_threshold\\n    }\\n\\n    # Identify numeric and categorical columns\\n    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\\n    categorical_cols = X.select_dtypes(include=[\\'object\\', \\'category\\']).columns.tolist()\\n\\n    print(f\"Simulating drift with threshold: {drift_threshold:.2f}\")\\n    print(f\"Applying to {len(numeric_cols)} numeric and {len(categorical_cols)} categorical features\")\\n\\n    # ============================================\\n    # COVARIATE SHIFT: Changes to feature distributions\\n    # ============================================\\n\\n    # 1. Numeric Feature Drifts\\n    for i, col in enumerate(numeric_cols):\\n        if col not in X_drifted.columns:\\n            continue\\n\\n        col_mean = X_drifted[col].mean()\\n        col_std = X_drifted[col].std()\\n\\n        if pd.isna(col_mean) or pd.isna(col_std) or col_std == 0:\\n            continue\\n\\n        # Apply different types of drift to different features\\n        drift_type = i % 4\\n\\n        if drift_type == 0:  # Mean shift (increase/decrease)\\n            shift_amount = drift_threshold * col_mean * 0.3  # Up to 30% of mean\\n            X_drifted[col] = X_drifted[col] + shift_amount\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'mean_shift\\',\\n                \\'amount\\': shift_amount\\n            })\\n\\n        elif drift_type == 1:  # Variance increase\\n            noise = np.random.normal(0, drift_threshold * col_std * 0.5, len(X_drifted))\\n            X_drifted[col] = X_drifted[col] + noise\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'variance_increase\\',\\n                \\'noise_std\\': drift_threshold * col_std * 0.5\\n            })\\n\\n        elif drift_type == 2:  # Multiplicative shift (scaling)\\n            scale_factor = 1 + drift_threshold * 0.2 * np.random.choice([-1, 1])\\n            X_drifted[col] = X_drifted[col] * scale_factor\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'multiplicative_shift\\',\\n                \\'factor\\': scale_factor\\n            })\\n\\n        else:  # Add outliers\\n            outlier_fraction = 0.1 * drift_threshold  # Up to 10% outliers\\n            n_outliers = int(outlier_fraction * len(X_drifted))\\n            outlier_indices = np.random.choice(X_drifted.index, n_outliers, replace=False)\\n            # Make outliers 3-5x the original value\\n            outlier_multiplier = 3 + 2 * drift_threshold\\n            X_drifted.loc[outlier_indices, col] = X_drifted.loc[outlier_indices, col] * outlier_multiplier\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'outliers\\',\\n                \\'n_outliers\\': n_outliers\\n            })\\n\\n    # Special handling for key Telco features\\n    if \\'tenure\\' in X_drifted.columns:\\n        # Simulate customers staying longer (market shift)\\n        tenure_increase = drift_threshold * 5  # Up to 5 months increase\\n        X_drifted[\\'tenure\\'] = X_drifted[\\'tenure\\'] + np.random.normal(tenure_increase, 2, len(X_drifted))\\n        X_drifted[\\'tenure\\'] = X_drifted[\\'tenure\\'].clip(lower=0)  # Ensure non-negative\\n        drift_info[\\'covariate_shifts\\'].append({\\n            \\'feature\\': \\'tenure\\',\\n            \\'type\\': \\'market_shift\\',\\n            \\'increase_months\\': tenure_increase\\n        })\\n\\n    if \\'MonthlyCharges\\' in X_drifted.columns:\\n        # Simulate price inflation\\n        inflation_rate = 1 + drift_threshold * 0.15  # Up to 15% increase\\n        X_drifted[\\'MonthlyCharges\\'] = X_drifted[\\'MonthlyCharges\\'] * inflation_rate\\n        drift_info[\\'covariate_shifts\\'].append({\\n            \\'feature\\': \\'MonthlyCharges\\',\\n            \\'type\\': \\'inflation\\',\\n            \\'rate\\': inflation_rate\\n        })\\n\\n    if \\'TotalCharges\\' in X_drifted.columns:\\n        # Recalculate TotalCharges based on drifted tenure and MonthlyCharges if both exist\\n        if \\'tenure\\' in X_drifted.columns and \\'MonthlyCharges\\' in X_drifted.columns:\\n            # TotalCharges should roughly be tenure * MonthlyCharges (with some variation)\\n            X_drifted[\\'TotalCharges\\'] = X_drifted[\\'tenure\\'] * X_drifted[\\'MonthlyCharges\\'] *                                        (1 + np.random.normal(0, 0.1 * drift_threshold, len(X_drifted)))\\n            X_drifted[\\'TotalCharges\\'] = X_drifted[\\'TotalCharges\\'].clip(lower=0)\\n\\n    # 2. Categorical Feature Drifts\\n    for col in categorical_cols[:min(5, len(categorical_cols))]:  # Limit to avoid too many changes\\n        if col not in X_drifted.columns:\\n            continue\\n\\n        unique_vals = X_drifted[col].unique()\\n        if len(unique_vals) < 2:\\n            continue\\n\\n        # Shift probability distribution towards different categories\\n        # Example: More customers choosing \\'Fiber optic\\' over \\'DSL\\'\\n        if col == \\'InternetService\\' and \\'Fiber optic\\' in unique_vals and \\'DSL\\' in unique_vals:\\n            mask_fiber = X_drifted[col] == \\'DSL\\'\\n            n_to_shift = int(len(X_drifted) * 0.2 * drift_threshold)\\n            shift_indices = np.random.choice(X_drifted[mask_fiber].index[:n_to_shift], \\n                                            size=min(n_to_shift, mask_fiber.sum()), \\n                                            replace=False)\\n            X_drifted.loc[shift_indices, col] = \\'Fiber optic\\'\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'category_probability_shift\\',\\n                \\'shift\\': f\\'DSL -> Fiber optic ({len(shift_indices)} samples)\\'\\n            })\\n\\n        # General categorical shift: change distribution\\n        elif len(unique_vals) >= 2:\\n            # Shift some samples from most common to least common category\\n            value_counts = X_drifted[col].value_counts()\\n            if len(value_counts) >= 2:\\n                most_common = value_counts.index[0]\\n                least_common = value_counts.index[-1]\\n\\n                n_to_shift = int(len(X_drifted) * 0.15 * drift_threshold)\\n                mask = X_drifted[col] == most_common\\n                if mask.sum() > 0:\\n                    shift_indices = np.random.choice(X_drifted[mask].index, \\n                                                    size=min(n_to_shift, mask.sum()), \\n                                                    replace=False)\\n                    X_drifted.loc[shift_indices, col] = least_common\\n                    drift_info[\\'covariate_shifts\\'].append({\\n                        \\'feature\\': col,\\n                        \\'type\\': \\'category_distribution_shift\\',\\n                        \\'shift\\': f\\'{most_common} -> {least_common} ({len(shift_indices)} samples)\\'\\n                    })\\n\\n    # ============================================\\n    # CONCEPT SHIFT: Changes to label relationships\\n    # ============================================\\n\\n    print(\"Applying concept shift...\")\\n\\n    # 1. Reverse relationship for high-value customers\\n    # Original: Higher charges -> more likely to churn\\n    # Drifted: Higher charges -> less likely to churn (premium retention)\\n    if \\'MonthlyCharges\\' in X_drifted.columns:\\n        high_charge_threshold = X_drifted[\\'MonthlyCharges\\'].quantile(0.75)\\n        high_charge_mask = X_drifted[\\'MonthlyCharges\\'] > high_charge_threshold\\n\\n        # Reverse churn probability for high-charge customers\\n        n_to_flip = int(high_charge_mask.sum() * 0.3 * drift_threshold)\\n        flip_indices = np.random.choice(X_drifted[high_charge_mask].index, \\n                                       size=min(n_to_flip, high_charge_mask.sum()), \\n                                       replace=False)\\n        y_drifted.loc[flip_indices] = 1 - y_drifted.loc[flip_indices]  # Flip labels\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'high_value_retention\\',\\n            \\'description\\': \\'High MonthlyCharges customers now less likely to churn\\',\\n            \\'n_samples\\': len(flip_indices)\\n        })\\n\\n    # 2. Change relationship with tenure\\n    # Original: Longer tenure -> less likely to churn\\n    # Drifted: Very long tenure customers may become more likely to churn (market fatigue)\\n    if \\'tenure\\' in X_drifted.columns:\\n        long_tenure_threshold = X_drifted[\\'tenure\\'].quantile(0.8)\\n        long_tenure_mask = (X_drifted[\\'tenure\\'] > long_tenure_threshold) & (y_drifted == 0)\\n\\n        n_to_flip = int(long_tenure_mask.sum() * 0.2 * drift_threshold)\\n        flip_indices = np.random.choice(X_drifted[long_tenure_mask].index, \\n                                       size=min(n_to_flip, long_tenure_mask.sum()), \\n                                       replace=False)\\n        y_drifted.loc[flip_indices] = 1  # Flip to churn\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'tenure_fatigue\\',\\n            \\'description\\': \\'Very long tenure customers more likely to churn\\',\\n            \\'n_samples\\': len(flip_indices)\\n        })\\n\\n    # 3. Change relationship with service engagement\\n    # Original: More services -> less likely to churn\\n    # Drifted: More services -> more likely to churn (complexity/overwhelm)\\n    if \\'service_engagement\\' in X_drifted.columns:\\n        high_engagement_threshold = X_drifted[\\'service_engagement\\'].quantile(0.7)\\n        high_engagement_mask = (X_drifted[\\'service_engagement\\'] > high_engagement_threshold) & (y_drifted == 0)\\n\\n        n_to_flip = int(high_engagement_mask.sum() * 0.25 * drift_threshold)\\n        flip_indices = np.random.choice(X_drifted[high_engagement_mask].index, \\n                                       size=min(n_to_flip, high_engagement_mask.sum()), \\n                                       replace=False)\\n        y_drifted.loc[flip_indices] = 1  # Flip to churn\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'service_overwhelm\\',\\n            \\'description\\': \\'High service engagement customers more likely to churn\\',\\n            \\'n_samples\\': len(flip_indices)\\n        })\\n\\n    # 4. Contract type relationship change\\n    # Original: Longer contracts -> less churn\\n    # Drifted: Some contract types become less effective\\n    if \\'Contract\\' in X_drifted.columns:\\n        # Make \"Two year\" contract customers more likely to churn (regret/commitment issues)\\n        two_year_mask = (X_drifted[\\'Contract\\'] == \\'Two year\\') & (y_drifted == 0)\\n        n_to_flip = int(two_year_mask.sum() * 0.15 * drift_threshold)\\n        flip_indices = np.random.choice(X_drifted[two_year_mask].index, \\n                                       size=min(n_to_flip, two_year_mask.sum()), \\n                                       replace=False)\\n        y_drifted.loc[flip_indices] = 1\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'contract_regret\\',\\n            \\'description\\': \\'Two year contract customers more likely to churn\\',\\n            \\'n_samples\\': len(flip_indices)\\n        })\\n\\n    # 5. Overall base rate shift (global concept shift)\\n    # Shift the overall churn rate\\n    base_rate_shift = drift_threshold * 0.1  # Up to 10 percentage points\\n    if base_rate_shift > 0:\\n        current_churn_rate = y_drifted.mean()\\n        target_churn_rate = min(1.0, current_churn_rate + base_rate_shift)\\n\\n        # Adjust labels to match target rate\\n        n_current_churn = y_drifted.sum()\\n        n_target_churn = int(len(y_drifted) * target_churn_rate)\\n        n_to_change = abs(n_target_churn - n_current_churn)\\n\\n        if n_target_churn > n_current_churn:\\n            # Need more churners - flip some non-churners\\n            non_churners = X_drifted[y_drifted == 0].index\\n            flip_indices = np.random.choice(non_churners, \\n                                           size=min(n_to_change, len(non_churners)), \\n                                           replace=False)\\n            y_drifted.loc[flip_indices] = 1\\n        else:\\n            # Need fewer churners - flip some churners\\n            churners = X_drifted[y_drifted == 1].index\\n            flip_indices = np.random.choice(churners, \\n                                           size=min(n_to_change, len(churners)), \\n                                           replace=False)\\n            y_drifted.loc[flip_indices] = 0\\n\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'base_rate_shift\\',\\n            \\'description\\': f\\'Overall churn rate shifted from {current_churn_rate:.3f} to {target_churn_rate:.3f}\\',\\n            \\'shift_amount\\': base_rate_shift\\n        })\\n\\n    print(f\"âœ“ Applied {len(drift_info[\\'covariate_shifts\\'])} covariate shifts\")\\n    print(f\"âœ“ Applied {len(drift_info[\\'concept_shifts\\'])} concept shifts\")\\n    print(f\"Final churn rate: {y_drifted.mean():.3f} (original: {y.mean():.3f})\")\\n\\n    return X_drifted, y_drifted, drift_info\\n\\n\\ndef create_drift_visualizations(X_original, y_original, X_drifted, y_drifted, \\n                                metrics_original, metrics_drifted, drift_threshold, \\n                                save_dir=\\'drift_plots\\'):\\n    \"\"\"\\n    Create visualization plots for drift analysis.\\n\\n    Parameters:\\n    -----------\\n    X_original : pd.DataFrame\\n        Original feature data\\n    y_original : pd.Series\\n        Original target labels\\n    X_drifted : pd.DataFrame\\n        Drifted feature data\\n    y_drifted : pd.Series\\n        Drifted target labels\\n    metrics_original : dict\\n        Metrics on original data\\n    metrics_drifted : dict\\n        Metrics on drifted data\\n    drift_threshold : float\\n        Drift threshold used\\n    save_dir : str\\n        Directory to save plots\\n\\n    Returns:\\n    --------\\n    plot_paths : list\\n        List of paths to saved plot files\\n    \"\"\"\\n    import os\\n    from sklearn.metrics import roc_curve\\n\\n    os.makedirs(save_dir, exist_ok=True)\\n    plot_paths = []\\n\\n    # 1. ROC Curve Comparison\\n    fig, ax = plt.subplots(figsize=(8, 6))\\n\\n    # Get predictions for ROC curves (assuming they\\'re passed or calculated)\\n    # For now, we\\'ll create a placeholder - in practice, predictions should be passed\\n    try:\\n        if \\'y_prob_original\\' in metrics_original and \\'y_prob_drifted\\' in metrics_drifted:\\n            fpr_orig, tpr_orig, _ = roc_curve(y_original, metrics_original[\\'y_prob_original\\'])\\n            fpr_drift, tpr_drift, _ = roc_curve(y_drifted, metrics_drifted[\\'y_prob_drifted\\'])\\n\\n            ax.plot(fpr_orig, tpr_orig, label=f\\'Original (AUC={metrics_original[\"auc\"]:.3f})\\', linewidth=2)\\n            ax.plot(fpr_drift, tpr_drift, label=f\\'Drifted (AUC={metrics_drifted[\"auc\"]:.3f})\\', linewidth=2)\\n            ax.plot([0, 1], [0, 1], \\'k--\\', label=\\'Random\\', linewidth=1)\\n            ax.set_xlabel(\\'False Positive Rate\\', fontsize=12)\\n            ax.set_ylabel(\\'True Positive Rate\\', fontsize=12)\\n            ax.set_title(f\\'ROC Curve Comparison (Drift Threshold: {drift_threshold})\\', fontsize=14, fontweight=\\'bold\\')\\n            ax.legend(loc=\\'lower right\\', fontsize=10)\\n            ax.grid(alpha=0.3)\\n    except:\\n        pass  # Skip if predictions not available\\n\\n    plt.tight_layout()\\n    roc_path = os.path.join(save_dir, \\'roc_curve_comparison.png\\')\\n    plt.savefig(roc_path, dpi=300, bbox_inches=\\'tight\\')\\n    plt.close()\\n    plot_paths.append(roc_path)\\n\\n    # 2. Metric Degradation Bar Chart\\n    fig, ax = plt.subplots(figsize=(10, 6))\\n\\n    metrics_to_plot = [\\'accuracy\\', \\'precision\\', \\'recall\\', \\'f1\\', \\'auc\\']\\n    original_vals = [metrics_original.get(m, 0) for m in metrics_to_plot]\\n    drifted_vals = [metrics_drifted.get(m, 0) for m in metrics_to_plot]\\n    degradations = [orig - drift for orig, drift in zip(original_vals, drifted_vals)]\\n\\n    x = np.arange(len(metrics_to_plot))\\n    width = 0.35\\n\\n    bars1 = ax.bar(x - width/2, original_vals, width, label=\\'Original\\', alpha=0.8, color=\\'#2ecc71\\')\\n    bars2 = ax.bar(x + width/2, drifted_vals, width, label=\\'Drifted\\', alpha=0.8, color=\\'#e74c3c\\')\\n\\n    # Add degradation percentages on bars\\n    for i, (orig, drift, deg) in enumerate(zip(original_vals, drifted_vals, degradations)):\\n        if orig > 0:\\n            pct = (deg / orig) * 100\\n            ax.text(i, max(orig, drift) + 0.02, f\\'{pct:.1f}%\\', \\n                   ha=\\'center\\', va=\\'bottom\\', fontsize=9, fontweight=\\'bold\\')\\n\\n    ax.set_xlabel(\\'Metrics\\', fontsize=12)\\n    ax.set_ylabel(\\'Score\\', fontsize=12)\\n    ax.set_title(f\\'Model Performance Degradation (Drift Threshold: {drift_threshold})\\', \\n                fontsize=14, fontweight=\\'bold\\')\\n    ax.set_xticks(x)\\n    ax.set_xticklabels(metrics_to_plot, fontsize=11)\\n    ax.legend(fontsize=10)\\n    ax.grid(axis=\\'y\\', alpha=0.3)\\n    ax.set_ylim([0, 1.1])\\n\\n    plt.tight_layout()\\n    metric_path = os.path.join(save_dir, \\'metric_degradation.png\\')\\n    plt.savefig(metric_path, dpi=300, bbox_inches=\\'tight\\')\\n    plt.close()\\n    plot_paths.append(metric_path)\\n\\n    # 3. Feature Distribution Comparison (for key numeric features)\\n    numeric_cols = X_original.select_dtypes(include=[np.number]).columns[:6]  # Top 6 numeric features\\n\\n    if len(numeric_cols) > 0:\\n        n_cols = min(3, len(numeric_cols))\\n        n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\\n        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\\n        axes = axes.flatten() if len(numeric_cols) > 1 else [axes]\\n\\n        for idx, col in enumerate(numeric_cols):\\n            if idx >= len(axes):\\n                break\\n            ax = axes[idx]\\n\\n            ax.hist(X_original[col].dropna(), bins=30, alpha=0.6, label=\\'Original\\', \\n                   color=\\'#2ecc71\\', density=True)\\n            ax.hist(X_drifted[col].dropna(), bins=30, alpha=0.6, label=\\'Drifted\\', \\n                   color=\\'#e74c3c\\', density=True)\\n            ax.set_xlabel(col, fontsize=10)\\n            ax.set_ylabel(\\'Density\\', fontsize=10)\\n            ax.set_title(f\\'{col} Distribution\\', fontsize=11, fontweight=\\'bold\\')\\n            ax.legend(fontsize=9)\\n            ax.grid(alpha=0.3)\\n\\n        # Hide unused subplots\\n        for idx in range(len(numeric_cols), len(axes)):\\n            axes[idx].axis(\\'off\\')\\n\\n        plt.suptitle(f\\'Feature Distribution Drift (Drift Threshold: {drift_threshold})\\', \\n                    fontsize=14, fontweight=\\'bold\\', y=1.02)\\n        plt.tight_layout()\\n        dist_path = os.path.join(save_dir, \\'feature_distributions.png\\')\\n        plt.savefig(dist_path, dpi=300, bbox_inches=\\'tight\\')\\n        plt.close()\\n        plot_paths.append(dist_path)\\n\\n    # 4. Churn Rate Comparison\\n    fig, ax = plt.subplots(figsize=(8, 6))\\n\\n    churn_original = y_original.mean()\\n    churn_drifted = y_drifted.mean()\\n\\n    categories = [\\'Original\\', \\'Drifted\\']\\n    churn_rates = [churn_original, churn_drifted]\\n    colors = [\\'#2ecc71\\', \\'#e74c3c\\']\\n\\n    bars = ax.bar(categories, churn_rates, color=colors, alpha=0.8, width=0.6)\\n    ax.set_ylabel(\\'Churn Rate\\', fontsize=12)\\n    ax.set_title(f\\'Churn Rate Shift (Drift Threshold: {drift_threshold})\\', \\n                fontsize=14, fontweight=\\'bold\\')\\n    ax.set_ylim([0, max(churn_rates) * 1.2])\\n    ax.grid(axis=\\'y\\', alpha=0.3)\\n\\n    # Add value labels on bars\\n    for bar, rate in zip(bars, churn_rates):\\n        height = bar.get_height()\\n        ax.text(bar.get_x() + bar.get_width()/2., height,\\n               f\\'{rate:.3f}\\',\\n               ha=\\'center\\', va=\\'bottom\\', fontsize=11, fontweight=\\'bold\\')\\n\\n    # Add change annotation\\n    change = churn_drifted - churn_original\\n    change_pct = (change / churn_original) * 100 if churn_original > 0 else 0\\n    ax.annotate(f\\'Change: {change:+.3f} ({change_pct:+.1f}%)\\',\\n               xy=(1, churn_drifted), xytext=(1.3, churn_drifted + 0.05),\\n               arrowprops=dict(arrowstyle=\\'->\\', color=\\'black\\', lw=1.5),\\n               fontsize=10, fontweight=\\'bold\\')\\n\\n    plt.tight_layout()\\n    churn_path = os.path.join(save_dir, \\'churn_rate_shift.png\\')\\n    plt.savefig(churn_path, dpi=300, bbox_inches=\\'tight\\')\\n    plt.close()\\n    plot_paths.append(churn_path)\\n\\n    return plot_paths\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell is now deprecated\n",
    "\n",
    "'''\n",
    "def simulate_drifted_data(X, y, drift_threshold=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Simulate drifted data with both covariate shift and concept shift.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Original feature dataframe (before preprocessing)\n",
    "    y : pd.Series\n",
    "        Original target labels (0/1)\n",
    "    drift_threshold : float\n",
    "        Controls the intensity of drift (0.0 to 1.0)\n",
    "        - 0.0: No drift\n",
    "        - 0.5: Moderate drift\n",
    "        - 1.0: Severe drift\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_drifted : pd.DataFrame\n",
    "        Drifted feature dataframe\n",
    "    y_drifted : pd.Series\n",
    "        Drifted target labels (after concept shift)\n",
    "    drift_info : dict\n",
    "        Information about what drift was applied\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    X_drifted = X.copy()\n",
    "    y_drifted = y.copy()\n",
    "    \n",
    "    drift_info = {\n",
    "        'covariate_shifts': [],\n",
    "        'concept_shifts': [],\n",
    "        'threshold': drift_threshold\n",
    "    }\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\"Simulating drift with threshold: {drift_threshold:.2f}\")\n",
    "    print(f\"Applying to {len(numeric_cols)} numeric and {len(categorical_cols)} categorical features\")\n",
    "    \n",
    "    # ============================================\n",
    "    # COVARIATE SHIFT: Changes to feature distributions\n",
    "    # ============================================\n",
    "    \n",
    "    # 1. Numeric Feature Drifts\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        if col not in X_drifted.columns:\n",
    "            continue\n",
    "            \n",
    "        col_mean = X_drifted[col].mean()\n",
    "        col_std = X_drifted[col].std()\n",
    "        \n",
    "        if pd.isna(col_mean) or pd.isna(col_std) or col_std == 0:\n",
    "            continue\n",
    "        \n",
    "        # Apply different types of drift to different features\n",
    "        drift_type = i % 4\n",
    "        \n",
    "        if drift_type == 0:  # Mean shift (increase/decrease)\n",
    "            shift_amount = drift_threshold * col_mean * 0.3  # Up to 30% of mean\n",
    "            X_drifted[col] = X_drifted[col] + shift_amount\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'mean_shift',\n",
    "                'amount': shift_amount\n",
    "            })\n",
    "            \n",
    "        elif drift_type == 1:  # Variance increase\n",
    "            noise = np.random.normal(0, drift_threshold * col_std * 0.5, len(X_drifted))\n",
    "            X_drifted[col] = X_drifted[col] + noise\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'variance_increase',\n",
    "                'noise_std': drift_threshold * col_std * 0.5\n",
    "            })\n",
    "            \n",
    "        elif drift_type == 2:  # Multiplicative shift (scaling)\n",
    "            scale_factor = 1 + drift_threshold * 0.2 * np.random.choice([-1, 1])\n",
    "            X_drifted[col] = X_drifted[col] * scale_factor\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'multiplicative_shift',\n",
    "                'factor': scale_factor\n",
    "            })\n",
    "            \n",
    "        else:  # Add outliers\n",
    "            outlier_fraction = 0.1 * drift_threshold  # Up to 10% outliers\n",
    "            n_outliers = int(outlier_fraction * len(X_drifted))\n",
    "            outlier_indices = np.random.choice(X_drifted.index, n_outliers, replace=False)\n",
    "            # Make outliers 3-5x the original value\n",
    "            outlier_multiplier = 3 + 2 * drift_threshold\n",
    "            X_drifted.loc[outlier_indices, col] = X_drifted.loc[outlier_indices, col] * outlier_multiplier\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'outliers',\n",
    "                'n_outliers': n_outliers\n",
    "            })\n",
    "    \n",
    "    # Special handling for key Telco features\n",
    "    if 'tenure' in X_drifted.columns:\n",
    "        # Simulate customers staying longer (market shift)\n",
    "        tenure_increase = drift_threshold * 5  # Up to 5 months increase\n",
    "        X_drifted['tenure'] = X_drifted['tenure'] + np.random.normal(tenure_increase, 2, len(X_drifted))\n",
    "        X_drifted['tenure'] = X_drifted['tenure'].clip(lower=0)  # Ensure non-negative\n",
    "        drift_info['covariate_shifts'].append({\n",
    "            'feature': 'tenure',\n",
    "            'type': 'market_shift',\n",
    "            'increase_months': tenure_increase\n",
    "        })\n",
    "    \n",
    "    if 'MonthlyCharges' in X_drifted.columns:\n",
    "        # Simulate price inflation\n",
    "        inflation_rate = 1 + drift_threshold * 0.15  # Up to 15% increase\n",
    "        X_drifted['MonthlyCharges'] = X_drifted['MonthlyCharges'] * inflation_rate\n",
    "        drift_info['covariate_shifts'].append({\n",
    "            'feature': 'MonthlyCharges',\n",
    "            'type': 'inflation',\n",
    "            'rate': inflation_rate\n",
    "        })\n",
    "    \n",
    "    if 'TotalCharges' in X_drifted.columns:\n",
    "        # Recalculate TotalCharges based on drifted tenure and MonthlyCharges if both exist\n",
    "        if 'tenure' in X_drifted.columns and 'MonthlyCharges' in X_drifted.columns:\n",
    "            # TotalCharges should roughly be tenure * MonthlyCharges (with some variation)\n",
    "            X_drifted['TotalCharges'] = X_drifted['tenure'] * X_drifted['MonthlyCharges'] * \\\n",
    "                                       (1 + np.random.normal(0, 0.1 * drift_threshold, len(X_drifted)))\n",
    "            X_drifted['TotalCharges'] = X_drifted['TotalCharges'].clip(lower=0)\n",
    "    \n",
    "    # 2. Categorical Feature Drifts\n",
    "    for col in categorical_cols[:min(5, len(categorical_cols))]:  # Limit to avoid too many changes\n",
    "        if col not in X_drifted.columns:\n",
    "            continue\n",
    "        \n",
    "        unique_vals = X_drifted[col].unique()\n",
    "        if len(unique_vals) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Shift probability distribution towards different categories\n",
    "        # Example: More customers choosing 'Fiber optic' over 'DSL'\n",
    "        if col == 'InternetService' and 'Fiber optic' in unique_vals and 'DSL' in unique_vals:\n",
    "            mask_fiber = X_drifted[col] == 'DSL'\n",
    "            n_to_shift = int(len(X_drifted) * 0.2 * drift_threshold)\n",
    "            shift_indices = np.random.choice(X_drifted[mask_fiber].index[:n_to_shift], \n",
    "                                            size=min(n_to_shift, mask_fiber.sum()), \n",
    "                                            replace=False)\n",
    "            X_drifted.loc[shift_indices, col] = 'Fiber optic'\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'category_probability_shift',\n",
    "                'shift': f'DSL -> Fiber optic ({len(shift_indices)} samples)'\n",
    "            })\n",
    "        \n",
    "        # General categorical shift: change distribution\n",
    "        elif len(unique_vals) >= 2:\n",
    "            # Shift some samples from most common to least common category\n",
    "            value_counts = X_drifted[col].value_counts()\n",
    "            if len(value_counts) >= 2:\n",
    "                most_common = value_counts.index[0]\n",
    "                least_common = value_counts.index[-1]\n",
    "                \n",
    "                n_to_shift = int(len(X_drifted) * 0.15 * drift_threshold)\n",
    "                mask = X_drifted[col] == most_common\n",
    "                if mask.sum() > 0:\n",
    "                    shift_indices = np.random.choice(X_drifted[mask].index, \n",
    "                                                    size=min(n_to_shift, mask.sum()), \n",
    "                                                    replace=False)\n",
    "                    X_drifted.loc[shift_indices, col] = least_common\n",
    "                    drift_info['covariate_shifts'].append({\n",
    "                        'feature': col,\n",
    "                        'type': 'category_distribution_shift',\n",
    "                        'shift': f'{most_common} -> {least_common} ({len(shift_indices)} samples)'\n",
    "                    })\n",
    "    \n",
    "    # ============================================\n",
    "    # CONCEPT SHIFT: Changes to label relationships\n",
    "    # ============================================\n",
    "    \n",
    "    print(\"Applying concept shift...\")\n",
    "    \n",
    "    # 1. Reverse relationship for high-value customers\n",
    "    # Original: Higher charges -> more likely to churn\n",
    "    # Drifted: Higher charges -> less likely to churn (premium retention)\n",
    "    if 'MonthlyCharges' in X_drifted.columns:\n",
    "        high_charge_threshold = X_drifted['MonthlyCharges'].quantile(0.75)\n",
    "        high_charge_mask = X_drifted['MonthlyCharges'] > high_charge_threshold\n",
    "        \n",
    "        # Reverse churn probability for high-charge customers\n",
    "        n_to_flip = int(high_charge_mask.sum() * 0.3 * drift_threshold)\n",
    "        flip_indices = np.random.choice(X_drifted[high_charge_mask].index, \n",
    "                                       size=min(n_to_flip, high_charge_mask.sum()), \n",
    "                                       replace=False)\n",
    "        y_drifted.loc[flip_indices] = 1 - y_drifted.loc[flip_indices]  # Flip labels\n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'high_value_retention',\n",
    "            'description': 'High MonthlyCharges customers now less likely to churn',\n",
    "            'n_samples': len(flip_indices)\n",
    "        })\n",
    "    \n",
    "    # 2. Change relationship with tenure\n",
    "    # Original: Longer tenure -> less likely to churn\n",
    "    # Drifted: Very long tenure customers may become more likely to churn (market fatigue)\n",
    "    if 'tenure' in X_drifted.columns:\n",
    "        long_tenure_threshold = X_drifted['tenure'].quantile(0.8)\n",
    "        long_tenure_mask = (X_drifted['tenure'] > long_tenure_threshold) & (y_drifted == 0)\n",
    "        \n",
    "        n_to_flip = int(long_tenure_mask.sum() * 0.2 * drift_threshold)\n",
    "        flip_indices = np.random.choice(X_drifted[long_tenure_mask].index, \n",
    "                                       size=min(n_to_flip, long_tenure_mask.sum()), \n",
    "                                       replace=False)\n",
    "        y_drifted.loc[flip_indices] = 1  # Flip to churn\n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'tenure_fatigue',\n",
    "            'description': 'Very long tenure customers more likely to churn',\n",
    "            'n_samples': len(flip_indices)\n",
    "        })\n",
    "    \n",
    "    # 3. Change relationship with service engagement\n",
    "    # Original: More services -> less likely to churn\n",
    "    # Drifted: More services -> more likely to churn (complexity/overwhelm)\n",
    "    if 'service_engagement' in X_drifted.columns:\n",
    "        high_engagement_threshold = X_drifted['service_engagement'].quantile(0.7)\n",
    "        high_engagement_mask = (X_drifted['service_engagement'] > high_engagement_threshold) & (y_drifted == 0)\n",
    "        \n",
    "        n_to_flip = int(high_engagement_mask.sum() * 0.25 * drift_threshold)\n",
    "        flip_indices = np.random.choice(X_drifted[high_engagement_mask].index, \n",
    "                                       size=min(n_to_flip, high_engagement_mask.sum()), \n",
    "                                       replace=False)\n",
    "        y_drifted.loc[flip_indices] = 1  # Flip to churn\n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'service_overwhelm',\n",
    "            'description': 'High service engagement customers more likely to churn',\n",
    "            'n_samples': len(flip_indices)\n",
    "        })\n",
    "    \n",
    "    # 4. Contract type relationship change\n",
    "    # Original: Longer contracts -> less churn\n",
    "    # Drifted: Some contract types become less effective\n",
    "    if 'Contract' in X_drifted.columns:\n",
    "        # Make \"Two year\" contract customers more likely to churn (regret/commitment issues)\n",
    "        two_year_mask = (X_drifted['Contract'] == 'Two year') & (y_drifted == 0)\n",
    "        n_to_flip = int(two_year_mask.sum() * 0.15 * drift_threshold)\n",
    "        flip_indices = np.random.choice(X_drifted[two_year_mask].index, \n",
    "                                       size=min(n_to_flip, two_year_mask.sum()), \n",
    "                                       replace=False)\n",
    "        y_drifted.loc[flip_indices] = 1\n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'contract_regret',\n",
    "            'description': 'Two year contract customers more likely to churn',\n",
    "            'n_samples': len(flip_indices)\n",
    "        })\n",
    "    \n",
    "    # 5. Overall base rate shift (global concept shift)\n",
    "    # Shift the overall churn rate\n",
    "    base_rate_shift = drift_threshold * 0.1  # Up to 10 percentage points\n",
    "    if base_rate_shift > 0:\n",
    "        current_churn_rate = y_drifted.mean()\n",
    "        target_churn_rate = min(1.0, current_churn_rate + base_rate_shift)\n",
    "        \n",
    "        # Adjust labels to match target rate\n",
    "        n_current_churn = y_drifted.sum()\n",
    "        n_target_churn = int(len(y_drifted) * target_churn_rate)\n",
    "        n_to_change = abs(n_target_churn - n_current_churn)\n",
    "        \n",
    "        if n_target_churn > n_current_churn:\n",
    "            # Need more churners - flip some non-churners\n",
    "            non_churners = X_drifted[y_drifted == 0].index\n",
    "            flip_indices = np.random.choice(non_churners, \n",
    "                                           size=min(n_to_change, len(non_churners)), \n",
    "                                           replace=False)\n",
    "            y_drifted.loc[flip_indices] = 1\n",
    "        else:\n",
    "            # Need fewer churners - flip some churners\n",
    "            churners = X_drifted[y_drifted == 1].index\n",
    "            flip_indices = np.random.choice(churners, \n",
    "                                           size=min(n_to_change, len(churners)), \n",
    "                                           replace=False)\n",
    "            y_drifted.loc[flip_indices] = 0\n",
    "        \n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'base_rate_shift',\n",
    "            'description': f'Overall churn rate shifted from {current_churn_rate:.3f} to {target_churn_rate:.3f}',\n",
    "            'shift_amount': base_rate_shift\n",
    "        })\n",
    "    \n",
    "    print(f\"âœ“ Applied {len(drift_info['covariate_shifts'])} covariate shifts\")\n",
    "    print(f\"âœ“ Applied {len(drift_info['concept_shifts'])} concept shifts\")\n",
    "    print(f\"Final churn rate: {y_drifted.mean():.3f} (original: {y.mean():.3f})\")\n",
    "    \n",
    "    return X_drifted, y_drifted, drift_info\n",
    "\n",
    "\n",
    "def create_drift_visualizations(X_original, y_original, X_drifted, y_drifted, \n",
    "                                metrics_original, metrics_drifted, drift_threshold, \n",
    "                                save_dir='drift_plots'):\n",
    "    \"\"\"\n",
    "    Create visualization plots for drift analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_original : pd.DataFrame\n",
    "        Original feature data\n",
    "    y_original : pd.Series\n",
    "        Original target labels\n",
    "    X_drifted : pd.DataFrame\n",
    "        Drifted feature data\n",
    "    y_drifted : pd.Series\n",
    "        Drifted target labels\n",
    "    metrics_original : dict\n",
    "        Metrics on original data\n",
    "    metrics_drifted : dict\n",
    "        Metrics on drifted data\n",
    "    drift_threshold : float\n",
    "        Drift threshold used\n",
    "    save_dir : str\n",
    "        Directory to save plots\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    plot_paths : list\n",
    "        List of paths to saved plot files\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from sklearn.metrics import roc_curve\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plot_paths = []\n",
    "    \n",
    "    # 1. ROC Curve Comparison\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Get predictions for ROC curves (assuming they're passed or calculated)\n",
    "    # For now, we'll create a placeholder - in practice, predictions should be passed\n",
    "    try:\n",
    "        if 'y_prob_original' in metrics_original and 'y_prob_drifted' in metrics_drifted:\n",
    "            fpr_orig, tpr_orig, _ = roc_curve(y_original, metrics_original['y_prob_original'])\n",
    "            fpr_drift, tpr_drift, _ = roc_curve(y_drifted, metrics_drifted['y_prob_drifted'])\n",
    "            \n",
    "            ax.plot(fpr_orig, tpr_orig, label=f'Original (AUC={metrics_original[\"auc\"]:.3f})', linewidth=2)\n",
    "            ax.plot(fpr_drift, tpr_drift, label=f'Drifted (AUC={metrics_drifted[\"auc\"]:.3f})', linewidth=2)\n",
    "            ax.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1)\n",
    "            ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "            ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "            ax.set_title(f'ROC Curve Comparison (Drift Threshold: {drift_threshold})', fontsize=14, fontweight='bold')\n",
    "            ax.legend(loc='lower right', fontsize=10)\n",
    "            ax.grid(alpha=0.3)\n",
    "    except:\n",
    "        pass  # Skip if predictions not available\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    roc_path = os.path.join(save_dir, 'roc_curve_comparison.png')\n",
    "    plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plot_paths.append(roc_path)\n",
    "    \n",
    "    # 2. Metric Degradation Bar Chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "    original_vals = [metrics_original.get(m, 0) for m in metrics_to_plot]\n",
    "    drifted_vals = [metrics_drifted.get(m, 0) for m in metrics_to_plot]\n",
    "    degradations = [orig - drift for orig, drift in zip(original_vals, drifted_vals)]\n",
    "    \n",
    "    x = np.arange(len(metrics_to_plot))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, original_vals, width, label='Original', alpha=0.8, color='#2ecc71')\n",
    "    bars2 = ax.bar(x + width/2, drifted_vals, width, label='Drifted', alpha=0.8, color='#e74c3c')\n",
    "    \n",
    "    # Add degradation percentages on bars\n",
    "    for i, (orig, drift, deg) in enumerate(zip(original_vals, drifted_vals, degradations)):\n",
    "        if orig > 0:\n",
    "            pct = (deg / orig) * 100\n",
    "            ax.text(i, max(orig, drift) + 0.02, f'{pct:.1f}%', \n",
    "                   ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Metrics', fontsize=12)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title(f'Model Performance Degradation (Drift Threshold: {drift_threshold})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics_to_plot, fontsize=11)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    metric_path = os.path.join(save_dir, 'metric_degradation.png')\n",
    "    plt.savefig(metric_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plot_paths.append(metric_path)\n",
    "    \n",
    "    # 3. Feature Distribution Comparison (for key numeric features)\n",
    "    numeric_cols = X_original.select_dtypes(include=[np.number]).columns[:6]  # Top 6 numeric features\n",
    "    \n",
    "    if len(numeric_cols) > 0:\n",
    "        n_cols = min(3, len(numeric_cols))\n",
    "        n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "        axes = axes.flatten() if len(numeric_cols) > 1 else [axes]\n",
    "        \n",
    "        for idx, col in enumerate(numeric_cols):\n",
    "            if idx >= len(axes):\n",
    "                break\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            ax.hist(X_original[col].dropna(), bins=30, alpha=0.6, label='Original', \n",
    "                   color='#2ecc71', density=True)\n",
    "            ax.hist(X_drifted[col].dropna(), bins=30, alpha=0.6, label='Drifted', \n",
    "                   color='#e74c3c', density=True)\n",
    "            ax.set_xlabel(col, fontsize=10)\n",
    "            ax.set_ylabel('Density', fontsize=10)\n",
    "            ax.set_title(f'{col} Distribution', fontsize=11, fontweight='bold')\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(alpha=0.3)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for idx in range(len(numeric_cols), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Feature Distribution Drift (Drift Threshold: {drift_threshold})', \n",
    "                    fontsize=14, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        dist_path = os.path.join(save_dir, 'feature_distributions.png')\n",
    "        plt.savefig(dist_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plot_paths.append(dist_path)\n",
    "    \n",
    "    # 4. Churn Rate Comparison\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    churn_original = y_original.mean()\n",
    "    churn_drifted = y_drifted.mean()\n",
    "    \n",
    "    categories = ['Original', 'Drifted']\n",
    "    churn_rates = [churn_original, churn_drifted]\n",
    "    colors = ['#2ecc71', '#e74c3c']\n",
    "    \n",
    "    bars = ax.bar(categories, churn_rates, color=colors, alpha=0.8, width=0.6)\n",
    "    ax.set_ylabel('Churn Rate', fontsize=12)\n",
    "    ax.set_title(f'Churn Rate Shift (Drift Threshold: {drift_threshold})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_ylim([0, max(churn_rates) * 1.2])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, rate in zip(bars, churn_rates):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{rate:.3f}',\n",
    "               ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Add change annotation\n",
    "    change = churn_drifted - churn_original\n",
    "    change_pct = (change / churn_original) * 100 if churn_original > 0 else 0\n",
    "    ax.annotate(f'Change: {change:+.3f} ({change_pct:+.1f}%)',\n",
    "               xy=(1, churn_drifted), xytext=(1.3, churn_drifted + 0.05),\n",
    "               arrowprops=dict(arrowstyle='->', color='black', lw=1.5),\n",
    "               fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    churn_path = os.path.join(save_dir, 'churn_rate_shift.png')\n",
    "    plt.savefig(churn_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plot_paths.append(churn_path)\n",
    "    \n",
    "    return plot_paths\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a7dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      "\n",
      "============================================================\n",
      "DRIFT SIMULATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Covariate Shifts Applied: 15\n",
      "  - SeniorCitizen: mean_shift\n",
      "  - tenure: variance_increase\n",
      "  - MonthlyCharges: multiplicative_shift\n",
      "  - TotalCharges: outliers\n",
      "  - monthly_total_ratio: mean_shift\n",
      "  ... and 10 more\n",
      "\n",
      "Concept Shifts Applied: 5\n",
      "  - high_value_retention: High MonthlyCharges customers now less likely to churn\n",
      "  - tenure_fatigue: Very long tenure customers more likely to churn\n",
      "  - service_overwhelm: High service engagement customers more likely to churn\n",
      "  - contract_regret: Two year contract customers more likely to churn\n",
      "  - base_rate_shift: Overall churn rate shifted from 0.326 to 0.376\n",
      "\n",
      "============================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "\n",
      "Metric                    Original    Drifted     Degradation\n",
      "-----------------------------------------------------------------\n",
      "accuracy               0.7935      0.6920     0.1015 ( 12.8%)\n",
      "precision              0.5887      0.5906    -0.0019 ( -0.3%)\n",
      "recall                 0.7292      0.5337     0.1955 ( 26.8%)\n",
      "f1                     0.6515      0.5607     0.0908 ( 13.9%)\n",
      "auc                    0.8571      0.7087     0.1484 ( 17.3%)\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:25:58 INFO mlflow.tracking.fluent: Experiment with name 'telco-drift-analysis' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging drifted data to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging baseline metrics...\n",
      "Logging drifted metrics...\n",
      "Logging degradation metrics...\n",
      "Creating visualizations...\n",
      "  âœ“ Logged drift_plots\\roc_curve_comparison.png\n",
      "  âœ“ Logged drift_plots\\metric_degradation.png\n",
      "  âœ“ Logged drift_plots\\feature_distributions.png\n",
      "  âœ“ Logged drift_plots\\churn_rate_shift.png\n",
      "\n",
      "âœ“ MLflow run completed. View at: http://localhost:5000\n",
      "Run ID: f072551870b84b68804a0f125fdc5ed4\n",
      "ðŸƒ View run drift_threshold_0.5 at: http://localhost:5000/#/experiments/2/runs/f072551870b84b68804a0f125fdc5ed4\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "# Example: Generate drifted data and evaluate model performance with MLflow logging\n",
    "\n",
    "drift_threshold = 0.5\n",
    "\n",
    "# Generate drifted data with moderate drift\n",
    "X_drifted, y_drifted, drift_info = simulate_drifted_data(X, y, drift_threshold=drift_threshold, random_state=42)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DRIFT SIMULATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nCovariate Shifts Applied: {len(drift_info['covariate_shifts'])}\")\n",
    "for shift in drift_info['covariate_shifts'][:5]:  # Show first 5\n",
    "    print(f\"  - {shift.get('feature', 'unknown')}: {shift.get('type', 'unknown')}\")\n",
    "if len(drift_info['covariate_shifts']) > 5:\n",
    "    print(f\"  ... and {len(drift_info['covariate_shifts']) - 5} more\")\n",
    "\n",
    "print(f\"\\nConcept Shifts Applied: {len(drift_info['concept_shifts'])}\")\n",
    "for shift in drift_info['concept_shifts']:\n",
    "    print(f\"  - {shift.get('type', 'unknown')}: {shift.get('description', '')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Evaluate on original test set (baseline)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get predictions on original test set\n",
    "y_pred_original = pipeline.predict(X_test)\n",
    "y_prob_original = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Get predictions on drifted data (using same test size for comparison)\n",
    "_, X_test_drifted, _, y_test_drifted = train_test_split(X_drifted, y_drifted, test_size=0.2, random_state=42)\n",
    "\n",
    "y_pred_drifted = pipeline.predict(X_test_drifted)\n",
    "y_prob_drifted = pipeline.predict_proba(X_test_drifted)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "metrics_original = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_original),\n",
    "    'precision': precision_score(y_test, y_pred_original),\n",
    "    'recall': recall_score(y_test, y_pred_original),\n",
    "    'f1': f1_score(y_test, y_pred_original),\n",
    "    'auc': roc_auc_score(y_test, y_prob_original),\n",
    "    'y_prob_original': y_prob_original\n",
    "}\n",
    "\n",
    "metrics_drifted = {\n",
    "    'accuracy': accuracy_score(y_test_drifted, y_pred_drifted),\n",
    "    'precision': precision_score(y_test_drifted, y_pred_drifted),\n",
    "    'recall': recall_score(y_test_drifted, y_pred_drifted),\n",
    "    'f1': f1_score(y_test_drifted, y_pred_drifted),\n",
    "    'auc': roc_auc_score(y_test_drifted, y_prob_drifted),\n",
    "    'y_prob_drifted': y_prob_drifted\n",
    "}\n",
    "\n",
    "# Calculate degradation metrics\n",
    "degradation_metrics = {}\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc']:\n",
    "    orig_val = metrics_original[metric]\n",
    "    drift_val = metrics_drifted[metric]\n",
    "    degradation = orig_val - drift_val\n",
    "    degradation_pct = (degradation / orig_val) * 100 if orig_val > 0 else 0\n",
    "    degradation_metrics[f'{metric}_degradation'] = degradation\n",
    "    degradation_metrics[f'{metric}_degradation_pct'] = degradation_pct\n",
    "\n",
    "# Display comparison\n",
    "print(\"\\nMetric                    Original    Drifted     Degradation\")\n",
    "print(\"-\" * 65)\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc']:\n",
    "    original_val = metrics_original[metric]\n",
    "    drifted_val = metrics_drifted[metric]\n",
    "    degradation = degradation_metrics[f'{metric}_degradation']\n",
    "    degradation_pct = degradation_metrics[f'{metric}_degradation_pct']\n",
    "    print(f\"{metric:20s} {original_val:8.4f}    {drifted_val:8.4f}    {degradation:7.4f} ({degradation_pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# MLflow Logging\n",
    "# ============================================\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"telco-drift-analysis\")\n",
    "\n",
    "with mlflow.start_run(run_name=f'drift_threshold_{drift_threshold}'):\n",
    "    # Log drift threshold parameter\n",
    "    mlflow.log_param('drift_threshold', drift_threshold)\n",
    "    mlflow.log_param('n_covariate_shifts', len(drift_info['covariate_shifts']))\n",
    "    mlflow.log_param('n_concept_shifts', len(drift_info['concept_shifts']))\n",
    "    \n",
    "    # Log data using mlflow.data module\n",
    "    print(\"\\nLogging drifted data to MLflow...\")\n",
    "    \n",
    "    # Combine X and y for data logging\n",
    "    X_test_with_target = X_test.copy()\n",
    "    X_test_with_target['Churn'] = y_test\n",
    "    baseline_dataset = mlflow.data.from_pandas(X_test_with_target)\n",
    "    mlflow.log_input(baseline_dataset, context='baseline_test')\n",
    "    \n",
    "    X_drifted_with_target = X_test_drifted.copy()\n",
    "    X_drifted_with_target['Churn'] = y_test_drifted\n",
    "    drifted_dataset = mlflow.data.from_pandas(X_drifted_with_target)\n",
    "    mlflow.log_input(drifted_dataset, context='drifted_test')\n",
    "    \n",
    "    # Log baseline metrics\n",
    "    print(\"Logging baseline metrics...\")\n",
    "    for metric_name, metric_value in metrics_original.items():\n",
    "        if metric_name != 'y_prob_original':  # Skip prediction arrays\n",
    "            mlflow.log_metric(f'baseline_{metric_name}', metric_value)\n",
    "    \n",
    "    # Log drifted metrics\n",
    "    print(\"Logging drifted metrics...\")\n",
    "    for metric_name, metric_value in metrics_drifted.items():\n",
    "        if metric_name != 'y_prob_drifted':  # Skip prediction arrays\n",
    "            mlflow.log_metric(f'drifted_{metric_name}', metric_value)\n",
    "    \n",
    "    # Log degradation metrics\n",
    "    print(\"Logging degradation metrics...\")\n",
    "    for metric_name, metric_value in degradation_metrics.items():\n",
    "        mlflow.log_metric(metric_name, metric_value)\n",
    "    \n",
    "    # Log data statistics\n",
    "    mlflow.log_metric('baseline_churn_rate', y_test.mean())\n",
    "    mlflow.log_metric('drifted_churn_rate', y_test_drifted.mean())\n",
    "    mlflow.log_metric('churn_rate_change', y_test_drifted.mean() - y_test.mean())\n",
    "    mlflow.log_metric('baseline_data_size', len(X_test))\n",
    "    mlflow.log_metric('drifted_data_size', len(X_test_drifted))\n",
    "    \n",
    "    # Create and log visualizations\n",
    "    print(\"Creating visualizations...\")\n",
    "    plot_paths = create_drift_visualizations(\n",
    "        X_test, y_test, X_test_drifted, y_test_drifted,\n",
    "        metrics_original, metrics_drifted, drift_threshold,\n",
    "        save_dir='drift_plots'\n",
    "    )\n",
    "    \n",
    "    for plot_path in plot_paths:\n",
    "        mlflow.log_artifact(plot_path, artifact_path='plots')\n",
    "        print(f\"  âœ“ Logged {plot_path}\")\n",
    "    \n",
    "    # Log drift info as JSON artifact\n",
    "    import json\n",
    "    drift_info_json = json.dumps(drift_info, indent=2, default=str)\n",
    "    with open('drift_info.json', 'w') as f:\n",
    "        f.write(drift_info_json)\n",
    "    mlflow.log_artifact('drift_info.json', artifact_path='drift_info')\n",
    "    \n",
    "    print(f\"\\nâœ“ MLflow run completed. View at: {mlflow.get_tracking_uri()}\")\n",
    "    print(f\"Run ID: {mlflow.active_run().info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940e6df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:26:02 INFO mlflow.tracking.fluent: Experiment with name 'telco-drift-threshold-analysis' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model performance across different drift thresholds with MLflow logging...\n",
      "\n",
      "\n",
      "Testing drift threshold: 0.00\n",
      "Simulating combined drift with threshold: 0.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.7949 (â†“-0.2%)\n",
      "  F1-Score: 0.6488 (â†“0.4%)\n",
      "  AUC: 0.8578 (â†“-0.1%)\n",
      "ðŸƒ View run threshold_0.0 at: http://localhost:5000/#/experiments/3/runs/e95f94bd232a474facfe475303c287db\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/3\n",
      "\n",
      "Testing drift threshold: 0.25\n",
      "Simulating combined drift with threshold: 0.25\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.7388 (â†“6.9%)\n",
      "  F1-Score: 0.6060 (â†“7.0%)\n",
      "  AUC: 0.7579 (â†“11.6%)\n",
      "ðŸƒ View run threshold_0.25 at: http://localhost:5000/#/experiments/3/runs/25b2aaf737a84e04bb35273c219273da\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/3\n",
      "\n",
      "Testing drift threshold: 0.50\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.6920 (â†“12.8%)\n",
      "  F1-Score: 0.5607 (â†“13.9%)\n",
      "  AUC: 0.7087 (â†“17.3%)\n",
      "ðŸƒ View run threshold_0.5 at: http://localhost:5000/#/experiments/3/runs/a3e0a82e7c6a44c5994eef554863f5ca\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/3\n",
      "\n",
      "Testing drift threshold: 0.75\n",
      "Simulating combined drift with threshold: 0.75\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.430 (original: 0.265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.6444 (â†“18.8%)\n",
      "  F1-Score: 0.5233 (â†“19.7%)\n",
      "  AUC: 0.6649 (â†“22.4%)\n",
      "ðŸƒ View run threshold_0.75 at: http://localhost:5000/#/experiments/3/runs/95aba6080a1a43ac99638d0e38a675c3\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/3\n",
      "\n",
      "Testing drift threshold: 1.00\n",
      "Simulating combined drift with threshold: 1.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.478 (original: 0.265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.6061 (â†“23.6%)\n",
      "  F1-Score: 0.5203 (â†“20.1%)\n",
      "  AUC: 0.6293 (â†“26.6%)\n",
      "ðŸƒ View run threshold_1.0 at: http://localhost:5000/#/experiments/3/runs/cd173d038c364296871a59b1f82b90a1\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/3\n",
      "\n",
      "Creating summary visualization...\n",
      "âœ“ Logged summary plot: drift_threshold_summary.png\n",
      "ðŸƒ View run summary at: http://localhost:5000/#/experiments/3/runs/24100ae9bb584dd4ae5709bf2985b650\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/3\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE DEGRADATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Baseline Performance:\n",
      "  Accuracy: 0.7935\n",
      "  F1-Score: 0.6515\n",
      "  AUC: 0.8571\n",
      "\n",
      "Threshold    Accuracy     F1-Score     AUC          Acc Deg (%)  AUC Deg (%)  F1 Deg (%)  \n",
      "--------------------------------------------------------------------------------\n",
      "0.00         0.7949       0.6488       0.8578       -0.18        -0.07        0.41        \n",
      "0.25         0.7388       0.6060       0.7579       6.89         11.58        6.98        \n",
      "0.50         0.6920       0.5607       0.7087       12.79        17.32        13.93       \n",
      "0.75         0.6444       0.5233       0.6649       18.78        22.43        19.68       \n",
      "1.00         0.6061       0.5203       0.6293       23.61        26.58        20.14       \n",
      "\n",
      " All results logged to MLflow experiment: telco-drift-threshold-analysis\n"
     ]
    }
   ],
   "source": [
    "# Test different drift thresholds with MLflow logging\n",
    "\n",
    "print(\"Testing model performance across different drift thresholds with MLflow logging...\\n\")\n",
    "\n",
    "drift_thresholds = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "results = []\n",
    "\n",
    "# Baseline performance on original test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_pred_baseline = pipeline.predict(X_test)\n",
    "y_prob_baseline = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "baseline_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_baseline),\n",
    "    'precision': precision_score(y_test, y_pred_baseline),\n",
    "    'recall': recall_score(y_test, y_pred_baseline),\n",
    "    'f1': f1_score(y_test, y_pred_baseline),\n",
    "    'auc': roc_auc_score(y_test, y_prob_baseline)\n",
    "}\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"telco-drift-threshold-analysis\")\n",
    "\n",
    "# Store summary plot path for later logging\n",
    "summary_plot_path = None\n",
    "\n",
    "for threshold in drift_thresholds:\n",
    "    print(f\"\\nTesting drift threshold: {threshold:.2f}\")\n",
    "    \n",
    "    # Create a run for each threshold\n",
    "    with mlflow.start_run(run_name=f'threshold_{threshold}'):\n",
    "        X_drifted, y_drifted, drift_info = simulate_drifted_data(X, y, drift_threshold=threshold, random_state=42)\n",
    "        \n",
    "        # Use same test size\n",
    "        _, X_test_drifted, _, y_test_drifted = train_test_split(X_drifted, y_drifted, test_size=0.2, random_state=42)\n",
    "        \n",
    "        y_pred_drifted = pipeline.predict(X_test_drifted)\n",
    "        y_prob_drifted = pipeline.predict_proba(X_test_drifted)[:, 1]\n",
    "        \n",
    "        # Calculate all metrics\n",
    "        metrics = {\n",
    "            'threshold': threshold,\n",
    "            'accuracy': accuracy_score(y_test_drifted, y_pred_drifted),\n",
    "            'precision': precision_score(y_test_drifted, y_pred_drifted),\n",
    "            'recall': recall_score(y_test_drifted, y_pred_drifted),\n",
    "            'f1': f1_score(y_test_drifted, y_pred_drifted),\n",
    "            'auc': roc_auc_score(y_test_drifted, y_prob_drifted),\n",
    "            'churn_rate': y_test_drifted.mean()\n",
    "        }\n",
    "        \n",
    "        # Calculate degradation metrics\n",
    "        degradation_metrics = {}\n",
    "        for metric_name in ['accuracy', 'precision', 'recall', 'f1', 'auc']:\n",
    "            baseline_val = baseline_metrics[metric_name]\n",
    "            drifted_val = metrics[metric_name]\n",
    "            degradation = baseline_val - drifted_val\n",
    "            degradation_pct = (degradation / baseline_val) * 100 if baseline_val > 0 else 0\n",
    "            degradation_metrics[f'{metric_name}_degradation'] = degradation\n",
    "            degradation_metrics[f'{metric_name}_degradation_pct'] = degradation_pct\n",
    "        \n",
    "        results.append({**metrics, **degradation_metrics})\n",
    "        \n",
    "        # Log to MLflow\n",
    "        mlflow.log_param('drift_threshold', threshold)\n",
    "        mlflow.log_param('n_covariate_shifts', len(drift_info['covariate_shifts']))\n",
    "        mlflow.log_param('n_concept_shifts', len(drift_info['concept_shifts']))\n",
    "        \n",
    "        # Log data\n",
    "        X_test_with_target = X_test_drifted.copy()\n",
    "        X_test_with_target['Churn'] = y_test_drifted\n",
    "        drifted_dataset = mlflow.data.from_pandas(X_test_with_target)\n",
    "        mlflow.log_input(drifted_dataset, context='drifted_test')\n",
    "        \n",
    "        # Log all metrics\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            if metric_name != 'threshold':\n",
    "                mlflow.log_metric(metric_name, metric_value)\n",
    "        \n",
    "        # Log degradation metrics\n",
    "        for metric_name, metric_value in degradation_metrics.items():\n",
    "            mlflow.log_metric(metric_name, metric_value)\n",
    "        \n",
    "        # Log additional statistics\n",
    "        mlflow.log_metric('churn_rate_change', y_test_drifted.mean() - y_test.mean())\n",
    "        \n",
    "        # Calculate degradation for display\n",
    "        acc_degradation = degradation_metrics['accuracy_degradation_pct']\n",
    "        auc_degradation = degradation_metrics['auc_degradation_pct']\n",
    "        f1_degradation = degradation_metrics['f1_degradation_pct']\n",
    "        \n",
    "        print(f\"  Accuracy: {metrics['accuracy']:.4f} (â†“{acc_degradation:.1f}%)\")\n",
    "        print(f\"  F1-Score: {metrics['f1']:.4f} (â†“{f1_degradation:.1f}%)\")\n",
    "        print(f\"  AUC: {metrics['auc']:.4f} (â†“{auc_degradation:.1f}%)\")\n",
    "\n",
    "# Create summary visualization\n",
    "print(\"\\nCreating summary visualization...\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Accuracy degradation across thresholds\n",
    "ax1 = axes[0, 0]\n",
    "thresholds = [r['threshold'] for r in results]\n",
    "accuracies = [r['accuracy'] for r in results]\n",
    "acc_degradations = [r['accuracy_degradation_pct'] for r in results]\n",
    "ax1.plot(thresholds, accuracies, 'o-', linewidth=2, markersize=8, label='Accuracy', color='#3498db')\n",
    "ax1.axhline(y=baseline_metrics['accuracy'], color='#2ecc71', linestyle='--', linewidth=2, label='Baseline')\n",
    "ax1.set_xlabel('Drift Threshold', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_title('Accuracy vs Drift Threshold', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# 2. AUC degradation across thresholds\n",
    "ax2 = axes[0, 1]\n",
    "aucs = [r['auc'] for r in results]\n",
    "auc_degradations = [r['auc_degradation_pct'] for r in results]\n",
    "ax2.plot(thresholds, aucs, 'o-', linewidth=2, markersize=8, label='AUC', color='#9b59b6')\n",
    "ax2.axhline(y=baseline_metrics['auc'], color='#2ecc71', linestyle='--', linewidth=2, label='Baseline')\n",
    "ax2.set_xlabel('Drift Threshold', fontsize=12)\n",
    "ax2.set_ylabel('AUC', fontsize=12)\n",
    "ax2.set_title('AUC vs Drift Threshold', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# 3. F1 degradation across thresholds\n",
    "ax3 = axes[1, 0]\n",
    "f1_scores = [r['f1'] for r in results]\n",
    "f1_degradations = [r['f1_degradation_pct'] for r in results]\n",
    "ax3.plot(thresholds, f1_scores, 'o-', linewidth=2, markersize=8, label='F1-Score', color='#e67e22')\n",
    "ax3.axhline(y=baseline_metrics['f1'], color='#2ecc71', linestyle='--', linewidth=2, label='Baseline')\n",
    "ax3.set_xlabel('Drift Threshold', fontsize=12)\n",
    "ax3.set_ylabel('F1-Score', fontsize=12)\n",
    "ax3.set_title('F1-Score vs Drift Threshold', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. Percentage degradation across thresholds\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(thresholds, acc_degradations, 'o-', linewidth=2, markersize=8, label='Accuracy', color='#3498db')\n",
    "ax4.plot(thresholds, auc_degradations, 's-', linewidth=2, markersize=8, label='AUC', color='#9b59b6')\n",
    "ax4.plot(thresholds, f1_degradations, '^-', linewidth=2, markersize=8, label='F1-Score', color='#e67e22')\n",
    "ax4.set_xlabel('Drift Threshold', fontsize=12)\n",
    "ax4.set_ylabel('Degradation (%)', fontsize=12)\n",
    "ax4.set_title('Performance Degradation vs Drift Threshold', fontsize=14, fontweight='bold')\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.suptitle('Model Performance Across Drift Thresholds', fontsize=16, fontweight='bold', y=1.0)\n",
    "plt.tight_layout()\n",
    "summary_plot_path = 'drift_threshold_summary.png'\n",
    "plt.savefig(summary_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Log summary plot to a final summary run\n",
    "with mlflow.start_run(run_name='summary'):\n",
    "    mlflow.log_param('baseline_accuracy', baseline_metrics['accuracy'])\n",
    "    mlflow.log_param('baseline_f1', baseline_metrics['f1'])\n",
    "    mlflow.log_param('baseline_auc', baseline_metrics['auc'])\n",
    "    mlflow.log_artifact(summary_plot_path, artifact_path='plots')\n",
    "    print(f\"âœ“ Logged summary plot: {summary_plot_path}\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE DEGRADATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBaseline Performance:\")\n",
    "print(f\"  Accuracy: {baseline_metrics['accuracy']:.4f}\")\n",
    "print(f\"  F1-Score: {baseline_metrics['f1']:.4f}\")\n",
    "print(f\"  AUC: {baseline_metrics['auc']:.4f}\")\n",
    "\n",
    "print(f\"\\n{'Threshold':<12} {'Accuracy':<12} {'F1-Score':<12} {'AUC':<12} {'Acc Deg (%)':<12} {'AUC Deg (%)':<12} {'F1 Deg (%)':<12}\")\n",
    "print(\"-\" * 80)\n",
    "for r in results:\n",
    "    print(f\"{r['threshold']:<12.2f} {r['accuracy']:<12.4f} {r['f1']:<12.4f} {r['auc']:<12.4f} \"\n",
    "          f\"{r['accuracy_degradation_pct']:<12.2f} {r['auc_degradation_pct']:<12.2f} {r['f1_degradation_pct']:<12.2f}\")\n",
    "\n",
    "print(f\"\\n All results logged to MLflow experiment: telco-drift-threshold-analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f162fed",
   "metadata": {},
   "source": [
    "### Drift analysis\n",
    "\n",
    "We take our random forest model and subject it to a drifted dataset based on the original. The drifted dataset has the same columns and data that the baseline model was trained on. We subject the model to varied thresholds of drift (from 0 - 1). The drift simulation is intended to simulate model degradation across scenarios in increasing order of magnitude; i.e. the aggressiveness increases as the threshold increases.\n",
    "\n",
    "We note, that as expected - the baseline model suffers as a result of drift, losing 22.8% of its accuracy at when the threshold is set to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad47fe1",
   "metadata": {},
   "source": [
    "## Interventions after drift is detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ade1d",
   "metadata": {},
   "source": [
    "### DDLA intervention for retraining\n",
    "\n",
    "Limitations: This is an implementation based on the approach used by Dong et al. (2024) for DDLAs that identify regions for low accuracy within a model. The authors use active learning - where predictions are passed to human annotators for ground truth. In our case, due to the limitations of our dataset and the lack of any domain experts - we need to assume that \"generated\" labels for annotators are ground truths - which do not accurately represent the authors' implementation of this algorithm. \n",
    "\n",
    "Furthermore, the approach itself appears appears to first inform deployments of harmful drift - if detected, and then further inform them of these low accuracy regions for selective retraining of the model. Selective retraining itself is not very clear (to me) in the paper - so implemtation will differ from the actual implementation.\n",
    "\n",
    "The source [code](https://github.com/SiSijie/data-drift-in-ML/blob/main/examples/Human-activaty_test.ipynb) is embedded in this cell.\n",
    "\n",
    "Update: On inspecting the example in the authors' notebook, it appears that they are in fact generating their own labels as opposed to using an actual active learning enabled pipeline. It seems the active learning bit is a theory rather than an implementation. This makes our job easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f84087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_ddlas_decision_tree(trained_pipeline, X_test, y_test, max_depth_range=(3, 10), min_samples_leaf_range=(0.01, 0.05), random_state=42):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    print(\"Identifying DDLAs with tree based approach\")\n",
    "    \n",
    "    # Step 1: Get model predictions and overall accuracy\n",
    "    y_pred = trained_pipeline.predict(X_test)\n",
    "    y_prob = trained_pipeline.predict_proba(X_test)[:, 1]\n",
    "    overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Overall model accuracy: {overall_accuracy:.4f}\")\n",
    "    \n",
    "    # Step 2: Re-label predictions (0=correct, 1=incorrect), essentially same as paper\n",
    "    correct_predictions = (y_pred == y_test).astype(int)\n",
    "    y_relabeled = 1 - correct_predictions\n",
    "    \n",
    "    incorrect_rate = y_relabeled.mean()\n",
    "    print(f\"  Overall incorrect prediction rate: {incorrect_rate:.4f}\")\n",
    "    \n",
    "    # Step 3: Get preprocessed features for decision tree training\n",
    "    # We need the same preprocessing that was used for the main model\n",
    "    X_test_preprocessed = trained_pipeline.named_steps['preprocessor'].transform(X_test)\n",
    "    \n",
    "    # Convert to DataFrame for easier handling (get feature names from preprocessor); this might cause an issue\n",
    "    try:\n",
    "        # Try to get feature names from the preprocessor\n",
    "        feature_names = trained_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "        X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed, columns=feature_names, index=X_test.index)\n",
    "    except:\n",
    "        # Fallback if feature names aren't available\n",
    "        n_features = X_test_preprocessed.shape[1]\n",
    "        feature_names = [f'feature_{i}' for i in range(n_features)]\n",
    "        X_test_preprocessed_df = pd.DataFrame(X_test_preprocessed, columns=feature_names, index=X_test.index)\n",
    "    \n",
    "    # Step 4: Train decision tree with hyperparameter tuning to identify failure patterns\n",
    "    param_grid = {\n",
    "        'max_depth': list(range(*max_depth_range)),\n",
    "        'min_samples_leaf': [max(1, int(frac * len(X_test_preprocessed_df))) for frac in np.linspace(*min_samples_leaf_range, 5)]\n",
    "    }\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=random_state, class_weight='balanced')\n",
    "    dt_grid = GridSearchCV(dt, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "    dt_grid.fit(X_test_preprocessed_df, y_relabeled)\n",
    "    \n",
    "    best_dt = dt_grid.best_estimator_\n",
    "    \n",
    "    print(f\"  Best decision tree params: {dt_grid.best_params_}\")\n",
    "    print(f\"  Decision tree F1 score: {dt_grid.best_score_:.4f}\")\n",
    "    \n",
    "    # Step 5: Identify leaf nodes and their accuracies\n",
    "    leaf_indices = best_dt.apply(X_test_preprocessed_df)\n",
    "    unique_leaves = np.unique(leaf_indices)\n",
    "    \n",
    "    ddlas = []\n",
    "    all_leaf_info = {}\n",
    "    \n",
    "    for leaf in unique_leaves:\n",
    "        leaf_mask = (leaf_indices == leaf)\n",
    "        leaf_data_indices = np.where(leaf_mask)[0]\n",
    "        \n",
    "        if len(leaf_data_indices) > 0:\n",
    "            # Calculate accuracy for this leaf using original indices\n",
    "            leaf_y_true = y_test.iloc[leaf_data_indices]\n",
    "            leaf_y_pred = y_pred[leaf_data_indices]\n",
    "            leaf_accuracy = accuracy_score(leaf_y_true, leaf_y_pred)\n",
    "            \n",
    "            # Get the decision path for this leaf (using first sample as representative)\n",
    "            decision_path = best_dt.decision_path(X_test_preprocessed_df.iloc[leaf_data_indices[0:1]])\n",
    "            \n",
    "            leaf_info = {\n",
    "                'leaf_id': leaf,\n",
    "                'accuracy': leaf_accuracy,\n",
    "                'error_rate': 1 - leaf_accuracy,\n",
    "                'sample_count': len(leaf_data_indices),\n",
    "                'sample_indices': leaf_data_indices.tolist(),\n",
    "                'sample_fraction': len(leaf_data_indices) / len(X_test),\n",
    "                'is_ddla': leaf_accuracy < overall_accuracy\n",
    "            }\n",
    "            \n",
    "            all_leaf_info[leaf] = leaf_info\n",
    "            \n",
    "            # Identify as DDLA if accuracy < overall accuracy\n",
    "            if leaf_accuracy < overall_accuracy:\n",
    "                ddlas.append(leaf_info)\n",
    "    \n",
    "    # Sort DDLAs by error rate (highest first)\n",
    "    ddlas.sort(key=lambda x: x['error_rate'], reverse=True)\n",
    "    \n",
    "    print(f\" Found {len(ddlas)} DDLAs out of {len(unique_leaves)} total leaf nodes\")\n",
    "    \n",
    "    # Calculate DDLA statistics\n",
    "    ddla_sample_count = sum(ddla['sample_count'] for ddla in ddlas)\n",
    "    ddla_fraction = ddla_sample_count / len(X_test)\n",
    "    \n",
    "    print(f\" DDLA coverage: {ddla_sample_count}/{len(X_test)} samples ({ddla_fraction:.3f})\")\n",
    "    \n",
    "    return {\n",
    "        'ddlas': ddlas,\n",
    "        'decision_tree': best_dt,\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'overall_error_rate': incorrect_rate,\n",
    "        'ddla_fraction_baseline': ddla_fraction,\n",
    "        'all_leaf_info': all_leaf_info,\n",
    "        'preprocessed_features': X_test_preprocessed_df,\n",
    "        'feature_names': feature_names,\n",
    "        'grid_search_results': dt_grid.cv_results_\n",
    "    }\n",
    "\n",
    "\n",
    "def detect_harmful_drift_ddla(ddla_info, X_serving_data, trained_pipeline, \n",
    "                              theta_inc=0.5, theta_ddla=0.1):\n",
    "    \n",
    "    print(\"Detecting harmful drift\")\n",
    "    \n",
    "    decision_tree = ddla_info['decision_tree']\n",
    "    baseline_ddla_fraction = ddla_info['ddla_fraction_baseline']\n",
    "    \n",
    "    # Preprocess serving data using the same pipeline\n",
    "    X_serving_preprocessed = trained_pipeline.named_steps['preprocessor'].transform(X_serving_data)\n",
    "    X_serving_preprocessed_df = pd.DataFrame(\n",
    "        X_serving_preprocessed, \n",
    "        columns=ddla_info['feature_names'], \n",
    "        index=X_serving_data.index\n",
    "    )\n",
    "    \n",
    "    # Predict leaf assignments for serving data\n",
    "    serving_leaf_indices = decision_tree.apply(X_serving_preprocessed_df)\n",
    "    \n",
    "    # Get DDLA leaf IDs\n",
    "    ddla_leaf_ids = [ddla['leaf_id'] for ddla in ddla_info['ddlas']]\n",
    "    \n",
    "    # Calculate serving DDLA ratio\n",
    "    serving_ddla_count = sum(1 for leaf in serving_leaf_indices if leaf in ddla_leaf_ids)\n",
    "    serving_ddla_fraction = serving_ddla_count / len(X_serving_data)\n",
    "    \n",
    "    print(f\"  Baseline DDLA fraction: {baseline_ddla_fraction:.4f}\")\n",
    "    print(f\"  Serving DDLA fraction: {serving_ddla_fraction:.4f}\")\n",
    "    \n",
    "    # Determine if harmful drift occurred\n",
    "    if serving_ddla_fraction <= baseline_ddla_fraction:\n",
    "        is_harmful = False\n",
    "        drift_type = \"benign\"\n",
    "        reason = \"DDLA fraction decreased or stayed same\"\n",
    "    else:\n",
    "        # Check thresholds for harmful drift\n",
    "        if baseline_ddla_fraction > 0:\n",
    "            ratio_increase = (serving_ddla_fraction - baseline_ddla_fraction) / baseline_ddla_fraction\n",
    "        else:\n",
    "            ratio_increase = float('inf') if serving_ddla_fraction > 0 else 0\n",
    "        \n",
    "        is_harmful = (ratio_increase > theta_inc) and (serving_ddla_fraction > theta_ddla)\n",
    "        \n",
    "        if is_harmful:\n",
    "            drift_type = \"harmful\"\n",
    "            reason = f\"DDLA ratio increased by {ratio_increase:.2%} (>{theta_inc:.1%}) and exceeds {theta_ddla:.1%}\"\n",
    "        else:\n",
    "            drift_type = \"benign\"\n",
    "            if ratio_increase <= theta_inc:\n",
    "                reason = f\"DDLA ratio increase {ratio_increase:.2%} below threshold {theta_inc:.1%}\"\n",
    "            else:\n",
    "                reason = f\"DDLA fraction {serving_ddla_fraction:.3f} below threshold {theta_ddla:.1%}\"\n",
    "    \n",
    "    print(f\" Drift assessment: {drift_type.upper()}\")\n",
    "    print(f\"  Reason: {reason}\")\n",
    "    \n",
    "    return {\n",
    "        'is_harmful_drift': is_harmful,\n",
    "        'drift_type': drift_type,\n",
    "        'reason': reason,\n",
    "        'baseline_ddla_fraction': baseline_ddla_fraction,\n",
    "        'serving_ddla_fraction': serving_ddla_fraction,\n",
    "        'ddla_fraction_change': serving_ddla_fraction - baseline_ddla_fraction,\n",
    "        'ddla_fraction_change_pct': ((serving_ddla_fraction - baseline_ddla_fraction) / baseline_ddla_fraction * 100) if baseline_ddla_fraction > 0 else 0,\n",
    "        'ratio_train': baseline_ddla_fraction,\n",
    "        'ratio_serving': serving_ddla_fraction,\n",
    "        'serving_ddla_count': serving_ddla_count,\n",
    "        'serving_total_count': len(X_serving_data),\n",
    "        'thresholds_used': {'theta_inc': theta_inc, 'theta_ddla': theta_ddla}\n",
    "    }\n",
    "\n",
    "\n",
    "def run_ddla_drift_experiment(X, y, trained_pipeline, drift_thresholds, \n",
    "                              experiment_name=\"telco-ddla-drift-analysis\", \n",
    "                              random_state=42):\n",
    "   \n",
    "    print(\"Starting DDLA Drift Experiment...\")\n",
    "    print(f\"Testing thresholds: {drift_thresholds}\")\n",
    "    \n",
    "    # Set up MLflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Split data for baseline DDLA identification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # Step 1: Identify DDLAs on baseline test data\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 1: IDENTIFYING DDLAs ON BASELINE DATA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    ddla_info = identify_ddlas_decision_tree(trained_pipeline, X_test, y_test, random_state=random_state)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Step 2: Test each drift threshold\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 2: TESTING DDLA APPROACH ACROSS DRIFT THRESHOLDS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for threshold in drift_thresholds:\n",
    "        print(f\"\\n Testing drift threshold: {threshold:.2f}\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f'ddla_threshold_{threshold}'):\n",
    "            # Generate drifted data using your existing function\n",
    "            X_drifted, y_drifted, drift_info = simulate_drifted_data(\n",
    "                X, y, drift_threshold=threshold, random_state=random_state\n",
    "            )\n",
    "            \n",
    "            # Split drifted data (same way as baseline)\n",
    "            _, X_test_drifted, _, y_test_drifted = train_test_split(\n",
    "                X_drifted, y_drifted, test_size=0.2, random_state=random_state\n",
    "            )\n",
    "            \n",
    "            # Test DDLA drift detection\n",
    "            drift_detection = detect_harmful_drift_ddla(\n",
    "                ddla_info, X_test_drifted, trained_pipeline\n",
    "            )\n",
    "            \n",
    "            # Get actual performance metrics for comparison\n",
    "            y_pred_drifted = trained_pipeline.predict(X_test_drifted)\n",
    "            y_prob_drifted = trained_pipeline.predict_proba(X_test_drifted)[:, 1]\n",
    "            \n",
    "            actual_metrics = {\n",
    "                'accuracy': accuracy_score(y_test_drifted, y_pred_drifted),\n",
    "                'precision': precision_score(y_test_drifted, y_pred_drifted),\n",
    "                'recall': recall_score(y_test_drifted, y_pred_drifted),\n",
    "                'f1': f1_score(y_test_drifted, y_pred_drifted),\n",
    "                'auc': roc_auc_score(y_test_drifted, y_prob_drifted)\n",
    "            }\n",
    "            \n",
    "            # Calculate performance degradation\n",
    "            baseline_accuracy = ddla_info['overall_accuracy']\n",
    "            accuracy_drop = baseline_accuracy - actual_metrics['accuracy']\n",
    "            accuracy_drop_pct = (accuracy_drop / baseline_accuracy) * 100 if baseline_accuracy > 0 else 0\n",
    "            \n",
    "            # Determine if retraining is actually needed (ground truth)\n",
    "            significant_degradation_threshold = 0.05  # 5% absolute accuracy drop\n",
    "            actually_needs_retraining = accuracy_drop > significant_degradation_threshold\n",
    "            \n",
    "            # Check if DDLA approach made correct decision\n",
    "            ddla_correct = drift_detection['is_harmful_drift'] == actually_needs_retraining\n",
    "            \n",
    "            # Store comprehensive results\n",
    "            result = {\n",
    "                'threshold': threshold,\n",
    "                'ddla_detected_harmful': drift_detection['is_harmful_drift'],\n",
    "                'ddla_drift_type': drift_detection['drift_type'],\n",
    "                'actually_needs_retraining': actually_needs_retraining,\n",
    "                'ddla_correct_decision': ddla_correct,\n",
    "                \n",
    "                # DDLA metrics\n",
    "                'baseline_ddla_fraction': drift_detection['baseline_ddla_fraction'],\n",
    "                'serving_ddla_fraction': drift_detection['serving_ddla_fraction'],\n",
    "                'ddla_fraction_change': drift_detection['ddla_fraction_change'],\n",
    "                'ddla_fraction_change_pct': drift_detection['ddla_fraction_change_pct'],\n",
    "                \n",
    "                # Performance metrics\n",
    "                'actual_accuracy': actual_metrics['accuracy'],\n",
    "                'accuracy_drop': accuracy_drop,\n",
    "                'accuracy_drop_pct': accuracy_drop_pct,\n",
    "                'actual_f1': actual_metrics['f1'],\n",
    "                'actual_auc': actual_metrics['auc'],\n",
    "                \n",
    "                # Drift simulation info\n",
    "                'n_covariate_shifts': len(drift_info['covariate_shifts']),\n",
    "                'n_concept_shifts': len(drift_info['concept_shifts']),\n",
    "                'final_churn_rate': y_test_drifted.mean()\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            # Log everything to MLflow\n",
    "            # Parameters\n",
    "            mlflow.log_param('drift_threshold', threshold)\n",
    "            mlflow.log_param('ddla_approach', 'decision_tree')\n",
    "            mlflow.log_param('n_ddlas_identified', len(ddla_info['ddlas']))\n",
    "            mlflow.log_param('n_covariate_shifts', len(drift_info['covariate_shifts']))\n",
    "            mlflow.log_param('n_concept_shifts', len(drift_info['concept_shifts']))\n",
    "            \n",
    "            # DDLA metrics\n",
    "            mlflow.log_metric('baseline_ddla_fraction', drift_detection['baseline_ddla_fraction'])\n",
    "            mlflow.log_metric('serving_ddla_fraction', drift_detection['serving_ddla_fraction'])\n",
    "            mlflow.log_metric('ddla_fraction_change', drift_detection['ddla_fraction_change'])\n",
    "            mlflow.log_metric('ddla_fraction_change_pct', drift_detection['ddla_fraction_change_pct'])\n",
    "            \n",
    "            # Decision metrics  \n",
    "            mlflow.log_metric('ddla_detected_harmful', 1 if drift_detection['is_harmful_drift'] else 0)\n",
    "            mlflow.log_metric('actually_needs_retraining', 1 if actually_needs_retraining else 0)\n",
    "            mlflow.log_metric('ddla_correct_decision', 1 if ddla_correct else 0)\n",
    "            \n",
    "            # Performance metrics\n",
    "            for metric_name, metric_value in actual_metrics.items():\n",
    "                mlflow.log_metric(f'actual_{metric_name}', metric_value)\n",
    "            \n",
    "            mlflow.log_metric('accuracy_drop', accuracy_drop)\n",
    "            mlflow.log_metric('accuracy_drop_pct', accuracy_drop_pct)\n",
    "            \n",
    "            # Data info\n",
    "            mlflow.log_metric('final_churn_rate', y_test_drifted.mean())\n",
    "            mlflow.log_metric('churn_rate_change', y_test_drifted.mean() - y_test.mean())\n",
    "            \n",
    "            # Log data\n",
    "            X_test_with_target = X_test_drifted.copy()\n",
    "            X_test_with_target['Churn'] = y_test_drifted\n",
    "            drifted_dataset = mlflow.data.from_pandas(X_test_with_target)\n",
    "            mlflow.log_input(drifted_dataset, context='drifted_test')\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"  DDLA says: {'HARMFUL' if drift_detection['is_harmful_drift'] else 'BENIGN'}\")\n",
    "            print(f\"  Actually needs retraining: {'YES' if actually_needs_retraining else 'NO'}\")\n",
    "            print(f\"  DDLA decision correct: {'YES' if ddla_correct else 'NO'}\")\n",
    "            print(f\"  Accuracy drop: {accuracy_drop:.4f} ({accuracy_drop_pct:.1f}%)\")\n",
    "            print(f\"  DDLA fraction: {drift_detection['baseline_ddla_fraction']:.3f} â†’ {drift_detection['serving_ddla_fraction']:.3f}\")\n",
    "    \n",
    "    # Create summary visualization and log to MLflow\n",
    "    create_ddla_summary_visualization(results, ddla_info, experiment_name)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def create_ddla_summary_visualization(results, ddla_info, experiment_name):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of DDLA experiment results.\n",
    "    \"\"\"\n",
    "    print(\"\\n Creating DDLA summary visualization\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    thresholds = [r['threshold'] for r in results]\n",
    "    \n",
    "    # 1. DDLA Detection Accuracy\n",
    "    ax1 = axes[0, 0]\n",
    "    correct_decisions = [r['ddla_correct_decision'] for r in results]\n",
    "    accuracy_rate = np.mean(correct_decisions) * 100\n",
    "    \n",
    "    colors = ['#27ae60' if correct else '#e74c3c' for correct in correct_decisions]\n",
    "    bars = ax1.bar(range(len(thresholds)), correct_decisions, color=colors, alpha=0.7)\n",
    "    ax1.set_xlabel('Drift Threshold', fontsize=11)\n",
    "    ax1.set_ylabel('Correct Decision (1=Yes, 0=No)', fontsize=11)\n",
    "    ax1.set_title(f'DDLA Decision Accuracy\\n(Overall: {accuracy_rate:.1f}%)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xticks(range(len(thresholds)))\n",
    "    ax1.set_xticklabels([f'{t:.2f}' for t in thresholds])\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 2. DDLA Fraction Changes\n",
    "    ax2 = axes[0, 1]\n",
    "    baseline_fractions = [r['baseline_ddla_fraction'] for r in results]\n",
    "    serving_fractions = [r['serving_ddla_fraction'] for r in results]\n",
    "    \n",
    "    ax2.plot(thresholds, baseline_fractions, 'o-', label='Baseline DDLA', linewidth=2, markersize=6)\n",
    "    ax2.plot(thresholds, serving_fractions, 's-', label='Serving DDLA', linewidth=2, markersize=6)\n",
    "    ax2.set_xlabel('Drift Threshold', fontsize=11)\n",
    "    ax2.set_ylabel('DDLA Fraction', fontsize=11)\n",
    "    ax2.set_title('DDLA Fraction: Baseline vs Serving', fontsize=12, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Actual Performance Degradation\n",
    "    ax3 = axes[0, 2]\n",
    "    accuracy_drops = [r['accuracy_drop_pct'] for r in results]\n",
    "    ax3.plot(thresholds, accuracy_drops, 'o-', color='#e74c3c', linewidth=2, markersize=6)\n",
    "    ax3.axhline(y=5, color='orange', linestyle='--', label='5% threshold')\n",
    "    ax3.set_xlabel('Drift Threshold', fontsize=11)\n",
    "    ax3.set_ylabel('Accuracy Drop (%)', fontsize=11)\n",
    "    ax3.set_title('Actual Performance Degradation', fontsize=12, fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. DDLA vs Reality Comparison\n",
    "    ax4 = axes[1, 0]\n",
    "    ddla_harmful = [1 if r['ddla_detected_harmful'] else 0 for r in results]\n",
    "    actually_needs = [1 if r['actually_needs_retraining'] else 0 for r in results]\n",
    "    \n",
    "    x = np.arange(len(thresholds))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax4.bar(x - width/2, ddla_harmful, width, label='DDLA Says Harmful', alpha=0.7, color='#3498db')\n",
    "    ax4.bar(x + width/2, actually_needs, width, label='Actually Needs Retraining', alpha=0.7, color='#e67e22')\n",
    "    \n",
    "    ax4.set_xlabel('Drift Threshold', fontsize=11)\n",
    "    ax4.set_ylabel('Decision (1=Yes, 0=No)', fontsize=11)\n",
    "    ax4.set_title('DDLA Predictions vs Reality', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xticks(x)\n",
    "    ax4.set_xticklabels([f'{t:.2f}' for t in thresholds])\n",
    "    ax4.legend()\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 5. DDLA Leaf Distribution\n",
    "    ax5 = axes[1, 1]\n",
    "    n_ddlas = len(ddla_info['ddlas'])\n",
    "    ddla_sizes = [ddla['sample_count'] for ddla in ddla_info['ddlas'][:10]]  # Top 10\n",
    "    ddla_labels = [f\"Leaf {ddla['leaf_id']}\" for ddla in ddla_info['ddlas'][:10]]\n",
    "    \n",
    "    if ddla_sizes:\n",
    "        ax5.pie(ddla_sizes, labels=ddla_labels, autopct='%1.1f%%', startangle=90)\n",
    "        ax5.set_title(f'Top 10 DDLA Distribution\\n(Total DDLAs: {n_ddlas})', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 6. Confusion Matrix Style\n",
    "    ax6 = axes[1, 2]\n",
    "    \n",
    "    # Create confusion matrix data\n",
    "    tp = sum(1 for r in results if r['ddla_detected_harmful'] and r['actually_needs_retraining'])\n",
    "    tn = sum(1 for r in results if not r['ddla_detected_harmful'] and not r['actually_needs_retraining'])\n",
    "    fp = sum(1 for r in results if r['ddla_detected_harmful'] and not r['actually_needs_retraining'])\n",
    "    fn = sum(1 for r in results if not r['ddla_detected_harmful'] and r['actually_needs_retraining'])\n",
    "    \n",
    "    confusion_matrix = np.array([[tn, fp], [fn, tp]])\n",
    "    \n",
    "    im = ax6.imshow(confusion_matrix, interpolation='nearest', cmap='Blues')\n",
    "    ax6.set_title('DDLA Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = confusion_matrix.max() / 2.\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax6.text(j, i, format(confusion_matrix[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if confusion_matrix[i, j] > thresh else \"black\",\n",
    "                    fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax6.set_xticks([0, 1])\n",
    "    ax6.set_xticklabels(['Predicted Benign', 'Predicted Harmful'])\n",
    "    ax6.set_yticks([0, 1])\n",
    "    ax6.set_yticklabels(['Actually Benign', 'Actually Harmful'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save and log to MLflow\n",
    "    summary_plot_path = f'ddla_summary_{experiment_name.replace(\"-\", \"_\")}.png'\n",
    "    plt.savefig(summary_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Log summary to MLflow\n",
    "    with mlflow.start_run(run_name='ddla_summary'):\n",
    "        mlflow.log_param('experiment_type', 'ddla_summary')\n",
    "        mlflow.log_param('n_ddlas_found', len(ddla_info['ddlas']))\n",
    "        mlflow.log_param('baseline_ddla_fraction', ddla_info['ddla_fraction_baseline'])\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        accuracy_rate = np.mean([r['ddla_correct_decision'] for r in results]) * 100\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score_ddla = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        mlflow.log_metric('ddla_accuracy_rate', accuracy_rate)\n",
    "        mlflow.log_metric('ddla_precision', precision)\n",
    "        mlflow.log_metric('ddla_recall', recall)\n",
    "        mlflow.log_metric('ddla_f1_score', f1_score_ddla)\n",
    "        \n",
    "        mlflow.log_artifact(summary_plot_path, artifact_path='plots')\n",
    "        \n",
    "        print(f\" DDLA Summary logged to MLflow\")\n",
    "        print(f\"   - Decision accuracy: {accuracy_rate:.1f}%\")\n",
    "        print(f\"   - Precision: {precision:.3f}\")\n",
    "        print(f\"   - Recall: {recall:.3f}\")\n",
    "        print(f\"   - F1-Score: {f1_score_ddla:.3f}\")\n",
    "    \n",
    "    return summary_plot_path\n",
    "\n",
    "def debug_ddla_results(ddla_info, results):\n",
    "\n",
    "    print(\" DDLA DEBUG ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"Baseline DDLAs found: {len(ddla_info['ddlas'])}\")\n",
    "    print(f\"Baseline DDLA ratio: {ddla_info['ddla_ratio_baseline']:.4f}\")\n",
    "    \n",
    "    if len(ddla_info['ddlas']) > 0:\n",
    "        print(\"\\nTop 5 DDLAs:\")\n",
    "        for i, ddla in enumerate(ddla_info['ddlas'][:5]):\n",
    "            print(f\"  {i+1}. Leaf {ddla['leaf_id']}: {ddla['accuracy']:.3f} accuracy \"\n",
    "                  f\"({ddla['sample_count']} samples)\")\n",
    "    \n",
    "    print(f\"\\nDDLA Ratios across thresholds:\")\n",
    "    print(f\"{'Threshold':<12} {'Baseline':<12} {'Serving':<12} {'Change':<12} {'% Change':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for r in results:\n",
    "        baseline_ratio = r.get('ratio_train', 0)\n",
    "        serving_ratio = r.get('ratio_serving', 0) \n",
    "        change = serving_ratio - baseline_ratio\n",
    "        pct_change = (change / baseline_ratio * 100) if baseline_ratio > 0 else 0\n",
    "        \n",
    "        print(f\"{r['threshold']:<12.2f} {baseline_ratio:<12.4f} {serving_ratio:<12.4f} \"\n",
    "              f\"{change:<12.4f} {pct_change:<12.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "346abef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:26:07 INFO mlflow.tracking.fluent: Experiment with name 'telco-ddla-drift-analysis' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DDLA Drift Experiment...\n",
      "Testing thresholds: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      "\n",
      "============================================================\n",
      "STEP 1: IDENTIFYING DDLAs ON BASELINE DATA\n",
      "============================================================\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 7, 'min_samples_leaf': 28}\n",
      "  Decision tree F1 score: 0.4888\n",
      " Found 9 DDLAs out of 27 total leaf nodes\n",
      " DDLA coverage: 585/1409 samples (0.415)\n",
      "\n",
      "============================================================\n",
      "STEP 2: TESTING DDLA APPROACH ACROSS DRIFT THRESHOLDS\n",
      "============================================================\n",
      "\n",
      " Testing drift threshold: 0.00\n",
      "Simulating combined drift with threshold: 0.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4145\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA fraction decreased or stayed same\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: NO\n",
      "  DDLA decision correct: YES\n",
      "  Accuracy drop: -0.0014 (-0.2%)\n",
      "  DDLA fraction: 0.415 â†’ 0.414\n",
      "ðŸƒ View run ddla_threshold_0.0 at: http://localhost:5000/#/experiments/4/runs/4c054b0313c34ff1849db543c7c96d2d\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/4\n",
      "\n",
      " Testing drift threshold: 0.25\n",
      "Simulating combined drift with threshold: 0.25\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4315\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 3.93% below threshold 50.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA decision correct: NO\n",
      "  Accuracy drop: 0.0546 (6.9%)\n",
      "  DDLA fraction: 0.415 â†’ 0.432\n",
      "ðŸƒ View run ddla_threshold_0.25 at: http://localhost:5000/#/experiments/4/runs/5fc90b9133624061ad60270dbe15f484\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/4\n",
      "\n",
      " Testing drift threshold: 0.50\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4379\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 5.47% below threshold 50.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA decision correct: NO\n",
      "  Accuracy drop: 0.1015 (12.8%)\n",
      "  DDLA fraction: 0.415 â†’ 0.438\n",
      "ðŸƒ View run ddla_threshold_0.5 at: http://localhost:5000/#/experiments/4/runs/80be566059ec4d01932ebcc8afe856ae\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/4\n",
      "\n",
      " Testing drift threshold: 0.75\n",
      "Simulating combined drift with threshold: 0.75\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.430 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4258\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 2.56% below threshold 50.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA decision correct: NO\n",
      "  Accuracy drop: 0.1490 (18.8%)\n",
      "  DDLA fraction: 0.415 â†’ 0.426\n",
      "ðŸƒ View run ddla_threshold_0.75 at: http://localhost:5000/#/experiments/4/runs/e98e4bdf25d74a2eb533b8dc0071b2de\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/4\n",
      "\n",
      " Testing drift threshold: 1.00\n",
      "Simulating combined drift with threshold: 1.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.478 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4365\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 5.13% below threshold 50.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA decision correct: NO\n",
      "  Accuracy drop: 0.1874 (23.6%)\n",
      "  DDLA fraction: 0.415 â†’ 0.436\n",
      "ðŸƒ View run ddla_threshold_1.0 at: http://localhost:5000/#/experiments/4/runs/703df7b1552d494f97cb9559293fc49b\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/4\n",
      "\n",
      " Creating DDLA summary visualization\n",
      " DDLA Summary logged to MLflow\n",
      "   - Decision accuracy: 20.0%\n",
      "   - Precision: 0.000\n",
      "   - Recall: 0.000\n",
      "   - F1-Score: 0.000\n",
      "ðŸƒ View run ddla_summary at: http://localhost:5000/#/experiments/4/runs/50100b115cef4779a2f1ed0ad01ba338\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/4\n",
      "\n",
      "================================================================================\n",
      "DDLA APPROACH SUMMARY\n",
      "================================================================================\n",
      "Overall DDLA Decision Accuracy: 1/5 (20.0%)\n",
      "\n",
      "Detailed Results:\n",
      "Threshold    DDLA Says    Actually     Correct    Acc Drop    \n",
      "------------------------------------------------------------\n",
      "0.00         BENIGN       NO           YES        -0.2        %\n",
      "0.25         BENIGN       YES          NO         6.9         %\n",
      "0.50         BENIGN       YES          NO         12.8        %\n",
      "0.75         BENIGN       YES          NO         18.8        %\n",
      "1.00         BENIGN       YES          NO         23.6        %\n"
     ]
    }
   ],
   "source": [
    "# Run the DDLA experiment using your existing setup\n",
    "ddla_results = run_ddla_drift_experiment(\n",
    "    X=X, \n",
    "    y=y, \n",
    "    trained_pipeline=pipeline,  # Your trained pipeline\n",
    "    drift_thresholds=[0.0, 0.25, 0.5, 0.75, 1.0],  # Same as your current experiment\n",
    "    experiment_name=\"telco-ddla-drift-analysis\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Print summary comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DDLA APPROACH SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correct_decisions = sum(r['ddla_correct_decision'] for r in ddla_results)\n",
    "total_decisions = len(ddla_results)\n",
    "accuracy_rate = (correct_decisions / total_decisions) * 100\n",
    "\n",
    "print(f\"Overall DDLA Decision Accuracy: {correct_decisions}/{total_decisions} ({accuracy_rate:.1f}%)\")\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(f\"{'Threshold':<12} {'DDLA Says':<12} {'Actually':<12} {'Correct':<10} {'Acc Drop':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for r in ddla_results:\n",
    "    ddla_decision = \"HARMFUL\" if r['ddla_detected_harmful'] else \"BENIGN\"\n",
    "    actual_need = \"YES\" if r['actually_needs_retraining'] else \"NO\"\n",
    "    correct =  \"YES\" if r['ddla_correct_decision'] else \"NO\"\n",
    "    \n",
    "    print(f\"{r['threshold']:<12.2f} {ddla_decision:<12} {actual_need:<12} {correct:<10} {r['accuracy_drop_pct']:<12.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083fc9b",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Our drift simulation actively introduces both kinds of drift - covariate and concept drift. The DDLA method we incorporate was only designed for covariate drift, rather than a concept drift or both being introduced. DDLA fails - or rather breaks under scenarios when there are both kinds of drift present. When tested across different combined drift thresholds - the method appears to only correctly detect DDLA regions and classify a drift scenario as benign. Data drift does not always appear as only a covariate or concept type in machine learning pipelines, but are slowly introduced over time. But, it is rare that only one kind of drift will be present in data - which is not very realistic scenario to begin with. \n",
    "\n",
    "We further test this method using only covariate shift under different thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b72e33",
   "metadata": {},
   "source": [
    "### Simulating DDLA under just covariate drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924fdb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef simulate_covariate_drift_only(X, y, drift_threshold=0.5, random_state=42):\\n    \"\"\"\\n    Simulate ONLY covariate drift (feature distribution changes) without concept shifts.\\n    Perfect for testing DDLA under its intended conditions.\\n\\n    Parameters:\\n    -----------\\n    X : pd.DataFrame\\n        Original feature dataframe (before preprocessing)\\n    y : pd.Series\\n        Original target labels (0/1) - UNCHANGED in covariate drift\\n    drift_threshold : float\\n        Controls the intensity of drift (0.0 to 1.0)\\n    random_state : int\\n        Random seed for reproducibility\\n\\n    Returns:\\n    --------\\n    X_drifted : pd.DataFrame\\n        Drifted feature dataframe (same relationships to y)\\n    y_unchanged : pd.Series\\n        Original target labels (unchanged by definition)\\n    drift_info : dict\\n        Information about covariate shifts applied\\n    \"\"\"\\n    np.random.seed(random_state)\\n    X_drifted = X.copy()\\n    y_unchanged = y.copy()  # No concept shift!\\n\\n    drift_info = {\\n        \\'covariate_shifts\\': [],\\n        \\'concept_shifts\\': [],  # Empty by design\\n        \\'threshold\\': drift_threshold,\\n        \\'drift_type\\': \\'covariate_only\\'\\n    }\\n\\n    # Identify numeric and categorical columns\\n    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\\n    categorical_cols = X.select_dtypes(include=[\\'object\\', \\'category\\']).columns.tolist()\\n\\n    print(f\" Simulating COVARIATE DRIFT ONLY with threshold: {drift_threshold:.2f}\")\\n    print(f\"Applying to {len(numeric_cols)} numeric and {len(categorical_cols)} categorical features\")\\n    print(\"Note: Target labels remain unchanged (P(Y|X) preserved)\")\\n\\n    # ============================================\\n    # COVARIATE SHIFT: Changes to feature distributions ONLY\\n    # ============================================\\n\\n    # 1. Numeric Feature Drifts (same as your original function)\\n    for i, col in enumerate(numeric_cols):\\n        if col not in X_drifted.columns:\\n            continue\\n\\n        col_mean = X_drifted[col].mean()\\n        col_std = X_drifted[col].std()\\n\\n        if pd.isna(col_mean) or pd.isna(col_std) or col_std == 0:\\n            continue\\n\\n        # Apply different types of drift to different features\\n        drift_type = i % 4\\n\\n        if drift_type == 0:  # Mean shift\\n            shift_amount = drift_threshold * col_mean * 0.3\\n            X_drifted[col] = X_drifted[col] + shift_amount\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'mean_shift\\',\\n                \\'amount\\': shift_amount\\n            })\\n\\n        elif drift_type == 1:  # Variance increase\\n            noise = np.random.normal(0, drift_threshold * col_std * 0.5, len(X_drifted))\\n            X_drifted[col] = X_drifted[col] + noise\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'variance_increase\\',\\n                \\'noise_std\\': drift_threshold * col_std * 0.5\\n            })\\n\\n        elif drift_type == 2:  # Multiplicative shift\\n            scale_factor = 1 + drift_threshold * 0.2 * np.random.choice([-1, 1])\\n            X_drifted[col] = X_drifted[col] * scale_factor\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'multiplicative_shift\\',\\n                \\'factor\\': scale_factor\\n            })\\n\\n        else:  # Add outliers\\n            outlier_fraction = 0.1 * drift_threshold\\n            n_outliers = int(outlier_fraction * len(X_drifted))\\n            outlier_indices = np.random.choice(X_drifted.index, n_outliers, replace=False)\\n            outlier_multiplier = 3 + 2 * drift_threshold\\n            X_drifted.loc[outlier_indices, col] = X_drifted.loc[outlier_indices, col] * outlier_multiplier\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'outliers\\',\\n                \\'n_outliers\\': n_outliers\\n            })\\n\\n    # Special handling for key Telco features\\n    if \\'tenure\\' in X_drifted.columns:\\n        tenure_increase = drift_threshold * 5\\n        X_drifted[\\'tenure\\'] = X_drifted[\\'tenure\\'] + np.random.normal(tenure_increase, 2, len(X_drifted))\\n        X_drifted[\\'tenure\\'] = X_drifted[\\'tenure\\'].clip(lower=0)\\n        drift_info[\\'covariate_shifts\\'].append({\\n            \\'feature\\': \\'tenure\\',\\n            \\'type\\': \\'market_shift\\',\\n            \\'increase_months\\': tenure_increase\\n        })\\n\\n    if \\'MonthlyCharges\\' in X_drifted.columns:\\n        inflation_rate = 1 + drift_threshold * 0.15\\n        X_drifted[\\'MonthlyCharges\\'] = X_drifted[\\'MonthlyCharges\\'] * inflation_rate\\n        drift_info[\\'covariate_shifts\\'].append({\\n            \\'feature\\': \\'MonthlyCharges\\',\\n            \\'type\\': \\'inflation\\',\\n            \\'rate\\': inflation_rate\\n        })\\n\\n    if \\'TotalCharges\\' in X_drifted.columns:\\n        if \\'tenure\\' in X_drifted.columns and \\'MonthlyCharges\\' in X_drifted.columns:\\n            X_drifted[\\'TotalCharges\\'] = X_drifted[\\'tenure\\'] * X_drifted[\\'MonthlyCharges\\'] *                                       (1 + np.random.normal(0, 0.1 * drift_threshold, len(X_drifted)))\\n            X_drifted[\\'TotalCharges\\'] = X_drifted[\\'TotalCharges\\'].clip(lower=0)\\n\\n    # 2. Categorical Feature Drifts\\n    for col in categorical_cols[:min(5, len(categorical_cols))]:\\n        if col not in X_drifted.columns:\\n            continue\\n\\n        unique_vals = X_drifted[col].unique()\\n        if len(unique_vals) < 2:\\n            continue\\n\\n        # Shift probability distributions\\n        if col == \\'InternetService\\' and \\'Fiber optic\\' in unique_vals and \\'DSL\\' in unique_vals:\\n            mask_fiber = X_drifted[col] == \\'DSL\\'\\n            n_to_shift = int(len(X_drifted) * 0.2 * drift_threshold)\\n            shift_indices = np.random.choice(X_drifted[mask_fiber].index[:n_to_shift], \\n                                           size=min(n_to_shift, mask_fiber.sum()), \\n                                           replace=False)\\n            X_drifted.loc[shift_indices, col] = \\'Fiber optic\\'\\n            drift_info[\\'covariate_shifts\\'].append({\\n                \\'feature\\': col,\\n                \\'type\\': \\'category_probability_shift\\',\\n                \\'shift\\': f\\'DSL -> Fiber optic ({len(shift_indices)} samples)\\'\\n            })\\n\\n        elif len(unique_vals) >= 2:\\n            value_counts = X_drifted[col].value_counts()\\n            if len(value_counts) >= 2:\\n                most_common = value_counts.index[0]\\n                least_common = value_counts.index[-1]\\n\\n                n_to_shift = int(len(X_drifted) * 0.15 * drift_threshold)\\n                mask = X_drifted[col] == most_common\\n                if mask.sum() > 0:\\n                    shift_indices = np.random.choice(X_drifted[mask].index, \\n                                                   size=min(n_to_shift, mask.sum()), \\n                                                   replace=False)\\n                    X_drifted.loc[shift_indices, col] = least_common\\n                    drift_info[\\'covariate_shifts\\'].append({\\n                        \\'feature\\': col,\\n                        \\'type\\': \\'category_distribution_shift\\',\\n                        \\'shift\\': f\\'{most_common} -> {least_common} ({len(shift_indices)} samples)\\'\\n                    })\\n\\n    print(f\"âœ“ Applied {len(drift_info[\\'covariate_shifts\\'])} covariate shifts\")\\n    print(f\"âœ“ Applied {len(drift_info[\\'concept_shifts\\'])} concept shifts (by design: 0)\")\\n    print(f\"Final churn rate: {y_unchanged.mean():.3f} (unchanged from original: {y.mean():.3f})\")\\n\\n    return X_drifted, y_unchanged, drift_info\\n\\n\\ndef simulate_concept_drift_only(X, y, drift_threshold=0.5, random_state=42):\\n    \"\"\"\\n    Simulate ONLY concept drift (relationship changes) without covariate shifts.\\n    Changes P(Y|X) while keeping P(X) the same.\\n\\n    Parameters:\\n    -----------\\n    X : pd.DataFrame\\n        Original feature dataframe (UNCHANGED in concept drift)\\n    y : pd.Series\\n        Original target labels (0/1)\\n    drift_threshold : float\\n        Controls the intensity of drift (0.0 to 1.0)\\n    random_state : int\\n        Random seed for reproducibility\\n\\n    Returns:\\n    --------\\n    X_unchanged : pd.DataFrame\\n        Original feature dataframe (unchanged by definition)\\n    y_drifted : pd.Series\\n        Drifted target labels (new relationships)\\n    drift_info : dict\\n        Information about concept shifts applied\\n    \"\"\"\\n    np.random.seed(random_state)\\n    X_unchanged = X.copy() \\n    y_drifted = y.copy()\\n\\n    drift_info = {\\n        \\'covariate_shifts\\': [], \\n        \\'concept_shifts\\': [],\\n        \\'threshold\\': drift_threshold,\\n        \\'drift_type\\': \\'concept_only\\'\\n    }\\n\\n    print(f\" Simulating CONCEPT DRIFT ONLY with threshold: {drift_threshold:.2f}\")\\n    print(\"Note: Feature distributions remain unchanged (P(X) preserved)\")\\n    print(\"Changing relationships between features and target (P(Y|X))\")\\n\\n    # ============================================\\n    # CONCEPT SHIFT: Changes to label relationships ONLY\\n    # ============================================\\n\\n    # 1. Reverse relationship for high-value customers\\n    if \\'MonthlyCharges\\' in X_unchanged.columns:\\n        high_charge_threshold = X_unchanged[\\'MonthlyCharges\\'].quantile(0.75)\\n        high_charge_mask = X_unchanged[\\'MonthlyCharges\\'] > high_charge_threshold\\n\\n        n_to_flip = int(high_charge_mask.sum() * 0.3 * drift_threshold)\\n        flip_indices = np.random.choice(X_unchanged[high_charge_mask].index, \\n                                      size=min(n_to_flip, high_charge_mask.sum()), \\n                                      replace=False)\\n        y_drifted.loc[flip_indices] = 1 - y_drifted.loc[flip_indices]\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'high_value_retention\\',\\n            \\'description\\': \\'High MonthlyCharges customers now less likely to churn\\',\\n            \\'n_samples\\': len(flip_indices)\\n        })\\n\\n    # 2. Change relationship with tenure\\n    if \\'tenure\\' in X_unchanged.columns:\\n        long_tenure_threshold = X_unchanged[\\'tenure\\'].quantile(0.8)\\n        long_tenure_mask = (X_unchanged[\\'tenure\\'] > long_tenure_threshold) & (y_drifted == 0)\\n\\n        n_to_flip = int(long_tenure_mask.sum() * 0.2 * drift_threshold)\\n        flip_indices = np.random.choice(X_unchanged[long_tenure_mask].index, \\n                                      size=min(n_to_flip, long_tenure_mask.sum()), \\n                                      replace=False)\\n        y_drifted.loc[flip_indices] = 1\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'tenure_fatigue\\',\\n            \\'description\\': \\'Very long tenure customers more likely to churn\\',\\n            \\'n_samples\\': len(flip_indices)\\n        })\\n\\n    # 3. Change relationship with service engagement\\n    if \\'service_engagement\\' in X_unchanged.columns:\\n        high_engagement_threshold = X_unchanged[\\'service_engagement\\'].quantile(0.7)\\n        high_engagement_mask = (X_unchanged[\\'service_engagement\\'] > high_engagement_threshold) & (y_drifted == 0)\\n\\n        n_to_flip = int(high_engagement_mask.sum() * 0.25 * drift_threshold)\\n        flip_indices = np.random.choice(X_unchanged[high_engagement_mask].index, \\n                                      size=min(n_to_flip, high_engagement_mask.sum()), \\n                                      replace=False)\\n        y_drifted.loc[flip_indices] = 1\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'service_overwhelm\\',\\n            \\'description\\': \\'High service engagement customers more likely to churn\\',\\n            \\'n_samples\\': len(flip_indices)\\n        })\\n\\n    # 4. Contract type relationship change\\n    if \\'Contract\\' in X_unchanged.columns:\\n        two_year_mask = (X_unchanged[\\'Contract\\'] == \\'Two year\\') & (y_drifted == 0)\\n        n_to_flip = int(two_year_mask.sum() * 0.15 * drift_threshold)\\n        flip_indices = np.random.choice(X_unchanged[two_year_mask].index, \\n                                      size=min(n_to_flip, two_year_mask.sum()), \\n                                      replace=False)\\n        y_drifted.loc[flip_indices] = 1\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'contract_regret\\',\\n            \\'description\\': \\'Two year contract customers more likely to churn\\',\\n            \\'n_samples\\': len(flip_indices)\\n        })\\n\\n    # 5. Overall base rate shift\\n    base_rate_shift = drift_threshold * 0.1\\n    if base_rate_shift > 0:\\n        current_churn_rate = y_drifted.mean()\\n        target_churn_rate = min(1.0, current_churn_rate + base_rate_shift)\\n\\n        n_current_churn = y_drifted.sum()\\n        n_target_churn = int(len(y_drifted) * target_churn_rate)\\n        n_to_change = abs(n_target_churn - n_current_churn)\\n\\n        if n_target_churn > n_current_churn:\\n            non_churners = X_unchanged[y_drifted == 0].index\\n            flip_indices = np.random.choice(non_churners, \\n                                          size=min(n_to_change, len(non_churners)), \\n                                          replace=False)\\n            y_drifted.loc[flip_indices] = 1\\n        else:\\n            churners = X_unchanged[y_drifted == 1].index\\n            flip_indices = np.random.choice(churners, \\n                                          size=min(n_to_change, len(churners)), \\n                                          replace=False)\\n            y_drifted.loc[flip_indices] = 0\\n\\n        drift_info[\\'concept_shifts\\'].append({\\n            \\'type\\': \\'base_rate_shift\\',\\n            \\'description\\': f\\'Overall churn rate shifted from {current_churn_rate:.3f} to {target_churn_rate:.3f}\\',\\n            \\'shift_amount\\': base_rate_shift\\n        })\\n\\n    print(f\"âœ“ Applied {len(drift_info[\\'covariate_shifts\\'])} covariate shifts (by design: 0)\")\\n    print(f\"âœ“ Applied {len(drift_info[\\'concept_shifts\\'])} concept shifts\")\\n    print(f\"Final churn rate: {y_drifted.mean():.3f} (original: {y.mean():.3f})\")\\n\\n    return X_unchanged, y_drifted, drift_info\\n\\n\\ndef simulate_selective_drift(X, y, drift_threshold=0.5, \\n                           covariate_ratio=0.75, concept_ratio=0.25, \\n                           random_state=42):\\n    \"\"\"\\n    Simulate drift with customizable balance between covariate and concept shifts.\\n    This gives you full control over the type and intensity of drift.\\n\\n    Parameters:\\n    -----------\\n    X : pd.DataFrame\\n        Original feature dataframe\\n    y : pd.Series\\n        Original target labels (0/1)\\n    drift_threshold : float\\n        Controls overall intensity of drift (0.0 to 1.0)\\n    covariate_ratio : float\\n        Fraction of drift intensity applied to covariate shifts (0.0 to 1.0)\\n    concept_ratio : float\\n        Fraction of drift intensity applied to concept shifts (0.0 to 1.0)\\n    random_state : int\\n        Random seed for reproducibility\\n\\n    Returns:\\n    --------\\n    X_drifted : pd.DataFrame\\n        Drifted feature dataframe\\n    y_drifted : pd.Series\\n        Drifted target labels\\n    drift_info : dict\\n        Information about all shifts applied\\n    \"\"\"\\n    print(f\" Simulating SELECTIVE DRIFT with threshold: {drift_threshold:.2f}\")\\n    print(f\"   Covariate intensity: {covariate_ratio:.2f} | Concept intensity: {concept_ratio:.2f}\")\\n\\n    # Start with original data\\n    X_result = X.copy()\\n    y_result = y.copy()\\n\\n    combined_drift_info = {\\n        \\'covariate_shifts\\': [],\\n        \\'concept_shifts\\': [],\\n        \\'threshold\\': drift_threshold,\\n        \\'covariate_ratio\\': covariate_ratio,\\n        \\'concept_ratio\\': concept_ratio,\\n        \\'drift_type\\': \\'selective\\'\\n    }\\n\\n    # Apply covariate drift if requested\\n    if covariate_ratio > 0:\\n        covariate_threshold = drift_threshold * covariate_ratio\\n        X_result, _, cov_info = simulate_covariate_drift_only(\\n            X_result, y_result, \\n            drift_threshold=covariate_threshold, \\n            random_state=random_state\\n        )\\n        combined_drift_info[\\'covariate_shifts\\'] = cov_info[\\'covariate_shifts\\']\\n\\n    # Apply concept drift if requested\\n    if concept_ratio > 0:\\n        concept_threshold = drift_threshold * concept_ratio\\n        _, y_result, con_info = simulate_concept_drift_only(\\n            X_result, y_result, \\n            drift_threshold=concept_threshold, \\n            random_state=random_state + 1  # Different seed\\n        )\\n        combined_drift_info[\\'concept_shifts\\'] = con_info[\\'concept_shifts\\']\\n\\n    print(f\"âœ“ Combined: {len(combined_drift_info[\\'covariate_shifts\\'])} covariate + \"\\n          f\"{len(combined_drift_info[\\'concept_shifts\\'])} concept shifts\")\\n    print(f\"Final churn rate: {y_result.mean():.3f} (original: {y.mean():.3f})\")\\n\\n    return X_result, y_result, combined_drift_info\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deprecated cell\n",
    "'''\n",
    "def simulate_covariate_drift_only(X, y, drift_threshold=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Simulate ONLY covariate drift (feature distribution changes) without concept shifts.\n",
    "    Perfect for testing DDLA under its intended conditions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Original feature dataframe (before preprocessing)\n",
    "    y : pd.Series\n",
    "        Original target labels (0/1) - UNCHANGED in covariate drift\n",
    "    drift_threshold : float\n",
    "        Controls the intensity of drift (0.0 to 1.0)\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X_drifted : pd.DataFrame\n",
    "        Drifted feature dataframe (same relationships to y)\n",
    "    y_unchanged : pd.Series\n",
    "        Original target labels (unchanged by definition)\n",
    "    drift_info : dict\n",
    "        Information about covariate shifts applied\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    X_drifted = X.copy()\n",
    "    y_unchanged = y.copy()  # No concept shift!\n",
    "    \n",
    "    drift_info = {\n",
    "        'covariate_shifts': [],\n",
    "        'concept_shifts': [],  # Empty by design\n",
    "        'threshold': drift_threshold,\n",
    "        'drift_type': 'covariate_only'\n",
    "    }\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\" Simulating COVARIATE DRIFT ONLY with threshold: {drift_threshold:.2f}\")\n",
    "    print(f\"Applying to {len(numeric_cols)} numeric and {len(categorical_cols)} categorical features\")\n",
    "    print(\"Note: Target labels remain unchanged (P(Y|X) preserved)\")\n",
    "    \n",
    "    # ============================================\n",
    "    # COVARIATE SHIFT: Changes to feature distributions ONLY\n",
    "    # ============================================\n",
    "    \n",
    "    # 1. Numeric Feature Drifts (same as your original function)\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        if col not in X_drifted.columns:\n",
    "            continue\n",
    "        \n",
    "        col_mean = X_drifted[col].mean()\n",
    "        col_std = X_drifted[col].std()\n",
    "        \n",
    "        if pd.isna(col_mean) or pd.isna(col_std) or col_std == 0:\n",
    "            continue\n",
    "        \n",
    "        # Apply different types of drift to different features\n",
    "        drift_type = i % 4\n",
    "        \n",
    "        if drift_type == 0:  # Mean shift\n",
    "            shift_amount = drift_threshold * col_mean * 0.3\n",
    "            X_drifted[col] = X_drifted[col] + shift_amount\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'mean_shift',\n",
    "                'amount': shift_amount\n",
    "            })\n",
    "            \n",
    "        elif drift_type == 1:  # Variance increase\n",
    "            noise = np.random.normal(0, drift_threshold * col_std * 0.5, len(X_drifted))\n",
    "            X_drifted[col] = X_drifted[col] + noise\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'variance_increase',\n",
    "                'noise_std': drift_threshold * col_std * 0.5\n",
    "            })\n",
    "            \n",
    "        elif drift_type == 2:  # Multiplicative shift\n",
    "            scale_factor = 1 + drift_threshold * 0.2 * np.random.choice([-1, 1])\n",
    "            X_drifted[col] = X_drifted[col] * scale_factor\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'multiplicative_shift',\n",
    "                'factor': scale_factor\n",
    "            })\n",
    "            \n",
    "        else:  # Add outliers\n",
    "            outlier_fraction = 0.1 * drift_threshold\n",
    "            n_outliers = int(outlier_fraction * len(X_drifted))\n",
    "            outlier_indices = np.random.choice(X_drifted.index, n_outliers, replace=False)\n",
    "            outlier_multiplier = 3 + 2 * drift_threshold\n",
    "            X_drifted.loc[outlier_indices, col] = X_drifted.loc[outlier_indices, col] * outlier_multiplier\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'outliers',\n",
    "                'n_outliers': n_outliers\n",
    "            })\n",
    "    \n",
    "    # Special handling for key Telco features\n",
    "    if 'tenure' in X_drifted.columns:\n",
    "        tenure_increase = drift_threshold * 5\n",
    "        X_drifted['tenure'] = X_drifted['tenure'] + np.random.normal(tenure_increase, 2, len(X_drifted))\n",
    "        X_drifted['tenure'] = X_drifted['tenure'].clip(lower=0)\n",
    "        drift_info['covariate_shifts'].append({\n",
    "            'feature': 'tenure',\n",
    "            'type': 'market_shift',\n",
    "            'increase_months': tenure_increase\n",
    "        })\n",
    "    \n",
    "    if 'MonthlyCharges' in X_drifted.columns:\n",
    "        inflation_rate = 1 + drift_threshold * 0.15\n",
    "        X_drifted['MonthlyCharges'] = X_drifted['MonthlyCharges'] * inflation_rate\n",
    "        drift_info['covariate_shifts'].append({\n",
    "            'feature': 'MonthlyCharges',\n",
    "            'type': 'inflation',\n",
    "            'rate': inflation_rate\n",
    "        })\n",
    "    \n",
    "    if 'TotalCharges' in X_drifted.columns:\n",
    "        if 'tenure' in X_drifted.columns and 'MonthlyCharges' in X_drifted.columns:\n",
    "            X_drifted['TotalCharges'] = X_drifted['tenure'] * X_drifted['MonthlyCharges'] * \\\n",
    "                                      (1 + np.random.normal(0, 0.1 * drift_threshold, len(X_drifted)))\n",
    "            X_drifted['TotalCharges'] = X_drifted['TotalCharges'].clip(lower=0)\n",
    "    \n",
    "    # 2. Categorical Feature Drifts\n",
    "    for col in categorical_cols[:min(5, len(categorical_cols))]:\n",
    "        if col not in X_drifted.columns:\n",
    "            continue\n",
    "        \n",
    "        unique_vals = X_drifted[col].unique()\n",
    "        if len(unique_vals) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Shift probability distributions\n",
    "        if col == 'InternetService' and 'Fiber optic' in unique_vals and 'DSL' in unique_vals:\n",
    "            mask_fiber = X_drifted[col] == 'DSL'\n",
    "            n_to_shift = int(len(X_drifted) * 0.2 * drift_threshold)\n",
    "            shift_indices = np.random.choice(X_drifted[mask_fiber].index[:n_to_shift], \n",
    "                                           size=min(n_to_shift, mask_fiber.sum()), \n",
    "                                           replace=False)\n",
    "            X_drifted.loc[shift_indices, col] = 'Fiber optic'\n",
    "            drift_info['covariate_shifts'].append({\n",
    "                'feature': col,\n",
    "                'type': 'category_probability_shift',\n",
    "                'shift': f'DSL -> Fiber optic ({len(shift_indices)} samples)'\n",
    "            })\n",
    "        \n",
    "        elif len(unique_vals) >= 2:\n",
    "            value_counts = X_drifted[col].value_counts()\n",
    "            if len(value_counts) >= 2:\n",
    "                most_common = value_counts.index[0]\n",
    "                least_common = value_counts.index[-1]\n",
    "                \n",
    "                n_to_shift = int(len(X_drifted) * 0.15 * drift_threshold)\n",
    "                mask = X_drifted[col] == most_common\n",
    "                if mask.sum() > 0:\n",
    "                    shift_indices = np.random.choice(X_drifted[mask].index, \n",
    "                                                   size=min(n_to_shift, mask.sum()), \n",
    "                                                   replace=False)\n",
    "                    X_drifted.loc[shift_indices, col] = least_common\n",
    "                    drift_info['covariate_shifts'].append({\n",
    "                        'feature': col,\n",
    "                        'type': 'category_distribution_shift',\n",
    "                        'shift': f'{most_common} -> {least_common} ({len(shift_indices)} samples)'\n",
    "                    })\n",
    "    \n",
    "    print(f\"âœ“ Applied {len(drift_info['covariate_shifts'])} covariate shifts\")\n",
    "    print(f\"âœ“ Applied {len(drift_info['concept_shifts'])} concept shifts (by design: 0)\")\n",
    "    print(f\"Final churn rate: {y_unchanged.mean():.3f} (unchanged from original: {y.mean():.3f})\")\n",
    "    \n",
    "    return X_drifted, y_unchanged, drift_info\n",
    "\n",
    "\n",
    "def simulate_concept_drift_only(X, y, drift_threshold=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Simulate ONLY concept drift (relationship changes) without covariate shifts.\n",
    "    Changes P(Y|X) while keeping P(X) the same.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Original feature dataframe (UNCHANGED in concept drift)\n",
    "    y : pd.Series\n",
    "        Original target labels (0/1)\n",
    "    drift_threshold : float\n",
    "        Controls the intensity of drift (0.0 to 1.0)\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X_unchanged : pd.DataFrame\n",
    "        Original feature dataframe (unchanged by definition)\n",
    "    y_drifted : pd.Series\n",
    "        Drifted target labels (new relationships)\n",
    "    drift_info : dict\n",
    "        Information about concept shifts applied\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    X_unchanged = X.copy() \n",
    "    y_drifted = y.copy()\n",
    "    \n",
    "    drift_info = {\n",
    "        'covariate_shifts': [], \n",
    "        'concept_shifts': [],\n",
    "        'threshold': drift_threshold,\n",
    "        'drift_type': 'concept_only'\n",
    "    }\n",
    "    \n",
    "    print(f\" Simulating CONCEPT DRIFT ONLY with threshold: {drift_threshold:.2f}\")\n",
    "    print(\"Note: Feature distributions remain unchanged (P(X) preserved)\")\n",
    "    print(\"Changing relationships between features and target (P(Y|X))\")\n",
    "    \n",
    "    # ============================================\n",
    "    # CONCEPT SHIFT: Changes to label relationships ONLY\n",
    "    # ============================================\n",
    "    \n",
    "    # 1. Reverse relationship for high-value customers\n",
    "    if 'MonthlyCharges' in X_unchanged.columns:\n",
    "        high_charge_threshold = X_unchanged['MonthlyCharges'].quantile(0.75)\n",
    "        high_charge_mask = X_unchanged['MonthlyCharges'] > high_charge_threshold\n",
    "        \n",
    "        n_to_flip = int(high_charge_mask.sum() * 0.3 * drift_threshold)\n",
    "        flip_indices = np.random.choice(X_unchanged[high_charge_mask].index, \n",
    "                                      size=min(n_to_flip, high_charge_mask.sum()), \n",
    "                                      replace=False)\n",
    "        y_drifted.loc[flip_indices] = 1 - y_drifted.loc[flip_indices]\n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'high_value_retention',\n",
    "            'description': 'High MonthlyCharges customers now less likely to churn',\n",
    "            'n_samples': len(flip_indices)\n",
    "        })\n",
    "    \n",
    "    # 2. Change relationship with tenure\n",
    "    if 'tenure' in X_unchanged.columns:\n",
    "        long_tenure_threshold = X_unchanged['tenure'].quantile(0.8)\n",
    "        long_tenure_mask = (X_unchanged['tenure'] > long_tenure_threshold) & (y_drifted == 0)\n",
    "        \n",
    "        n_to_flip = int(long_tenure_mask.sum() * 0.2 * drift_threshold)\n",
    "        flip_indices = np.random.choice(X_unchanged[long_tenure_mask].index, \n",
    "                                      size=min(n_to_flip, long_tenure_mask.sum()), \n",
    "                                      replace=False)\n",
    "        y_drifted.loc[flip_indices] = 1\n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'tenure_fatigue',\n",
    "            'description': 'Very long tenure customers more likely to churn',\n",
    "            'n_samples': len(flip_indices)\n",
    "        })\n",
    "    \n",
    "    # 3. Change relationship with service engagement\n",
    "    if 'service_engagement' in X_unchanged.columns:\n",
    "        high_engagement_threshold = X_unchanged['service_engagement'].quantile(0.7)\n",
    "        high_engagement_mask = (X_unchanged['service_engagement'] > high_engagement_threshold) & (y_drifted == 0)\n",
    "        \n",
    "        n_to_flip = int(high_engagement_mask.sum() * 0.25 * drift_threshold)\n",
    "        flip_indices = np.random.choice(X_unchanged[high_engagement_mask].index, \n",
    "                                      size=min(n_to_flip, high_engagement_mask.sum()), \n",
    "                                      replace=False)\n",
    "        y_drifted.loc[flip_indices] = 1\n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'service_overwhelm',\n",
    "            'description': 'High service engagement customers more likely to churn',\n",
    "            'n_samples': len(flip_indices)\n",
    "        })\n",
    "    \n",
    "    # 4. Contract type relationship change\n",
    "    if 'Contract' in X_unchanged.columns:\n",
    "        two_year_mask = (X_unchanged['Contract'] == 'Two year') & (y_drifted == 0)\n",
    "        n_to_flip = int(two_year_mask.sum() * 0.15 * drift_threshold)\n",
    "        flip_indices = np.random.choice(X_unchanged[two_year_mask].index, \n",
    "                                      size=min(n_to_flip, two_year_mask.sum()), \n",
    "                                      replace=False)\n",
    "        y_drifted.loc[flip_indices] = 1\n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'contract_regret',\n",
    "            'description': 'Two year contract customers more likely to churn',\n",
    "            'n_samples': len(flip_indices)\n",
    "        })\n",
    "    \n",
    "    # 5. Overall base rate shift\n",
    "    base_rate_shift = drift_threshold * 0.1\n",
    "    if base_rate_shift > 0:\n",
    "        current_churn_rate = y_drifted.mean()\n",
    "        target_churn_rate = min(1.0, current_churn_rate + base_rate_shift)\n",
    "        \n",
    "        n_current_churn = y_drifted.sum()\n",
    "        n_target_churn = int(len(y_drifted) * target_churn_rate)\n",
    "        n_to_change = abs(n_target_churn - n_current_churn)\n",
    "        \n",
    "        if n_target_churn > n_current_churn:\n",
    "            non_churners = X_unchanged[y_drifted == 0].index\n",
    "            flip_indices = np.random.choice(non_churners, \n",
    "                                          size=min(n_to_change, len(non_churners)), \n",
    "                                          replace=False)\n",
    "            y_drifted.loc[flip_indices] = 1\n",
    "        else:\n",
    "            churners = X_unchanged[y_drifted == 1].index\n",
    "            flip_indices = np.random.choice(churners, \n",
    "                                          size=min(n_to_change, len(churners)), \n",
    "                                          replace=False)\n",
    "            y_drifted.loc[flip_indices] = 0\n",
    "        \n",
    "        drift_info['concept_shifts'].append({\n",
    "            'type': 'base_rate_shift',\n",
    "            'description': f'Overall churn rate shifted from {current_churn_rate:.3f} to {target_churn_rate:.3f}',\n",
    "            'shift_amount': base_rate_shift\n",
    "        })\n",
    "    \n",
    "    print(f\"âœ“ Applied {len(drift_info['covariate_shifts'])} covariate shifts (by design: 0)\")\n",
    "    print(f\"âœ“ Applied {len(drift_info['concept_shifts'])} concept shifts\")\n",
    "    print(f\"Final churn rate: {y_drifted.mean():.3f} (original: {y.mean():.3f})\")\n",
    "    \n",
    "    return X_unchanged, y_drifted, drift_info\n",
    "\n",
    "\n",
    "def simulate_selective_drift(X, y, drift_threshold=0.5, \n",
    "                           covariate_ratio=0.75, concept_ratio=0.25, \n",
    "                           random_state=42):\n",
    "    \"\"\"\n",
    "    Simulate drift with customizable balance between covariate and concept shifts.\n",
    "    This gives you full control over the type and intensity of drift.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Original feature dataframe\n",
    "    y : pd.Series\n",
    "        Original target labels (0/1)\n",
    "    drift_threshold : float\n",
    "        Controls overall intensity of drift (0.0 to 1.0)\n",
    "    covariate_ratio : float\n",
    "        Fraction of drift intensity applied to covariate shifts (0.0 to 1.0)\n",
    "    concept_ratio : float\n",
    "        Fraction of drift intensity applied to concept shifts (0.0 to 1.0)\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X_drifted : pd.DataFrame\n",
    "        Drifted feature dataframe\n",
    "    y_drifted : pd.Series\n",
    "        Drifted target labels\n",
    "    drift_info : dict\n",
    "        Information about all shifts applied\n",
    "    \"\"\"\n",
    "    print(f\" Simulating SELECTIVE DRIFT with threshold: {drift_threshold:.2f}\")\n",
    "    print(f\"   Covariate intensity: {covariate_ratio:.2f} | Concept intensity: {concept_ratio:.2f}\")\n",
    "    \n",
    "    # Start with original data\n",
    "    X_result = X.copy()\n",
    "    y_result = y.copy()\n",
    "    \n",
    "    combined_drift_info = {\n",
    "        'covariate_shifts': [],\n",
    "        'concept_shifts': [],\n",
    "        'threshold': drift_threshold,\n",
    "        'covariate_ratio': covariate_ratio,\n",
    "        'concept_ratio': concept_ratio,\n",
    "        'drift_type': 'selective'\n",
    "    }\n",
    "    \n",
    "    # Apply covariate drift if requested\n",
    "    if covariate_ratio > 0:\n",
    "        covariate_threshold = drift_threshold * covariate_ratio\n",
    "        X_result, _, cov_info = simulate_covariate_drift_only(\n",
    "            X_result, y_result, \n",
    "            drift_threshold=covariate_threshold, \n",
    "            random_state=random_state\n",
    "        )\n",
    "        combined_drift_info['covariate_shifts'] = cov_info['covariate_shifts']\n",
    "    \n",
    "    # Apply concept drift if requested\n",
    "    if concept_ratio > 0:\n",
    "        concept_threshold = drift_threshold * concept_ratio\n",
    "        _, y_result, con_info = simulate_concept_drift_only(\n",
    "            X_result, y_result, \n",
    "            drift_threshold=concept_threshold, \n",
    "            random_state=random_state + 1  # Different seed\n",
    "        )\n",
    "        combined_drift_info['concept_shifts'] = con_info['concept_shifts']\n",
    "    \n",
    "    print(f\"âœ“ Combined: {len(combined_drift_info['covariate_shifts'])} covariate + \"\n",
    "          f\"{len(combined_drift_info['concept_shifts'])} concept shifts\")\n",
    "    print(f\"Final churn rate: {y_result.mean():.3f} (original: {y.mean():.3f})\")\n",
    "    \n",
    "    return X_result, y_result, combined_drift_info\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1427f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ddla_drift_comparison(X, y, trained_pipeline, drift_thresholds,\n",
    "                              experiment_name=\"telco-ddla-drift-comparison\",\n",
    "                              random_state=42):  \n",
    "    \"\"\"\n",
    "    Run DDLA experiments across different drift types to test the approach's sensitivity.\n",
    "    \n",
    "    This will test:\n",
    "    1. Pure covariate drift (DDLA's intended scenario)\n",
    "    2. Pure concept drift (DDLA's weakness)\n",
    "    3. Combined drift (your original realistic scenario)\n",
    "    \"\"\"\n",
    "    print(\" Starting DDLA Drift Type Comparison Experiment\")\n",
    "    print(f\"Testing thresholds: {drift_thresholds}\")\n",
    "    \n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Baseline setup\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # Identify DDLAs once on baseline\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"IDENTIFYING DDLAs ON BASELINE DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ddla_info = identify_ddlas_decision_tree(trained_pipeline, X_test, y_test, random_state=random_state)\n",
    "    \n",
    "    # Test different drift scenarios\n",
    "    drift_scenarios = [\n",
    "        {\n",
    "            'name': 'covariate_only',\n",
    "            'description': 'Pure Covariate Drift (DDLA\\'s intended use case)',\n",
    "            'function': simulate_covariate_drift_only\n",
    "        },\n",
    "        {\n",
    "            'name': 'concept_only', \n",
    "            'description': 'Pure Concept Drift (DDLA\\'s weakness)',\n",
    "            'function': simulate_concept_drift_only\n",
    "        },\n",
    "        {\n",
    "            'name': 'combined_drift',\n",
    "            'description': 'Combined Drift (your original realistic scenario)',\n",
    "            'function': simulate_drifted_data  # Your original function\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for scenario in drift_scenarios:\n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(f\"TESTING: {scenario['description'].upper()}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        scenario_results = []\n",
    "        \n",
    "        for threshold in drift_thresholds:\n",
    "            print(f\"\\n {scenario['name']} - Threshold: {threshold:.2f}\")\n",
    "            \n",
    "            with mlflow.start_run(run_name=f'{scenario[\"name\"]}_threshold_{threshold}'):\n",
    "                # Generate drift using appropriate function\n",
    "                X_drifted, y_drifted, drift_info_scenario = scenario['function'](\n",
    "                    X, y, drift_threshold=threshold, random_state=random_state\n",
    "                )\n",
    "                \n",
    "                # Split drifted data\n",
    "                _, X_test_drifted, _, y_test_drifted = train_test_split(\n",
    "                    X_drifted, y_drifted, test_size=0.2, random_state=random_state\n",
    "                )\n",
    "                \n",
    "                # Test DDLA detection\n",
    "                drift_detection = detect_harmful_drift_ddla(\n",
    "                    ddla_info, X_test_drifted, trained_pipeline\n",
    "                )\n",
    "                \n",
    "                # Calculate actual performance\n",
    "                y_pred_drifted = trained_pipeline.predict(X_test_drifted)\n",
    "                actual_accuracy = accuracy_score(y_test_drifted, y_pred_drifted)\n",
    "                accuracy_drop = ddla_info['overall_accuracy'] - actual_accuracy\n",
    "                \n",
    "                # Ground truth\n",
    "                significant_degradation = accuracy_drop > 0.05\n",
    "                ddla_correct = drift_detection['is_harmful_drift'] == significant_degradation\n",
    "                \n",
    "                # Store results\n",
    "                result = {\n",
    "                    'scenario': scenario['name'],\n",
    "                    'threshold': threshold,\n",
    "                    'ddla_detected_harmful': drift_detection['is_harmful_drift'],\n",
    "                    'actually_needs_retraining': significant_degradation,\n",
    "                    'ddla_correct': ddla_correct,\n",
    "                    'accuracy_drop': accuracy_drop,\n",
    "                    'accuracy_drop_pct': (accuracy_drop / ddla_info['overall_accuracy']) * 100,\n",
    "                    'ratio_train': drift_detection['ratio_train'],\n",
    "                    'ratio_serving': drift_detection['ratio_serving'],\n",
    "                    'n_covariate_shifts': len(drift_info_scenario['covariate_shifts']),\n",
    "                    'n_concept_shifts': len(drift_info_scenario['concept_shifts'])\n",
    "                }\n",
    "                \n",
    "                scenario_results.append(result)\n",
    "                \n",
    "                # Log to MLflow\n",
    "                mlflow.log_param('drift_scenario', scenario['name'])\n",
    "                mlflow.log_param('drift_threshold', threshold)\n",
    "                mlflow.log_param('ddla_approach', 'authentic_dong_2024')\n",
    "                \n",
    "                # Log key metrics\n",
    "                mlflow.log_metric('ddla_detected_harmful', 1 if drift_detection['is_harmful_drift'] else 0)\n",
    "                mlflow.log_metric('actually_needs_retraining', 1 if significant_degradation else 0)\n",
    "                mlflow.log_metric('ddla_correct', 1 if ddla_correct else 0)\n",
    "                mlflow.log_metric('accuracy_drop_pct', result['accuracy_drop_pct'])\n",
    "                mlflow.log_metric('ratio_train', drift_detection['ratio_train'])\n",
    "                mlflow.log_metric('ratio_serving', drift_detection['ratio_serving'])\n",
    "                \n",
    "                # Print results\n",
    "                print(f\"  DDLA says: {'HARMFUL' if drift_detection['is_harmful_drift'] else 'BENIGN'}\")\n",
    "                print(f\"  Actually needs retraining: {'YES' if significant_degradation else 'NO'}\")\n",
    "                print(f\"  DDLA correct: {'YES' if ddla_correct else 'NO'}\")\n",
    "                print(f\"  Accuracy drop: {accuracy_drop:.4f} ({result['accuracy_drop_pct']:.1f}%)\")\n",
    "        \n",
    "        all_results[scenario['name']] = scenario_results\n",
    "    \n",
    "    # Create comprehensive comparison visualization\n",
    "    create_drift_comparison_visualization(all_results, experiment_name)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "def create_drift_comparison_visualization(all_results, experiment_name):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization comparing DDLA performance across drift types.\n",
    "    \"\"\"\n",
    "    print(\"\\n Creating Drift Type Comparison Visualizations...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('DDLA Performance Across Different Drift Types', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    scenarios = list(all_results.keys())\n",
    "    colors = {'covariate_only': '#2ecc71', 'concept_only': '#e74c3c', 'combined_drift': '#f39c12'}\n",
    "    \n",
    "    # 1. Accuracy Rate by Scenario\n",
    "    ax1 = axes[0, 0]\n",
    "    scenario_accuracies = []\n",
    "    scenario_names = []\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        results = all_results[scenario]\n",
    "        correct_decisions = [r['ddla_correct'] for r in results]\n",
    "        accuracy_rate = np.mean(correct_decisions) * 100\n",
    "        scenario_accuracies.append(accuracy_rate)\n",
    "        scenario_names.append(scenario.replace('_', ' ').title())\n",
    "    \n",
    "    bars = ax1.bar(scenario_names, scenario_accuracies, color=[colors[s] for s in scenarios], alpha=0.8)\n",
    "    ax1.set_ylabel('DDLA Accuracy Rate (%)')\n",
    "    ax1.set_title('DDLA Decision Accuracy by Drift Type')\n",
    "    ax1.set_ylim([0, 100])\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, accuracy in zip(bars, scenario_accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "                f'{accuracy:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. DDLA Accuracy vs Drift Threshold\n",
    "    ax2 = axes[0, 1]\n",
    "    for scenario in scenarios:\n",
    "        results = all_results[scenario]\n",
    "        thresholds = [r['threshold'] for r in results]\n",
    "        accuracies = [r['ddla_correct'] for r in results]\n",
    "        ax2.plot(thresholds, accuracies, 'o-', label=scenario.replace('_', ' ').title(), \n",
    "                color=colors[scenario], linewidth=2, markersize=6)\n",
    "    \n",
    "    ax2.set_xlabel('Drift Threshold')\n",
    "    ax2.set_ylabel('DDLA Correct Decision (1=Yes, 0=No)')\n",
    "    ax2.set_title('DDLA Accuracy Across Thresholds')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Actual Performance Drop vs DDLA Detection\n",
    "    ax3 = axes[1, 0]\n",
    "    for scenario in scenarios:\n",
    "        results = all_results[scenario]\n",
    "        performance_drops = [r['accuracy_drop_pct'] for r in results]\n",
    "        ddla_detections = [1 if r['ddla_detected_harmful'] else 0 for r in results]\n",
    "        \n",
    "        # Scatter plot with jitter for visibility\n",
    "        x_jitter = np.array(ddla_detections) + np.random.normal(0, 0.05, len(ddla_detections))\n",
    "        ax3.scatter(x_jitter, performance_drops, label=scenario.replace('_', ' ').title(),\n",
    "                   color=colors[scenario], alpha=0.7, s=60)\n",
    "    \n",
    "    ax3.axhline(y=5, color='orange', linestyle='--', label='5% significance threshold')\n",
    "    ax3.set_xlabel('DDLA Detection (0=Benign, 1=Harmful)')\n",
    "    ax3.set_ylabel('Actual Performance Drop (%)')\n",
    "    ax3.set_title('Performance Drop vs DDLA Prediction')\n",
    "    ax3.legend()\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Confusion Matrix Heatmap\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Calculate confusion matrices for each scenario\n",
    "    confusion_data = np.zeros((len(scenarios), 4))  # [TP, TN, FP, FN]\n",
    "    \n",
    "    for i, scenario in enumerate(scenarios):\n",
    "        results = all_results[scenario]\n",
    "        tp = sum(1 for r in results if r['ddla_detected_harmful'] and r['actually_needs_retraining'])\n",
    "        tn = sum(1 for r in results if not r['ddla_detected_harmful'] and not r['actually_needs_retraining'])\n",
    "        fp = sum(1 for r in results if r['ddla_detected_harmful'] and not r['actually_needs_retraining'])\n",
    "        fn = sum(1 for r in results if not r['ddla_detected_harmful'] and r['actually_needs_retraining'])\n",
    "        \n",
    "        total = tp + tn + fp + fn\n",
    "        if total > 0:\n",
    "            confusion_data[i] = [tp/total, tn/total, fp/total, fn/total]\n",
    "    \n",
    "    # Create stacked bar chart for confusion matrix\n",
    "    bottom = np.zeros(len(scenarios))\n",
    "    metrics = ['True Positive', 'True Negative', 'False Positive', 'False Negative']\n",
    "    metric_colors = ['#27ae60', '#2ecc71', '#e74c3c', '#c0392b']\n",
    "    \n",
    "    for j, metric in enumerate(metrics):\n",
    "        ax4.bar(scenario_names, confusion_data[:, j], bottom=bottom, \n",
    "               label=metric, color=metric_colors[j], alpha=0.8)\n",
    "        bottom += confusion_data[:, j]\n",
    "    \n",
    "    ax4.set_ylabel('Proportion')\n",
    "    ax4.set_title('DDLA Decision Distribution by Drift Type')\n",
    "    ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax4.set_ylim([0, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save and log\n",
    "    comparison_plot_path = f'ddla_drift_comparison_{experiment_name.replace(\"-\", \"_\")}.png'\n",
    "    plt.savefig(comparison_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Log summary to MLflow\n",
    "    with mlflow.start_run(run_name='drift_comparison_summary'):\n",
    "        mlflow.log_param('experiment_type', 'drift_comparison_summary')\n",
    "        mlflow.log_param('scenarios_tested', len(scenarios))\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        for scenario in scenarios:\n",
    "            results = all_results[scenario]\n",
    "            accuracy_rate = np.mean([r['ddla_correct'] for r in results]) * 100\n",
    "            mlflow.log_metric(f'{scenario}_accuracy_rate', accuracy_rate)\n",
    "        \n",
    "        mlflow.log_artifact(comparison_plot_path, artifact_path='plots')\n",
    "        \n",
    "        print(f\"Drift Comparison Summary logged to MLflow\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"DDLA PERFORMANCE SUMMARY BY DRIFT TYPE\")\n",
    "        print(\"=\"*80)\n",
    "        for scenario in scenarios:\n",
    "            results = all_results[scenario]\n",
    "            accuracy_rate = np.mean([r['ddla_correct'] for r in results]) * 100\n",
    "            print(f\"{scenario.replace('_', ' ').title():<25}: {accuracy_rate:.1f}% accuracy\")\n",
    "    \n",
    "    return comparison_plot_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f47f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:26:17 INFO mlflow.tracking.fluent: Experiment with name 'telco-ddla-drift-type-comparison' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting DDLA Drift Type Comparison Experiment\n",
      "Testing thresholds: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      "\n",
      "======================================================================\n",
      "IDENTIFYING DDLAs ON BASELINE DATA\n",
      "======================================================================\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 7, 'min_samples_leaf': 28}\n",
      "  Decision tree F1 score: 0.4888\n",
      " Found 9 DDLAs out of 27 total leaf nodes\n",
      " DDLA coverage: 585/1409 samples (0.415)\n",
      "\n",
      "======================================================================\n",
      "TESTING: PURE COVARIATE DRIFT (DDLA'S INTENDED USE CASE)\n",
      "======================================================================\n",
      "\n",
      " covariate_only - Threshold: 0.00\n",
      "Simulating covariate drift with threshold: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4145\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA fraction decreased or stayed same\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: NO\n",
      "  DDLA correct: YES\n",
      "  Accuracy drop: -0.0014 (-0.2%)\n",
      "ðŸƒ View run covariate_only_threshold_0.0 at: http://localhost:5000/#/experiments/5/runs/be3a90010c2a4da6a0f39ef864794366\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " covariate_only - Threshold: 0.25\n",
      "Simulating covariate drift with threshold: 0.25\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4315\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 3.93% below threshold 50.0%\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: NO\n",
      "  DDLA correct: YES\n",
      "  Accuracy drop: 0.0021 (0.3%)\n",
      "ðŸƒ View run covariate_only_threshold_0.25 at: http://localhost:5000/#/experiments/5/runs/fd301b2bad7c4223b24ae93991f611ec\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " covariate_only - Threshold: 0.50\n",
      "Simulating covariate drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4379\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 5.47% below threshold 50.0%\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: NO\n",
      "  DDLA correct: YES\n",
      "  Accuracy drop: 0.0106 (1.3%)\n",
      "ðŸƒ View run covariate_only_threshold_0.5 at: http://localhost:5000/#/experiments/5/runs/b45ab1f7e33047aea0576609f5afdd8d\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " covariate_only - Threshold: 0.75\n",
      "Simulating covariate drift with threshold: 0.75\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4258\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 2.56% below threshold 50.0%\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: NO\n",
      "  DDLA correct: YES\n",
      "  Accuracy drop: 0.0128 (1.6%)\n",
      "ðŸƒ View run covariate_only_threshold_0.75 at: http://localhost:5000/#/experiments/5/runs/a595b0cd368c45f799a1bba7fb2794b2\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " covariate_only - Threshold: 1.00\n",
      "Simulating covariate drift with threshold: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4365\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 5.13% below threshold 50.0%\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: NO\n",
      "  DDLA correct: YES\n",
      "  Accuracy drop: 0.0156 (2.0%)\n",
      "ðŸƒ View run covariate_only_threshold_1.0 at: http://localhost:5000/#/experiments/5/runs/d922a0ff6ffb496daeaf624a7fe51a1f\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      "======================================================================\n",
      "TESTING: PURE CONCEPT DRIFT (DDLA'S WEAKNESS)\n",
      "======================================================================\n",
      "\n",
      " concept_only - Threshold: 0.00\n",
      "Simulating concept drift with threshold: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4152\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA fraction decreased or stayed same\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: NO\n",
      "  DDLA correct: YES\n",
      "  Accuracy drop: 0.0000 (0.0%)\n",
      "ðŸƒ View run concept_only_threshold_0.0 at: http://localhost:5000/#/experiments/5/runs/7ea09ec7a1594225848fe24a8f3393c7\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " concept_only - Threshold: 0.25\n",
      "Simulating concept drift with threshold: 0.25\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4152\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA fraction decreased or stayed same\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA correct: NO\n",
      "  Accuracy drop: 0.0582 (7.3%)\n",
      "ðŸƒ View run concept_only_threshold_0.25 at: http://localhost:5000/#/experiments/5/runs/e331e92c46a34f1f98422ea129db9cad\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " concept_only - Threshold: 0.50\n",
      "Simulating concept drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4152\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA fraction decreased or stayed same\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA correct: NO\n",
      "  Accuracy drop: 0.0830 (10.5%)\n",
      "ðŸƒ View run concept_only_threshold_0.5 at: http://localhost:5000/#/experiments/5/runs/c38a13831e914938a98834439c46b1fa\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " concept_only - Threshold: 0.75\n",
      "Simulating concept drift with threshold: 0.75\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.427 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4152\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA fraction decreased or stayed same\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA correct: NO\n",
      "  Accuracy drop: 0.1221 (15.4%)\n",
      "ðŸƒ View run concept_only_threshold_0.75 at: http://localhost:5000/#/experiments/5/runs/e671cf975a39404e8706ddacd22be749\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " concept_only - Threshold: 1.00\n",
      "Simulating concept drift with threshold: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.475 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4152\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA fraction decreased or stayed same\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA correct: NO\n",
      "  Accuracy drop: 0.1859 (23.4%)\n",
      "ðŸƒ View run concept_only_threshold_1.0 at: http://localhost:5000/#/experiments/5/runs/73bcb6c4ed764a14a64a16ed9496b294\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      "======================================================================\n",
      "TESTING: COMBINED DRIFT (YOUR ORIGINAL REALISTIC SCENARIO)\n",
      "======================================================================\n",
      "\n",
      " combined_drift - Threshold: 0.00\n",
      "Simulating combined drift with threshold: 0.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4145\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA fraction decreased or stayed same\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: NO\n",
      "  DDLA correct: YES\n",
      "  Accuracy drop: -0.0014 (-0.2%)\n",
      "ðŸƒ View run combined_drift_threshold_0.0 at: http://localhost:5000/#/experiments/5/runs/ce480727fc8a496ea6f5fb49c0ed07d4\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " combined_drift - Threshold: 0.25\n",
      "Simulating combined drift with threshold: 0.25\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4315\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 3.93% below threshold 50.0%\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA correct: NO\n",
      "  Accuracy drop: 0.0546 (6.9%)\n",
      "ðŸƒ View run combined_drift_threshold_0.25 at: http://localhost:5000/#/experiments/5/runs/a6352c6474b74d5299692cf591678969\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " combined_drift - Threshold: 0.50\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4379\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 5.47% below threshold 50.0%\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA correct: NO\n",
      "  Accuracy drop: 0.1015 (12.8%)\n",
      "ðŸƒ View run combined_drift_threshold_0.5 at: http://localhost:5000/#/experiments/5/runs/99c96023eab54e72972765b061585121\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " combined_drift - Threshold: 0.75\n",
      "Simulating combined drift with threshold: 0.75\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.430 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4258\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 2.56% below threshold 50.0%\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA correct: NO\n",
      "  Accuracy drop: 0.1490 (18.8%)\n",
      "ðŸƒ View run combined_drift_threshold_0.75 at: http://localhost:5000/#/experiments/5/runs/8f7ba696dafc4f6eb0c587c36d40fe46\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " combined_drift - Threshold: 1.00\n",
      "Simulating combined drift with threshold: 1.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.478 (original: 0.265)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.4152\n",
      "  Serving DDLA fraction: 0.4365\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 5.13% below threshold 50.0%\n",
      "  DDLA says: BENIGN\n",
      "  Actually needs retraining: YES\n",
      "  DDLA correct: NO\n",
      "  Accuracy drop: 0.1874 (23.6%)\n",
      "ðŸƒ View run combined_drift_threshold_1.0 at: http://localhost:5000/#/experiments/5/runs/e092bd13b9a54f979a4ce03024842251\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      " Creating Drift Type Comparison Visualizations...\n",
      "Drift Comparison Summary logged to MLflow\n",
      "\n",
      "================================================================================\n",
      "DDLA PERFORMANCE SUMMARY BY DRIFT TYPE\n",
      "================================================================================\n",
      "Covariate Only           : 100.0% accuracy\n",
      "Concept Only             : 20.0% accuracy\n",
      "Combined Drift           : 20.0% accuracy\n",
      "ðŸƒ View run drift_comparison_summary at: http://localhost:5000/#/experiments/5/runs/564550d0c1be488383dd144386525cad\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/5\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE DDLA DRIFT TYPE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Covariate Only Results:\n",
      "  Overall Accuracy: 5/5 (100.0%)\n",
      "  Threshold    DDLA Says    Actually     Correct    Acc Drop    \n",
      "  ------------------------------------------------------------\n",
      "  0.00         BENIGN       NO           YES        -0.2        %\n",
      "  0.25         BENIGN       NO           YES        0.3         %\n",
      "  0.50         BENIGN       NO           YES        1.3         %\n",
      "  0.75         BENIGN       NO           YES        1.6         %\n",
      "  1.00         BENIGN       NO           YES        2.0         %\n",
      "\n",
      "Concept Only Results:\n",
      "  Overall Accuracy: 1/5 (20.0%)\n",
      "  Threshold    DDLA Says    Actually     Correct    Acc Drop    \n",
      "  ------------------------------------------------------------\n",
      "  0.00         BENIGN       NO           YES        0.0         %\n",
      "  0.25         BENIGN       YES          NO         7.3         %\n",
      "  0.50         BENIGN       YES          NO         10.5        %\n",
      "  0.75         BENIGN       YES          NO         15.4        %\n",
      "  1.00         BENIGN       YES          NO         23.4        %\n",
      "\n",
      "Combined Drift Results:\n",
      "  Overall Accuracy: 1/5 (20.0%)\n",
      "  Threshold    DDLA Says    Actually     Correct    Acc Drop    \n",
      "  ------------------------------------------------------------\n",
      "  0.00         BENIGN       NO           YES        -0.2        %\n",
      "  0.25         BENIGN       YES          NO         6.9         %\n",
      "  0.50         BENIGN       YES          NO         12.8        %\n",
      "  0.75         BENIGN       YES          NO         18.8        %\n",
      "  1.00         BENIGN       YES          NO         23.6        %\n",
      "\n",
      "============================================================\n",
      "TESTING PURE COVARIATE DRIFT\n",
      "============================================================\n",
      "Simulating covariate drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "\n",
      "============================================================\n",
      "TESTING PURE CONCEPT DRIFT\n",
      "============================================================\n",
      "Simulating concept drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      "\n",
      "============================================================\n",
      "TESTING CUSTOM BALANCED DRIFT\n",
      "============================================================\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 0.75, Concept weight: 0.25\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.294 (original: 0.265)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# DDLA EXPERIMENT WITH DIFFERENT DRIFT TYPES\n",
    "# ==============================================================\n",
    "\n",
    "# Test DDLA performance across different drift types\n",
    "drift_comparison_results = run_ddla_drift_comparison(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    trained_pipeline=pipeline,\n",
    "    drift_thresholds=[0.0, 0.25, 0.5, 0.75, 1.0],\n",
    "    experiment_name=\"telco-ddla-drift-type-comparison\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Print comprehensive comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE DDLA DRIFT TYPE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for drift_type, results in drift_comparison_results.items():\n",
    "    correct_predictions = sum(r['ddla_correct'] for r in results)\n",
    "    total_predictions = len(results)\n",
    "    accuracy_rate = (correct_predictions / total_predictions) * 100\n",
    "    \n",
    "    print(f\"\\n{drift_type.replace('_', ' ').title()} Results:\")\n",
    "    print(f\"  Overall Accuracy: {correct_predictions}/{total_predictions} ({accuracy_rate:.1f}%)\")\n",
    "    \n",
    "    print(f\"  {'Threshold':<12} {'DDLA Says':<12} {'Actually':<12} {'Correct':<10} {'Acc Drop':<12}\")\n",
    "    print(\"  \" + \"-\" * 60)\n",
    "    \n",
    "    for r in results:\n",
    "        ddla_decision = \"HARMFUL\" if r['ddla_detected_harmful'] else \"BENIGN\"\n",
    "        actual_need = \"YES\" if r['actually_needs_retraining'] else \"NO\"\n",
    "        correct =  \"YES\" if r['ddla_correct'] else \"NO\"\n",
    "        \n",
    "        print(f\"  {r['threshold']:<12.2f} {ddla_decision:<12} {actual_need:<12} \"\n",
    "              f\"{correct:<10} {r['accuracy_drop_pct']:<12.1f}%\")\n",
    "\n",
    "# You can also test specific scenarios individually:\n",
    "\n",
    "# Test ONLY covariate drift (DDLA's intended scenario)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING PURE COVARIATE DRIFT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_cov_drifted, y_cov_unchanged, cov_drift_info = simulate_covariate_drift_only(\n",
    "    X, y, drift_threshold=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Test ONLY concept drift (where DDLA should fail)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING PURE CONCEPT DRIFT\") \n",
    "print(\"=\"*60)\n",
    "\n",
    "X_con_unchanged, y_con_drifted, con_drift_info = simulate_concept_drift_only(\n",
    "    X, y, drift_threshold=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Test custom balance (75% covariate, 25% concept)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING CUSTOM BALANCED DRIFT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_selective, y_selective, selective_drift_info = simulate_selective_drift(\n",
    "    X, y, drift_threshold=0.5, \n",
    "    covariate_ratio=0.75, concept_ratio=0.25, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ddf22b",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "DDLAs are able to accurately determine low accuracy regions for covariate drifts only - they start to fail when subjected to concept and combined drift scenarios. The accuracy drop of the DDLAs show us how they perform when they are subject to different drift scenarios. This essentially means that this method is limited in viability when it comes to production systems. Naturally, this is natural given that the authors explicitly state this in their Limitations and Future Work sections - where they contemplate on using Explanation Tables and other methods for a similar approach to mitigating drift. \n",
    "\n",
    "This gives rise to a potential research avenue:\n",
    "\n",
    "- What if we use clustering instead of a single decision tree to identify low accuracy areas?\n",
    "\n",
    "Literature suggests that clustering based methodology has been used in this context for multiple use cases. For example, [Mishara & Stamp (2025)](https://arxiv.org/abs/2502.14135) use a clustering based approach (K-Means) to detect concept drift and a specific threshold to trigger model retraining, and a silhouette score which exerts less strain on available compute compared to other methods vastly due to the reduced number of times retraining is triggered. Similarly, [Razaei & Sajedi (2025)](https://link.springer.com/article/10.1007/s10115-025-02484-5) use a \"fractal-dimension\" stream clustering algorithm to detect concept drift and pattern recurrence to address data streaming challenges with respect to sensitivity to concept drift, compute efficiency, and adaptability. [Yu et al. (2021)](https://arxiv.org/pdf/2105.01419) propose a meta learning model for drift detection that is capable of the detection of all kinds of drifts within data streams and tabular data. \n",
    "\n",
    "Applying a clustering based DDLA approach could help us better understand how unsupervised frameworks are able to deal with low accruracy regions to advise retrianing when no active learning options are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3de553",
   "metadata": {},
   "source": [
    "## DDLA-Clustering approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2acc8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def find_optimal_error_clusters(X_errors_preprocessed, n_clusters_range=(3, 12), random_state=42):\n",
    "    \"\"\"\n",
    "    Find optimal number of clusters for error patterns using multiple metrics.\n",
    "    This is specifically designed for clustering model failures.\n",
    "    \"\"\"\n",
    "    if len(X_errors_preprocessed) < 6:  # Need at least 6 samples for meaningful clustering\n",
    "        print(f\"    Too few error samples ({len(X_errors_preprocessed)}) for clustering\")\n",
    "        return None, 0\n",
    "    \n",
    "    best_score = -1\n",
    "    best_k = n_clusters_range[0]\n",
    "    best_kmeans = None\n",
    "    scoring_results = []\n",
    "    \n",
    "    print(f\"   Finding optimal clusters for {len(X_errors_preprocessed)} error samples...\")\n",
    "    \n",
    "    for k in range(n_clusters_range[0], min(n_clusters_range[1] + 1, len(X_errors_preprocessed))):\n",
    "        try:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=random_state, n_init=10)\n",
    "            cluster_labels = kmeans.fit_predict(X_errors_preprocessed)\n",
    "            \n",
    "            # Skip if all samples in one cluster\n",
    "            if len(np.unique(cluster_labels)) < 2:\n",
    "                continue\n",
    "                \n",
    "            # Calculate multiple clustering quality metrics\n",
    "            silhouette = silhouette_score(X_errors_preprocessed, cluster_labels)\n",
    "            calinski_harabasz = calinski_harabasz_score(X_errors_preprocessed, cluster_labels)\n",
    "            \n",
    "            # Combined score (weighted)\n",
    "            combined_score = 0.7 * silhouette + 0.3 * (calinski_harabasz / 1000)  # Normalize CH score\n",
    "            \n",
    "            scoring_results.append({\n",
    "                'k': k,\n",
    "                'silhouette': silhouette,\n",
    "                'calinski_harabasz': calinski_harabasz,\n",
    "                'combined_score': combined_score\n",
    "            })\n",
    "            \n",
    "            if combined_score > best_score:\n",
    "                best_score = combined_score\n",
    "                best_k = k\n",
    "                best_kmeans = kmeans\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Error with k={k}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if best_kmeans is None:\n",
    "        print(f\"Could not find valid clustering\")\n",
    "        return None, 0\n",
    "    \n",
    "    print(f\"Optimal clusters: {best_k} (score: {best_score:.3f})\")\n",
    "    \n",
    "    return best_kmeans, best_k\n",
    "\n",
    "\n",
    "def identify_ddlas_error_clustering(trained_pipeline, X_test, y_test, \n",
    "                                   n_clusters_range=(3, 12), random_state=42):\n",
    "    \"\"\"\n",
    "    This revolutionary approach:\n",
    "    1. Focuses ONLY on incorrectly predicted samples\n",
    "    2. Clusters these error samples to find failure patterns  \n",
    "    3. Maps all data to these error-derived clusters\n",
    "    4. Identifies which clusters represent DDLAs\n",
    "    \n",
    "    This should be more robust to concept drift than decision trees!\n",
    "    \"\"\"\n",
    "    print(\"Identifying DDLAs using Error-Driven Clustering...\")\n",
    "    print(\"This is the world's first implementation of this approach! ðŸŒŸ\")\n",
    "    \n",
    "    # Step 1: Get model predictions and overall accuracy\n",
    "    y_pred = trained_pipeline.predict(X_test)\n",
    "    y_prob = trained_pipeline.predict_proba(X_test)\n",
    "    overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "    overall_error_rate = 1 - overall_accuracy\n",
    "    \n",
    "    print(f\"  Overall model accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"  Overall error rate: {overall_error_rate:.4f}\")\n",
    "    \n",
    "    # Step 2: Focus ONLY on model errors\n",
    "    error_mask = (y_pred != y_test)\n",
    "    X_errors = X_test[error_mask].copy()\n",
    "    y_errors_true = y_test[error_mask]\n",
    "    y_errors_pred = y_pred[error_mask]\n",
    "    y_errors_prob = y_prob[error_mask]\n",
    "    \n",
    "    print(f\"   Focusing on {len(X_errors)} error samples out of {len(X_test)} total\")\n",
    "    \n",
    "    if len(X_errors) < 6:\n",
    "        print(\"    Too few errors for meaningful clustering. Returning empty DDLAs.\")\n",
    "        return {\n",
    "            'ddlas': [],\n",
    "            'error_clusters': None, \n",
    "            'overall_accuracy': overall_accuracy,\n",
    "            'overall_error_rate': overall_error_rate,\n",
    "            'ddla_ratio_baseline': 0.0,\n",
    "            'error_sample_count': len(X_errors),\n",
    "            'total_sample_count': len(X_test),\n",
    "            'feature_names': [],\n",
    "            'approach': 'error_driven_clustering'\n",
    "        }\n",
    "    \n",
    "    # Step 3: Preprocess error samples in the SAME space the model sees\n",
    "    X_errors_preprocessed = trained_pipeline.named_steps['preprocessor'].transform(X_errors)\n",
    "    \n",
    "    # Get feature names for interpretability\n",
    "    try:\n",
    "        feature_names = trained_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "    except:\n",
    "        n_features = X_errors_preprocessed.shape[1]\n",
    "        feature_names = [f'feature_{i}' for i in range(n_features)]\n",
    "    \n",
    "    print(f\"   Error samples have {len(feature_names)} features after preprocessing\")\n",
    "    \n",
    "    # Step 4: Find optimal clustering of ERROR PATTERNS\n",
    "    error_kmeans, optimal_k = find_optimal_error_clusters(\n",
    "        X_errors_preprocessed, n_clusters_range, random_state\n",
    "    )\n",
    "    \n",
    "    if error_kmeans is None:\n",
    "        print(\"Could not cluster error patterns. Returning empty DDLAs.\")\n",
    "        return {\n",
    "            'ddlas': [],\n",
    "            'error_clusters': None,\n",
    "            'overall_accuracy': overall_accuracy,\n",
    "            'overall_error_rate': overall_error_rate,\n",
    "            'ddla_ratio_baseline': 0.0,\n",
    "            'error_sample_count': len(X_errors),\n",
    "            'total_sample_count': len(X_test),\n",
    "            'feature_names': feature_names,\n",
    "            'approach': 'error_driven_clustering'\n",
    "        }\n",
    "    \n",
    "    # Step 5: Assign ERROR cluster labels\n",
    "    error_cluster_labels = error_kmeans.predict(X_errors_preprocessed)\n",
    "    \n",
    "    print(f\"   Found {optimal_k} distinct error patterns\")\n",
    "    \n",
    "    # Step 6: Map ALL data to these error-derived clusters\n",
    "    X_all_preprocessed = trained_pipeline.named_steps['preprocessor'].transform(X_test)\n",
    "    all_cluster_labels = error_kmeans.predict(X_all_preprocessed)\n",
    "    \n",
    "    # Step 7: Analyze each cluster to identify DDLAs\n",
    "    ddlas = []\n",
    "    cluster_info = {}\n",
    "    total_ddla_samples = 0\n",
    "    \n",
    "    for cluster_id in range(optimal_k):\n",
    "        # Get all samples assigned to this cluster\n",
    "        cluster_mask = (all_cluster_labels == cluster_id)\n",
    "        cluster_indices = np.where(cluster_mask)[0]\n",
    "        \n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate cluster accuracy using ALL samples in cluster\n",
    "        cluster_y_true = y_test.iloc[cluster_indices]\n",
    "        cluster_y_pred = y_pred[cluster_indices]\n",
    "        cluster_accuracy = accuracy_score(cluster_y_true, cluster_y_pred)\n",
    "        cluster_error_rate = 1 - cluster_accuracy\n",
    "        \n",
    "        # How many of the original error samples are in this cluster?\n",
    "        error_samples_in_cluster = sum(1 for idx in cluster_indices if error_mask.iloc[idx])\n",
    "        \n",
    "        # Cluster characteristics for interpretability\n",
    "        cluster_data = X_test.iloc[cluster_indices]\n",
    "        cluster_size = len(cluster_indices)\n",
    "        cluster_fraction = cluster_size / len(X_test)\n",
    "        \n",
    "        cluster_info[cluster_id] = {\n",
    "            'cluster_id': cluster_id,\n",
    "            'accuracy': cluster_accuracy,\n",
    "            'error_rate': cluster_error_rate,\n",
    "            'sample_count': cluster_size,\n",
    "            'sample_fraction': cluster_fraction,\n",
    "            'error_samples_in_cluster': error_samples_in_cluster,\n",
    "            'error_concentration': error_samples_in_cluster / len(X_errors) if len(X_errors) > 0 else 0,\n",
    "            'sample_indices': cluster_indices.tolist(),\n",
    "            'is_ddla': cluster_accuracy < overall_accuracy  # DDLA definition\n",
    "        }\n",
    "        \n",
    "        # This is a DDLA if accuracy < overall accuracy\n",
    "        if cluster_accuracy < overall_accuracy:\n",
    "            ddlas.append(cluster_info[cluster_id])\n",
    "            total_ddla_samples += cluster_size\n",
    "            \n",
    "            print(f\"     DDLA found: Cluster {cluster_id}\")\n",
    "            print(f\"       Accuracy: {cluster_accuracy:.3f} (vs overall {overall_accuracy:.3f})\")\n",
    "            print(f\"       Size: {cluster_size} samples ({cluster_fraction:.3f} of total)\")\n",
    "            print(f\"       Error concentration: {error_samples_in_cluster}/{len(X_errors)} \" + \n",
    "                  f\"({cluster_info[cluster_id]['error_concentration']:.3f})\")\n",
    "    \n",
    "    # Sort DDLAs by error rate (most problematic first)\n",
    "    ddlas.sort(key=lambda x: x['error_rate'], reverse=True)\n",
    "    \n",
    "    # Calculate baseline DDLA ratio\n",
    "    ddla_ratio_baseline = total_ddla_samples / len(X_test)\n",
    "    \n",
    "    print(f\" Found {len(ddlas)} DDLAs covering {total_ddla_samples}/{len(X_test)} \" +\n",
    "          f\"samples ({ddla_ratio_baseline:.3f} ratio)\")\n",
    "    \n",
    "    # Step 8: Generate interpretable cluster characterizations\n",
    "    cluster_characterizations = characterize_error_clusters(\n",
    "        cluster_info, X_test, y_test, y_pred, y_prob, error_kmeans, X_all_preprocessed\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'ddlas': ddlas,\n",
    "        'error_clusters': error_kmeans,\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'overall_error_rate': overall_error_rate,\n",
    "        'ddla_ratio_baseline': ddla_ratio_baseline,\n",
    "        'total_ddla_samples': total_ddla_samples,\n",
    "        'cluster_info': cluster_info,\n",
    "        'cluster_characterizations': cluster_characterizations,\n",
    "        'error_sample_count': len(X_errors),\n",
    "        'total_sample_count': len(X_test),\n",
    "        'feature_names': feature_names,\n",
    "        'optimal_k': optimal_k,\n",
    "        'approach': 'error_driven_clustering'\n",
    "    }\n",
    "\n",
    "\n",
    "def characterize_error_clusters(cluster_info, X_test, y_test, y_pred, y_prob, \n",
    "                               error_kmeans, X_all_preprocessed):\n",
    "    \"\"\"\n",
    "    Generate interpretable characterizations of error clusters.\n",
    "    This is the INTERPRETABILITY INNOVATION part!\n",
    "    \"\"\"\n",
    "    print(\"Generating interpretable cluster characterizations...\")\n",
    "    \n",
    "    characterizations = {}\n",
    "    \n",
    "    for cluster_id, info in cluster_info.items():\n",
    "        cluster_indices = info['sample_indices']\n",
    "        cluster_data = X_test.iloc[cluster_indices]\n",
    "        cluster_y_true = y_test.iloc[cluster_indices]\n",
    "        cluster_y_pred = y_pred[cluster_indices]\n",
    "        cluster_y_prob = y_prob[cluster_indices]\n",
    "        \n",
    "        # Feature profile: what makes this cluster unique?\n",
    "        feature_profile = {}\n",
    "        numeric_cols = X_test.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if col in cluster_data.columns:\n",
    "                cluster_mean = cluster_data[col].mean()\n",
    "                global_mean = X_test[col].mean()\n",
    "                feature_profile[col] = {\n",
    "                    'cluster_mean': cluster_mean,\n",
    "                    'global_mean': global_mean,\n",
    "                    'difference': cluster_mean - global_mean,\n",
    "                    'relative_difference': ((cluster_mean - global_mean) / global_mean) * 100 if global_mean != 0 else 0\n",
    "                }\n",
    "        \n",
    "        # Error characteristics\n",
    "        error_profile = {\n",
    "            'accuracy': info['accuracy'],\n",
    "            'error_rate': info['error_rate'],\n",
    "            'avg_prediction_confidence': np.mean(np.max(cluster_y_prob, axis=1)),\n",
    "            'prediction_distribution': pd.Series(cluster_y_pred).value_counts(normalize=True).to_dict(),\n",
    "            'true_label_distribution': pd.Series(cluster_y_true).value_counts(normalize=True).to_dict()\n",
    "        }\n",
    "        \n",
    "        # Generate interpretable description\n",
    "        interpretation = generate_cluster_interpretation(\n",
    "            cluster_data, cluster_y_true, cluster_y_pred, feature_profile, error_profile\n",
    "        )\n",
    "        \n",
    "        characterizations[cluster_id] = {\n",
    "            'cluster_id': cluster_id,\n",
    "            'size': len(cluster_indices),\n",
    "            'is_ddla': info['is_ddla'],\n",
    "            'feature_profile': feature_profile,\n",
    "            'error_profile': error_profile,\n",
    "            'interpretation': interpretation\n",
    "        }\n",
    "    \n",
    "    return characterizations\n",
    "\n",
    "\n",
    "def generate_cluster_interpretation(cluster_data, cluster_y_true, cluster_y_pred, \n",
    "                                  feature_profile, error_profile):\n",
    "    \"\"\"\n",
    "    Generate human-readable interpretation of what each cluster represents.\n",
    "    \"\"\"\n",
    "    interpretation = {\n",
    "        'cluster_type': '',\n",
    "        'key_characteristics': [],\n",
    "        'common_errors': '',\n",
    "        'business_meaning': ''\n",
    "    }\n",
    "    \n",
    "    # Identify key distinguishing features (top 3 largest relative differences)\n",
    "    feature_diffs = [(col, abs(profile['relative_difference'])) \n",
    "                     for col, profile in feature_profile.items()]\n",
    "    feature_diffs.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_features = feature_diffs[:3]\n",
    "    \n",
    "    for feature, _ in top_features:\n",
    "        profile = feature_profile[feature]\n",
    "        if abs(profile['relative_difference']) > 10:  # More than 10% difference\n",
    "            direction = \"higher\" if profile['relative_difference'] > 0 else \"lower\"\n",
    "            interpretation['key_characteristics'].append(\n",
    "                f\"{direction} {feature} ({profile['relative_difference']:+.1f}%)\"\n",
    "            )\n",
    "    \n",
    "    # Determine cluster type based on accuracy\n",
    "    if error_profile['accuracy'] < 0.5:\n",
    "        interpretation['cluster_type'] = 'High-Risk Failure Pattern'\n",
    "    elif error_profile['accuracy'] < 0.7:\n",
    "        interpretation['cluster_type'] = 'Moderate-Risk Pattern'\n",
    "    else:\n",
    "        interpretation['cluster_type'] = 'Low-Risk Pattern'\n",
    "    \n",
    "    # Common error pattern\n",
    "    pred_dist = error_profile['prediction_distribution']\n",
    "    true_dist = error_profile['true_label_distribution']\n",
    "    \n",
    "    if len(pred_dist) > 0 and len(true_dist) > 0:\n",
    "        most_predicted = max(pred_dist.keys(), key=pred_dist.get)\n",
    "        most_actual = max(true_dist.keys(), key=true_dist.get)\n",
    "        \n",
    "        if most_predicted != most_actual:\n",
    "            interpretation['common_errors'] = f\"Often predicts {most_predicted} when actual is {most_actual}\"\n",
    "        \n",
    "    # Business meaning (Telco-specific)\n",
    "    interpretation['business_meaning'] = generate_telco_business_meaning(\n",
    "        interpretation['key_characteristics'], error_profile\n",
    "    )\n",
    "    \n",
    "    return interpretation\n",
    "\n",
    "\n",
    "def generate_telco_business_meaning(key_characteristics, error_profile):\n",
    "    \"\"\"\n",
    "    Generate business-relevant interpretation for Telco context.\n",
    "    \"\"\"\n",
    "    meaning_pieces = []\n",
    "    \n",
    "    for char in key_characteristics:\n",
    "        if 'tenure' in char.lower():\n",
    "            if 'higher' in char:\n",
    "                meaning_pieces.append(\"long-term customers\")\n",
    "            else:\n",
    "                meaning_pieces.append(\"new customers\")\n",
    "        elif 'monthlycharges' in char.lower():\n",
    "            if 'higher' in char:\n",
    "                meaning_pieces.append(\"high-value customers\")\n",
    "            else:\n",
    "                meaning_pieces.append(\"budget customers\")\n",
    "        elif 'totalcharges' in char.lower():\n",
    "            if 'higher' in char:\n",
    "                meaning_pieces.append(\"high lifetime value\")\n",
    "            else:\n",
    "                meaning_pieces.append(\"low lifetime value\")\n",
    "    \n",
    "    if not meaning_pieces:\n",
    "        meaning_pieces.append(\"customers with mixed characteristics\")\n",
    "    \n",
    "    accuracy = error_profile['accuracy']\n",
    "    if accuracy < 0.5:\n",
    "        risk_level = \"very difficult to predict correctly\"\n",
    "    elif accuracy < 0.7:\n",
    "        risk_level = \"challenging to predict\"\n",
    "    else:\n",
    "        risk_level = \"relatively predictable\"\n",
    "    \n",
    "    return f\"Represents {' and '.join(meaning_pieces)} who are {risk_level}\"\n",
    "\n",
    "\n",
    "def detect_harmful_drift_error_clustering(ddla_info, X_serving, trained_pipeline,\n",
    "                                          theta_inc=0.5, theta_ddla=0.1):\n",
    "    \"\"\"\n",
    "    Detect harmful drift using error-driven clustering approach.\n",
    "    This should be more robust to concept drift than decision trees!\n",
    "    \"\"\"\n",
    "    print(\" Detecting harmful drift using Error-Driven Clustering...\")\n",
    "    \n",
    "    error_clusters = ddla_info['error_clusters']\n",
    "    baseline_ddla_ratio = ddla_info['ddla_ratio_baseline']\n",
    "    \n",
    "    if error_clusters is None:\n",
    "        print(\"    No error clusters available. Assuming benign drift.\")\n",
    "        return {\n",
    "            'is_harmful_drift': False,\n",
    "            'drift_type': 'benign',\n",
    "            'reason': 'No baseline error clusters to compare against',\n",
    "            'ratio_train': baseline_ddla_ratio,\n",
    "            'ratio_serving': 0.0,\n",
    "            'approach': 'error_driven_clustering'\n",
    "        }\n",
    "    \n",
    "    # Preprocess serving data\n",
    "    X_serving_preprocessed = trained_pipeline.named_steps['preprocessor'].transform(X_serving)\n",
    "    \n",
    "    # Assign serving data to error-derived clusters\n",
    "    serving_cluster_labels = error_clusters.predict(X_serving_preprocessed)\n",
    "    \n",
    "    # Get DDLA cluster IDs\n",
    "    ddla_cluster_ids = {ddla['cluster_id'] for ddla in ddla_info['ddlas']}\n",
    "    \n",
    "    # Calculate serving DDLA ratio\n",
    "    serving_ddla_count = sum(1 for cluster_id in serving_cluster_labels \n",
    "                           if cluster_id in ddla_cluster_ids)\n",
    "    serving_ddla_ratio = serving_ddla_count / len(X_serving)\n",
    "    \n",
    "    print(f\"  Baseline DDLA ratio: {baseline_ddla_ratio:.4f}\")\n",
    "    print(f\"  Serving DDLA ratio: {serving_ddla_ratio:.4f}\")\n",
    "    \n",
    "    # Apply drift detection logic (same as original DDLA)\n",
    "    if serving_ddla_ratio <= baseline_ddla_ratio:\n",
    "        is_harmful = False\n",
    "        drift_type = \"benign\"\n",
    "        reason = \"DDLA ratio decreased or stayed same\"\n",
    "    else:\n",
    "        if baseline_ddla_ratio > 0:\n",
    "            ratio_increase = (serving_ddla_ratio - baseline_ddla_ratio) / baseline_ddla_ratio\n",
    "        else:\n",
    "            ratio_increase = float('inf') if serving_ddla_ratio > 0 else 0\n",
    "        \n",
    "        is_harmful = (ratio_increase > theta_inc) and (serving_ddla_ratio > theta_ddla)\n",
    "        \n",
    "        if is_harmful:\n",
    "            drift_type = \"harmful\"\n",
    "            reason = f\"DDLA ratio increased by {ratio_increase:.2%} and exceeds thresholds\"\n",
    "        else:\n",
    "            drift_type = \"benign\"\n",
    "            reason = f\"DDLA ratio increase {ratio_increase:.2%} below threshold or serving ratio too low\"\n",
    "    \n",
    "    print(f\"   Drift assessment: {drift_type.upper()}\")\n",
    "    print(f\"  Reason: {reason}\")\n",
    "    \n",
    "    return {\n",
    "        'is_harmful_drift': is_harmful,\n",
    "        'drift_type': drift_type,\n",
    "        'reason': reason,\n",
    "        'baseline_ddla_ratio': baseline_ddla_ratio,\n",
    "        'serving_ddla_ratio': serving_ddla_ratio,\n",
    "        'ratio_train': baseline_ddla_ratio,  # For compatibility\n",
    "        'ratio_serving': serving_ddla_ratio,  # For compatibility\n",
    "        'ddla_fraction_change': serving_ddla_ratio - baseline_ddla_ratio,\n",
    "        'ddla_fraction_change_pct': ((serving_ddla_ratio - baseline_ddla_ratio) / baseline_ddla_ratio * 100) if baseline_ddla_ratio > 0 else 0,\n",
    "        'serving_ddla_count': serving_ddla_count,\n",
    "        'serving_total_count': len(X_serving),\n",
    "        'approach': 'error_driven_clustering',\n",
    "        'thresholds_used': {'theta_inc': theta_inc, 'theta_ddla': theta_ddla}\n",
    "    }\n",
    "\n",
    "\n",
    "def run_error_clustering_ddla_experiment(X, y, trained_pipeline, drift_thresholds,\n",
    "                                        experiment_name=\"telco-error-clustering-ddla\",\n",
    "                                        random_state=42):\n",
    "    \"\"\"\n",
    "    Run the world's first Error-Driven DDLA Clustering experiment!\n",
    "    \"\"\"\n",
    "    print(\" Starting Error-Driven DDLA Clustering Experiment!\")\n",
    "    print(\"This is pioneering research in drift detection! ðŸŒŸ\")\n",
    "    print(f\"Testing thresholds: {drift_thresholds}\")\n",
    "    \n",
    "    # Setup MLflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Split data for baseline\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # Step 1: Identify DDLAs using our error clustering approach\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 1: IDENTIFYING DDLAs USING ERROR-DRIVEN CLUSTERING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ddla_info = identify_ddlas_error_clustering(\n",
    "        trained_pipeline, X_test, y_test, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    if len(ddla_info['ddlas']) == 0:\n",
    "        print(\"  No DDLAs found with error clustering. This might indicate:\")\n",
    "        print(\"   - Very robust model with consistent error patterns\")\n",
    "        print(\"   - Need to adjust clustering parameters\")\n",
    "        print(\"   - Different approach needed for this dataset\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Step 2: Test across drift scenarios\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 2: TESTING ERROR-CLUSTERING DDLA ACROSS DRIFT TYPES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Test on all drift scenarios\n",
    "    drift_scenarios = [\n",
    "        ('covariate_only', simulate_covariate_drift_only),\n",
    "        ('concept_only', simulate_concept_drift_only), \n",
    "        ('combined_drift', simulate_drifted_data)\n",
    "    ]\n",
    "    \n",
    "    all_scenario_results = {}\n",
    "    \n",
    "    for scenario_name, drift_function in drift_scenarios:\n",
    "        print(f\"\\n Testing {scenario_name.replace('_', ' ').title()} Scenario\")\n",
    "        scenario_results = []\n",
    "        \n",
    "        for threshold in drift_thresholds:\n",
    "            print(f\"\\n  Threshold: {threshold:.2f}\")\n",
    "            \n",
    "            with mlflow.start_run(run_name=f'error_clustering_{scenario_name}_threshold_{threshold}'):\n",
    "                # Generate drift\n",
    "                X_drifted, y_drifted, drift_info_scenario = drift_function(\n",
    "                    X, y, drift_threshold=threshold, random_state=random_state\n",
    "                )\n",
    "                \n",
    "                # Split drifted data\n",
    "                _, X_test_drifted, _, y_test_drifted = train_test_split(\n",
    "                    X_drifted, y_drifted, test_size=0.2, random_state=random_state\n",
    "                )\n",
    "                \n",
    "                # Test our error clustering drift detection\n",
    "                drift_detection = detect_harmful_drift_error_clustering(\n",
    "                    ddla_info, X_test_drifted, trained_pipeline\n",
    "                )\n",
    "                \n",
    "                # Calculate actual performance\n",
    "                y_pred_drifted = trained_pipeline.predict(X_test_drifted)\n",
    "                actual_accuracy = accuracy_score(y_test_drifted, y_pred_drifted)\n",
    "                accuracy_drop = ddla_info['overall_accuracy'] - actual_accuracy\n",
    "                significant_degradation = accuracy_drop > 0.05\n",
    "                \n",
    "                # Evaluate our approach\n",
    "                error_clustering_correct = drift_detection['is_harmful_drift'] == significant_degradation\n",
    "                \n",
    "                result = {\n",
    "                    'scenario': scenario_name,\n",
    "                    'threshold': threshold,\n",
    "                    'error_clustering_detected_harmful': drift_detection['is_harmful_drift'],\n",
    "                    'actually_needs_retraining': significant_degradation,\n",
    "                    'error_clustering_correct': error_clustering_correct,\n",
    "                    'accuracy_drop': accuracy_drop,\n",
    "                    'accuracy_drop_pct': (accuracy_drop / ddla_info['overall_accuracy']) * 100,\n",
    "                    'ratio_train': drift_detection['ratio_train'],\n",
    "                    'ratio_serving': drift_detection['ratio_serving'],\n",
    "                    'n_ddlas_found': len(ddla_info['ddlas']),\n",
    "                    'approach': 'error_driven_clustering'\n",
    "                }\n",
    "                \n",
    "                scenario_results.append(result)\n",
    "                \n",
    "                # Log to MLflow\n",
    "                mlflow.log_param('drift_scenario', scenario_name)\n",
    "                mlflow.log_param('drift_threshold', threshold)\n",
    "                mlflow.log_param('approach', 'error_driven_clustering')\n",
    "                mlflow.log_param('n_ddlas_found', len(ddla_info['ddlas']))\n",
    "                \n",
    "                mlflow.log_metric('error_clustering_detected_harmful', 1 if drift_detection['is_harmful_drift'] else 0)\n",
    "                mlflow.log_metric('actually_needs_retraining', 1 if significant_degradation else 0)\n",
    "                mlflow.log_metric('error_clustering_correct', 1 if error_clustering_correct else 0)\n",
    "                mlflow.log_metric('accuracy_drop_pct', result['accuracy_drop_pct'])\n",
    "                mlflow.log_metric('ratio_train', drift_detection['ratio_train'])\n",
    "                mlflow.log_metric('ratio_serving', drift_detection['ratio_serving'])\n",
    "                \n",
    "                # Print results\n",
    "                print(f\"    Error Clustering says: {'HARMFUL' if drift_detection['is_harmful_drift'] else 'BENIGN'}\")\n",
    "                print(f\"    Actually needs retraining: {'YES' if significant_degradation else 'NO'}\")\n",
    "                print(f\"    Error Clustering correct: {'YES' if error_clustering_correct else 'NO'}\")\n",
    "                print(f\"    Accuracy drop: {accuracy_drop:.4f} ({result['accuracy_drop_pct']:.1f}%)\")\n",
    "        \n",
    "        all_scenario_results[scenario_name] = scenario_results\n",
    "    \n",
    "    # Create comprehensive comparison visualization\n",
    "    create_error_clustering_summary(all_scenario_results, ddla_info, experiment_name)\n",
    "    \n",
    "    return all_scenario_results\n",
    "\n",
    "\n",
    "def create_error_clustering_summary(all_results, ddla_info, experiment_name):\n",
    "    \"\"\"\n",
    "    Create visualization summary for our error-driven clustering approach.\n",
    "    \"\"\"\n",
    "    print(\"\\n Creating Error-Driven Clustering Summary...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Error-Driven DDLA Clustering Performance', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    scenarios = list(all_results.keys())\n",
    "    colors = {'covariate_only': '#2ecc71', 'concept_only': '#e74c3c', 'combined_drift': '#f39c12'}\n",
    "    \n",
    "    # 1. Accuracy Rate by Scenario\n",
    "    ax1 = axes[0, 0]\n",
    "    scenario_accuracies = []\n",
    "    scenario_names = []\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        results = all_results[scenario]\n",
    "        correct_decisions = [r['error_clustering_correct'] for r in results]\n",
    "        accuracy_rate = np.mean(correct_decisions) * 100\n",
    "        scenario_accuracies.append(accuracy_rate)\n",
    "        scenario_names.append(scenario.replace('_', ' ').title())\n",
    "    \n",
    "    bars = ax1.bar(scenario_names, scenario_accuracies, \n",
    "                  color=[colors[s] for s in scenarios], alpha=0.8)\n",
    "    ax1.set_ylabel('Error Clustering Accuracy (%)')\n",
    "    ax1.set_title('Error-Driven DDLA: Decision Accuracy by Drift Type')\n",
    "    ax1.set_ylim([0, 100])\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, accuracy in zip(bars, scenario_accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "                f'{accuracy:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. Error Clustering vs Thresholds\n",
    "    ax2 = axes[0, 1]\n",
    "    for scenario in scenarios:\n",
    "        results = all_results[scenario]\n",
    "        thresholds = [r['threshold'] for r in results]\n",
    "        accuracies = [r['error_clustering_correct'] for r in results]\n",
    "        ax2.plot(thresholds, accuracies, 'o-', \n",
    "                label=scenario.replace('_', ' ').title(),\n",
    "                color=colors[scenario], linewidth=2, markersize=6)\n",
    "    \n",
    "    ax2.set_xlabel('Drift Threshold')\n",
    "    ax2.set_ylabel('Correct Decision (1=Yes, 0=No)')\n",
    "    ax2.set_title('Error Clustering Accuracy Across Thresholds')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Performance Drop vs Detection\n",
    "    ax3 = axes[0, 2]\n",
    "    for scenario in scenarios:\n",
    "        results = all_results[scenario]\n",
    "        performance_drops = [r['accuracy_drop_pct'] for r in results]\n",
    "        detections = [1 if r['error_clustering_detected_harmful'] else 0 for r in results]\n",
    "        \n",
    "        x_jitter = np.array(detections) + np.random.normal(0, 0.05, len(detections))\n",
    "        ax3.scatter(x_jitter, performance_drops, \n",
    "                   label=scenario.replace('_', ' ').title(),\n",
    "                   color=colors[scenario], alpha=0.7, s=60)\n",
    "    \n",
    "    ax3.axhline(y=5, color='orange', linestyle='--', label='5% significance threshold')\n",
    "    ax3.set_xlabel('Error Clustering Detection (0=Benign, 1=Harmful)')\n",
    "    ax3.set_ylabel('Actual Performance Drop (%)')\n",
    "    ax3.set_title('Performance Drop vs Error Clustering Prediction')\n",
    "    ax3.legend()\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Cluster Characteristics\n",
    "    ax4 = axes[1, 0]\n",
    "    if ddla_info['cluster_characterizations']:\n",
    "        cluster_data = []\n",
    "        cluster_labels = []\n",
    "        for cluster_id, char in ddla_info['cluster_characterizations'].items():\n",
    "            cluster_data.append(char['size'])\n",
    "            cluster_labels.append(f\"C{cluster_id}\\n({'DDLA' if char['is_ddla'] else 'Safe'})\")\n",
    "        \n",
    "        colors_clusters = ['#e74c3c' if 'DDLA' in label else '#2ecc71' for label in cluster_labels]\n",
    "        ax4.pie(cluster_data, labels=cluster_labels, autopct='%1.1f%%', \n",
    "               colors=colors_clusters, startangle=90)\n",
    "        ax4.set_title(f'Error-Derived Clusters\\n({len(ddla_info[\"ddlas\"])} DDLAs found)')\n",
    "    else:\n",
    "        ax4.text(0.5, 0.5, 'No Clusters\\nFound', ha='center', va='center', \n",
    "                transform=ax4.transAxes, fontsize=14)\n",
    "        ax4.set_title('Error-Derived Clusters')\n",
    "    \n",
    "    # 5. DDLA Ratio Evolution\n",
    "    ax5 = axes[1, 1]\n",
    "    # Show one representative scenario (combined drift)\n",
    "    if 'combined_drift' in all_results:\n",
    "        results = all_results['combined_drift']\n",
    "        thresholds = [r['threshold'] for r in results]\n",
    "        ratio_train = [r['ratio_train'] for r in results]\n",
    "        ratio_serving = [r['ratio_serving'] for r in results]\n",
    "        \n",
    "        ax5.plot(thresholds, ratio_train, 'o-', label='Training DDLA Ratio', \n",
    "                linewidth=3, markersize=8, color='#3498db')\n",
    "        ax5.plot(thresholds, ratio_serving, 's-', label='Serving DDLA Ratio',\n",
    "                linewidth=3, markersize=8, color='#e67e22')\n",
    "        ax5.set_xlabel('Drift Threshold')\n",
    "        ax5.set_ylabel('DDLA Ratio')\n",
    "        ax5.set_title('Error Clustering: DDLA Ratios\\n(Combined Drift Scenario)')\n",
    "        ax5.legend()\n",
    "        ax5.grid(alpha=0.3)\n",
    "    \n",
    "    # 6. Innovation Highlight\n",
    "    ax6 = axes[1, 2]\n",
    "    ax6.text(0.5, 0.7, ':APPROACH:', ha='center', va='center',\n",
    "            transform=ax6.transAxes, fontsize=16, fontweight='bold', color='#e74c3c')\n",
    "    ax6.text(0.5, 0.5, 'Error-Driven\\nDDLA Clustering', ha='center', va='center',\n",
    "            transform=ax6.transAxes, fontsize=14, fontweight='bold')\n",
    "    ax6.text(0.5, 0.3, 'Implementation', ha='center', va='center',\n",
    "            transform=ax6.transAxes, fontsize=12, style='italic')\n",
    "    ax6.text(0.5, 0.1, f'Found {len(ddla_info[\"ddlas\"])} DDLAs\\nfrom {ddla_info[\"error_sample_count\"]} error samples',\n",
    "            ha='center', va='center', transform=ax6.transAxes, fontsize=10)\n",
    "    ax6.set_xlim([0, 1])\n",
    "    ax6.set_ylim([0, 1])\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save and log\n",
    "    summary_plot_path = f'error_clustering_ddla_summary_{experiment_name.replace(\"-\", \"_\")}.png'\n",
    "    plt.savefig(summary_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Log summary to MLflow\n",
    "    with mlflow.start_run(run_name='error_clustering_summary'):\n",
    "        mlflow.log_param('experiment_type', 'error_clustering_summary')\n",
    "        mlflow.log_param('approach', 'error_driven_ddla_clustering')\n",
    "        mlflow.log_param('n_ddlas_found', len(ddla_info['ddlas']))\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        for scenario in scenarios:\n",
    "            results = all_results[scenario]\n",
    "            accuracy_rate = np.mean([r['error_clustering_correct'] for r in results]) * 100\n",
    "            mlflow.log_metric(f'{scenario}_accuracy_rate', accuracy_rate)\n",
    "        \n",
    "        mlflow.log_artifact(summary_plot_path, artifact_path='plots')\n",
    "        \n",
    "        print(f\" Error-Driven Clustering Summary logged to MLflow\")\n",
    "        \n",
    "        # Print performance summary\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\" ERROR-DRIVEN DDLA CLUSTERING PERFORMANCE SUMMARY ðŸŒŸ\")\n",
    "        print(\"=\"*80)\n",
    "        for scenario in scenarios:\n",
    "            results = all_results[scenario]\n",
    "            accuracy_rate = np.mean([r['error_clustering_correct'] for r in results]) * 100\n",
    "            print(f\"{scenario.replace('_', ' ').title():<25}: {accuracy_rate:.1f}% accuracy\")\n",
    "        \n",
    "        print(f\"\\nDDLAs Found: {len(ddla_info['ddlas'])}\")\n",
    "        print(f\"Error Samples Analyzed: {ddla_info['error_sample_count']}\")\n",
    "        print(f\"Baseline DDLA Ratio: {ddla_info['ddla_ratio_baseline']:.3f}\")\n",
    "    \n",
    "    return summary_plot_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e6d012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:26:25 INFO mlflow.tracking.fluent: Experiment with name 'telco-error-clustering-ddla' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LAUNCHING ERROR-DRIVEN DDLA CLUSTERING EXPERIMENT! \n",
      " Starting Error-Driven DDLA Clustering Experiment!\n",
      "This is pioneering research in drift detection! ðŸŒŸ\n",
      "Testing thresholds: [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      "\n",
      "======================================================================\n",
      "STEP 1: IDENTIFYING DDLAs USING ERROR-DRIVEN CLUSTERING\n",
      "======================================================================\n",
      "Identifying DDLAs using Error-Driven Clustering...\n",
      "This is the world's first implementation of this approach! ðŸŒŸ\n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      "   Focusing on 291 error samples out of 1409 total\n",
      "   Error samples have 57 features after preprocessing\n",
      "   Finding optimal clusters for 291 error samples...\n",
      "Optimal clusters: 3 (score: 0.240)\n",
      "   Found 3 distinct error patterns\n",
      "     DDLA found: Cluster 1\n",
      "       Accuracy: 0.688 (vs overall 0.793)\n",
      "       Size: 144 samples (0.102 of total)\n",
      "       Error concentration: 45/291 (0.155)\n",
      "     DDLA found: Cluster 2\n",
      "       Accuracy: 0.658 (vs overall 0.793)\n",
      "       Size: 228 samples (0.162 of total)\n",
      "       Error concentration: 78/291 (0.268)\n",
      " Found 2 DDLAs covering 372/1409 samples (0.264 ratio)\n",
      "Generating interpretable cluster characterizations...\n",
      "\n",
      "======================================================================\n",
      "STEP 2: TESTING ERROR-CLUSTERING DDLA ACROSS DRIFT TYPES\n",
      "======================================================================\n",
      "\n",
      " Testing Covariate Only Scenario\n",
      "\n",
      "  Threshold: 0.00\n",
      "Simulating covariate drift with threshold: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2640\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio decreased or stayed same\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: NO\n",
      "    Error Clustering correct: YES\n",
      "    Accuracy drop: -0.0014 (-0.2%)\n",
      "ðŸƒ View run error_clustering_covariate_only_threshold_0.0 at: http://localhost:5000/#/experiments/6/runs/13b3344a939a496db9e614f84fa3c3b0\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 0.25\n",
      "Simulating covariate drift with threshold: 0.25\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2654\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 0.54% below threshold or serving ratio too low\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: NO\n",
      "    Error Clustering correct: YES\n",
      "    Accuracy drop: 0.0021 (0.3%)\n",
      "ðŸƒ View run error_clustering_covariate_only_threshold_0.25 at: http://localhost:5000/#/experiments/6/runs/a8527e99270040cd8b695336c0f3a4e4\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 0.50\n",
      "Simulating covariate drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2676\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 1.34% below threshold or serving ratio too low\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: NO\n",
      "    Error Clustering correct: YES\n",
      "    Accuracy drop: 0.0106 (1.3%)\n",
      "ðŸƒ View run error_clustering_covariate_only_threshold_0.5 at: http://localhost:5000/#/experiments/6/runs/021a66eba3ce485985e82b91267ef62d\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 0.75\n",
      "Simulating covariate drift with threshold: 0.75\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2690\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 1.88% below threshold or serving ratio too low\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: NO\n",
      "    Error Clustering correct: YES\n",
      "    Accuracy drop: 0.0128 (1.6%)\n",
      "ðŸƒ View run error_clustering_covariate_only_threshold_0.75 at: http://localhost:5000/#/experiments/6/runs/ebed638c97bd4ebb80b0b95dddf9af13\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 1.00\n",
      "Simulating covariate drift with threshold: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2740\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 3.76% below threshold or serving ratio too low\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: NO\n",
      "    Error Clustering correct: YES\n",
      "    Accuracy drop: 0.0156 (2.0%)\n",
      "ðŸƒ View run error_clustering_covariate_only_threshold_1.0 at: http://localhost:5000/#/experiments/6/runs/845ad2077e7343fdba56dfd22f168470\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      " Testing Concept Only Scenario\n",
      "\n",
      "  Threshold: 0.00\n",
      "Simulating concept drift with threshold: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2640\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio decreased or stayed same\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: NO\n",
      "    Error Clustering correct: YES\n",
      "    Accuracy drop: 0.0000 (0.0%)\n",
      "ðŸƒ View run error_clustering_concept_only_threshold_0.0 at: http://localhost:5000/#/experiments/6/runs/8d11b1890d3d49aaa6ab5b083f949479\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 0.25\n",
      "Simulating concept drift with threshold: 0.25\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2640\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio decreased or stayed same\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: YES\n",
      "    Error Clustering correct: NO\n",
      "    Accuracy drop: 0.0582 (7.3%)\n",
      "ðŸƒ View run error_clustering_concept_only_threshold_0.25 at: http://localhost:5000/#/experiments/6/runs/b52580cd79cc40809dd9d346afac2ed6\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 0.50\n",
      "Simulating concept drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2640\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio decreased or stayed same\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: YES\n",
      "    Error Clustering correct: NO\n",
      "    Accuracy drop: 0.0830 (10.5%)\n",
      "ðŸƒ View run error_clustering_concept_only_threshold_0.5 at: http://localhost:5000/#/experiments/6/runs/ab49e15c3e874ceca0c997dda072c07e\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 0.75\n",
      "Simulating concept drift with threshold: 0.75\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.427 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2640\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio decreased or stayed same\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: YES\n",
      "    Error Clustering correct: NO\n",
      "    Accuracy drop: 0.1221 (15.4%)\n",
      "ðŸƒ View run error_clustering_concept_only_threshold_0.75 at: http://localhost:5000/#/experiments/6/runs/d93ec6cce2854d2fb5738a0f05f75b8b\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 1.00\n",
      "Simulating concept drift with threshold: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.475 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2640\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio decreased or stayed same\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: YES\n",
      "    Error Clustering correct: NO\n",
      "    Accuracy drop: 0.1859 (23.4%)\n",
      "ðŸƒ View run error_clustering_concept_only_threshold_1.0 at: http://localhost:5000/#/experiments/6/runs/7ca3c190c2f9418aa09535b29ea8c029\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      " Testing Combined Drift Scenario\n",
      "\n",
      "  Threshold: 0.00\n",
      "Simulating combined drift with threshold: 0.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2640\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio decreased or stayed same\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: NO\n",
      "    Error Clustering correct: YES\n",
      "    Accuracy drop: -0.0014 (-0.2%)\n",
      "ðŸƒ View run error_clustering_combined_drift_threshold_0.0 at: http://localhost:5000/#/experiments/6/runs/4e4fd789c15640c399aa673efc03897a\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 0.25\n",
      "Simulating combined drift with threshold: 0.25\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2654\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 0.54% below threshold or serving ratio too low\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: YES\n",
      "    Error Clustering correct: NO\n",
      "    Accuracy drop: 0.0546 (6.9%)\n",
      "ðŸƒ View run error_clustering_combined_drift_threshold_0.25 at: http://localhost:5000/#/experiments/6/runs/bc92d8c199af4ea6a040c9361c1703ba\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 0.50\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2676\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 1.34% below threshold or serving ratio too low\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: YES\n",
      "    Error Clustering correct: NO\n",
      "    Accuracy drop: 0.1015 (12.8%)\n",
      "ðŸƒ View run error_clustering_combined_drift_threshold_0.5 at: http://localhost:5000/#/experiments/6/runs/3b8543e663aa4cae9e53aa7cfc074ee1\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 0.75\n",
      "Simulating combined drift with threshold: 0.75\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.430 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2690\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 1.88% below threshold or serving ratio too low\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: YES\n",
      "    Error Clustering correct: NO\n",
      "    Accuracy drop: 0.1490 (18.8%)\n",
      "ðŸƒ View run error_clustering_combined_drift_threshold_0.75 at: http://localhost:5000/#/experiments/6/runs/762a7be5a93e4f198cf412365c1ba6c7\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "  Threshold: 1.00\n",
      "Simulating combined drift with threshold: 1.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.478 (original: 0.265)\n",
      " Detecting harmful drift using Error-Driven Clustering...\n",
      "  Baseline DDLA ratio: 0.2640\n",
      "  Serving DDLA ratio: 0.2740\n",
      "   Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 3.76% below threshold or serving ratio too low\n",
      "    Error Clustering says: BENIGN\n",
      "    Actually needs retraining: YES\n",
      "    Error Clustering correct: NO\n",
      "    Accuracy drop: 0.1874 (23.6%)\n",
      "ðŸƒ View run error_clustering_combined_drift_threshold_1.0 at: http://localhost:5000/#/experiments/6/runs/5b2e8fbd66c74615b711452d944de543\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      " Creating Error-Driven Clustering Summary...\n",
      " Error-Driven Clustering Summary logged to MLflow\n",
      "\n",
      "================================================================================\n",
      " ERROR-DRIVEN DDLA CLUSTERING PERFORMANCE SUMMARY ðŸŒŸ\n",
      "================================================================================\n",
      "Covariate Only           : 100.0% accuracy\n",
      "Concept Only             : 20.0% accuracy\n",
      "Combined Drift           : 20.0% accuracy\n",
      "\n",
      "DDLAs Found: 2\n",
      "Error Samples Analyzed: 291\n",
      "Baseline DDLA Ratio: 0.264\n",
      "ðŸƒ View run error_clustering_summary at: http://localhost:5000/#/experiments/6/runs/4217aab1f1144452a9e471345a983c75\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/6\n",
      "\n",
      "================================================================================\n",
      " COMPARING ERROR CLUSTERING vs DECISION TREE DDLA\n",
      "================================================================================\n",
      "\n",
      "Covariate Only:\n",
      "  Error Clustering Accuracy: 5/5 (100.0%)\n",
      "  Threshold    Error-Clust  Actually     Correct    Acc Drop    \n",
      "  ------------------------------------------------------------\n",
      "  0.00         BENIGN       NO           YES        -0.2        %\n",
      "  0.25         BENIGN       NO           YES        0.3         %\n",
      "  0.50         BENIGN       NO           YES        1.3         %\n",
      "  0.75         BENIGN       NO           YES        1.6         %\n",
      "  1.00         BENIGN       NO           YES        2.0         %\n",
      "\n",
      "Concept Only:\n",
      "  Error Clustering Accuracy: 1/5 (20.0%)\n",
      "  Threshold    Error-Clust  Actually     Correct    Acc Drop    \n",
      "  ------------------------------------------------------------\n",
      "  0.00         BENIGN       NO           YES        0.0         %\n",
      "  0.25         BENIGN       YES          NO         7.3         %\n",
      "  0.50         BENIGN       YES          NO         10.5        %\n",
      "  0.75         BENIGN       YES          NO         15.4        %\n",
      "  1.00         BENIGN       YES          NO         23.4        %\n",
      "\n",
      "Combined Drift:\n",
      "  Error Clustering Accuracy: 1/5 (20.0%)\n",
      "  Threshold    Error-Clust  Actually     Correct    Acc Drop    \n",
      "  ------------------------------------------------------------\n",
      "  0.00         BENIGN       NO           YES        -0.2        %\n",
      "  0.25         BENIGN       YES          NO         6.9         %\n",
      "  0.50         BENIGN       YES          NO         12.8        %\n",
      "  0.75         BENIGN       YES          NO         18.8        %\n",
      "  1.00         BENIGN       YES          NO         23.6        %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\" LAUNCHING ERROR-DRIVEN DDLA CLUSTERING EXPERIMENT! \")\n",
    "\n",
    "# Run approach\n",
    "error_clustering_results = run_error_clustering_ddla_experiment(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    trained_pipeline=pipeline,\n",
    "    drift_thresholds=[0.0, 0.25, 0.5, 0.75, 1.0],\n",
    "    experiment_name=\"telco-error-clustering-ddla\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" COMPARING ERROR CLUSTERING vs DECISION TREE DDLA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare with your previous decision tree results\n",
    "for scenario in ['covariate_only', 'concept_only', 'combined_drift']:\n",
    "    if scenario in error_clustering_results:\n",
    "        results = error_clustering_results[scenario]\n",
    "        correct = sum(r['error_clustering_correct'] for r in results)\n",
    "        total = len(results)\n",
    "        accuracy = (correct / total) * 100\n",
    "        \n",
    "        print(f\"\\n{scenario.replace('_', ' ').title()}:\")\n",
    "        print(f\"  Error Clustering Accuracy: {correct}/{total} ({accuracy:.1f}%)\")\n",
    "        \n",
    "        # Show detailed comparison\n",
    "        print(f\"  {'Threshold':<12} {'Error-Clust':<12} {'Actually':<12} {'Correct':<10} {'Acc Drop':<12}\")\n",
    "        print(\"  \" + \"-\" * 60)\n",
    "        \n",
    "        for r in results:\n",
    "            detection = \"HARMFUL\" if r['error_clustering_detected_harmful'] else \"BENIGN\"\n",
    "            actual = \"YES\" if r['actually_needs_retraining'] else \"NO\"\n",
    "            correct_mark =  \"YES\" if r['error_clustering_correct'] else \"NO\"\n",
    "            \n",
    "            print(f\"  {r['threshold']:<12.2f} {detection:<12} {actual:<12} \"\n",
    "                  f\"{correct_mark:<10} {r['accuracy_drop_pct']:<12.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9bcba",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Okay, so a \"simple\" clustering based approach also fails - and barely performs any better than the DT approach on concept and combined drift. If we were to observe the results a bit more, both approaches appear to fail when feature and target relationships change drastically. The covariate drift simulation does not particularly affect performance, but as soon as concept drifts over a certain threshold - we get bad results. \n",
    "\n",
    "In taking a look at K-Means' assumptions, this becomes evident because of a few key pitfalls:\n",
    "\n",
    "- Similar variance within clusters: The introduction of drift actually causes a change in variance, which affects how cluster centroids are assigned.\n",
    "- Cluster sizes are similar: This is not going to be the case most of the time, we in fact, have no idea how large or small are clusters are going to be, making this difficult to interpret.\n",
    "- Outliers: We are explicitly violating this assumption by subjecting this to the drift simulation. We are deliberately creating data outliers.\n",
    "\n",
    "Another question:\n",
    "\n",
    "- Would changing the core algorithm that is more dynamic change our results? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a863e4",
   "metadata": {},
   "source": [
    "## DBSCAN based DDLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf821038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def find_optimal_dbscan_params(X_errors_preprocessed, eps_range=(0.1, 2.0), min_samples_range=(3, 20)):\n",
    "    \n",
    "    if len(X_errors_preprocessed) < 10:\n",
    "        print(f\" Too few error samples ({len(X_errors_preprocessed)}) for DBSCAN\")\n",
    "        return None, None, 0\n",
    "    \n",
    "    print(f\" Finding optimal DBSCAN parameters for {len(X_errors_preprocessed)} error samples...\")\n",
    "    \n",
    "    # Method 1: Use k-distance graph to find optimal eps\n",
    "    # This is the standard DBSCAN parameter selection method\n",
    "    k = max(4, min(10, len(X_errors_preprocessed) // 10))  # Adaptive k based on data size\n",
    "    neigh_dist = NearestNeighbors(n_neighbors=k)\n",
    "    neigh_dist_fit = neigh_dist.fit(X_errors_preprocessed)\n",
    "    distances, indices = neigh_dist_fit.kneighbors(X_errors_preprocessed)\n",
    "    distances = np.sort(distances[:, k-1], axis=0)\n",
    "    \n",
    "    # Find the \"knee\" in the k-distance graph\n",
    "    # This represents the optimal eps value\n",
    "    knee_point = find_knee_point(distances)\n",
    "    optimal_eps = distances[knee_point] if knee_point < len(distances) else distances[len(distances)//2]\n",
    "    \n",
    "    print(f\" K-distance analysis suggests eps = {optimal_eps:.3f}\")\n",
    "    \n",
    "    # Method 2: Grid search with clustering quality metrics\n",
    "    best_score = -1\n",
    "    best_eps = optimal_eps\n",
    "    best_min_samples = k\n",
    "    best_dbscan = None\n",
    "    \n",
    "    # Test around the knee point eps\n",
    "    eps_candidates = np.linspace(max(0.1, optimal_eps * 0.5), optimal_eps * 2.0, 10)\n",
    "    min_samples_candidates = range(max(3, k-2), min(min_samples_range[1], k+3))\n",
    "    \n",
    "    print(f\" Grid searching DBSCAN parameters...\")\n",
    "    \n",
    "    for eps in eps_candidates:\n",
    "        for min_samples in min_samples_candidates:\n",
    "            try:\n",
    "                dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "                cluster_labels = dbscan.fit_predict(X_errors_preprocessed)\n",
    "                \n",
    "                # Check if we got meaningful clusters\n",
    "                n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "                n_noise = list(cluster_labels).count(-1)\n",
    "                \n",
    "                if n_clusters < 2:  # Need at least 2 clusters\n",
    "                    continue\n",
    "                    \n",
    "                if n_noise > len(X_errors_preprocessed) * 0.5:  # Too much noise\n",
    "                    continue\n",
    "                \n",
    "                # Calculate clustering quality score\n",
    "                # For DBSCAN, we use a custom score since silhouette doesn't handle noise well\n",
    "                score = calculate_dbscan_quality_score(X_errors_preprocessed, cluster_labels)\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_eps = eps\n",
    "                    best_min_samples = min_samples\n",
    "                    best_dbscan = dbscan\n",
    "                    \n",
    "                print(f\"    eps={eps:.3f}, min_samples={min_samples}: {n_clusters} clusters, {n_noise} noise, score={score:.3f}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    if best_dbscan is None:\n",
    "        print(f\" Could not find valid DBSCAN parameters\")\n",
    "        return None, None, 0\n",
    "    \n",
    "    print(f\" Optimal DBSCAN: eps={best_eps:.3f}, min_samples={best_min_samples}, score={best_score:.3f}\")\n",
    "    \n",
    "    return best_dbscan, best_eps, best_min_samples\n",
    "\n",
    "\n",
    "def find_knee_point(distances):\n",
    "    \"\"\"\n",
    "    Find the knee point in k-distance graph for optimal eps selection.\n",
    "    \"\"\"\n",
    "    if len(distances) < 3:\n",
    "        return len(distances) // 2\n",
    "        \n",
    "    # Calculate second derivative to find knee\n",
    "    first_diff = np.diff(distances)\n",
    "    second_diff = np.diff(first_diff)\n",
    "    \n",
    "    # Find the point with maximum second derivative (sharpest bend)\n",
    "    knee_point = np.argmax(second_diff) + 1\n",
    "    \n",
    "    return min(knee_point, len(distances) - 1)\n",
    "\n",
    "\n",
    "def calculate_dbscan_quality_score(X, cluster_labels):\n",
    "    \"\"\"\n",
    "    Custom quality score for DBSCAN that handles noise points properly.\n",
    "    \"\"\"\n",
    "    unique_labels = set(cluster_labels)\n",
    "    n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)\n",
    "    \n",
    "    if n_clusters < 2:\n",
    "        return -1\n",
    "    \n",
    "    # Penalty for too much noise\n",
    "    noise_ratio = list(cluster_labels).count(-1) / len(cluster_labels)\n",
    "    noise_penalty = max(0, noise_ratio - 0.1) * 2  # Allow up to 10% noise\n",
    "    \n",
    "    # Reward for balanced cluster sizes (but allow some imbalance - this is the key!)\n",
    "    cluster_sizes = [list(cluster_labels).count(label) for label in unique_labels if label != -1]\n",
    "    size_balance = 1 - (np.std(cluster_sizes) / np.mean(cluster_sizes)) if len(cluster_sizes) > 1 else 0.5\n",
    "    \n",
    "    # Combined score\n",
    "    score = size_balance - noise_penalty + (n_clusters * 0.1)  # Slight bonus for more clusters\n",
    "    \n",
    "    return max(0, score)\n",
    "\n",
    "\n",
    "def identify_ddlas_dbscan(trained_pipeline, X_test, y_test, random_state=42):\n",
    "    \n",
    "    print(\" REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\")\n",
    "    print(\"Testing your brilliant algorithmic insight! \")\n",
    "    \n",
    "    # Step 1: Get model predictions and overall accuracy\n",
    "    y_pred = trained_pipeline.predict(X_test)\n",
    "    y_prob = trained_pipeline.predict_proba(X_test)\n",
    "    overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "    overall_error_rate = 1 - overall_accuracy\n",
    "    \n",
    "    print(f\"  Overall model accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"  Overall error rate: {overall_error_rate:.4f}\")\n",
    "    \n",
    "    # Step 2: Focus ONLY on model errors\n",
    "    error_mask = (y_pred != y_test)\n",
    "    X_errors = X_test[error_mask].copy()\n",
    "    \n",
    "    print(f\" Focusing on {len(X_errors)} error samples out of {len(X_test)} total\")\n",
    "    \n",
    "    if len(X_errors) < 10:  # DBSCAN needs more samples than K-Means\n",
    "        print(\" Too few errors for DBSCAN clustering. Returning empty DDLAs.\")\n",
    "        return {\n",
    "            'ddlas': [],\n",
    "            'error_clusters': None, \n",
    "            'overall_accuracy': overall_accuracy,\n",
    "            'overall_error_rate': overall_error_rate,\n",
    "            'ddla_ratio_baseline': 0.0,\n",
    "            'error_sample_count': len(X_errors),\n",
    "            'total_sample_count': len(X_test),\n",
    "            'feature_names': [],\n",
    "            'approach': 'dbscan_error_clustering'\n",
    "        }\n",
    "    \n",
    "    # Step 3: Preprocess error samples\n",
    "    X_errors_preprocessed = trained_pipeline.named_steps['preprocessor'].transform(X_errors)\n",
    "    \n",
    "    # Handle any remaining NaN/inf values\n",
    "    if hasattr(X_errors_preprocessed, 'toarray'):\n",
    "        X_errors_preprocessed = X_errors_preprocessed.toarray()\n",
    "    \n",
    "    X_errors_preprocessed = np.nan_to_num(X_errors_preprocessed, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Get feature names\n",
    "    try:\n",
    "        feature_names = trained_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "    except:\n",
    "        n_features = X_errors_preprocessed.shape[1]\n",
    "        feature_names = [f'feature_{i}' for i in range(n_features)]\n",
    "    \n",
    "    print(f\"  ðŸ“Š Error samples have {len(feature_names)} features after preprocessing\")\n",
    "    \n",
    "    # Step 4: Find optimal DBSCAN clustering of ERROR PATTERNS\n",
    "    dbscan_model, optimal_eps, optimal_min_samples = find_optimal_dbscan_params(X_errors_preprocessed)\n",
    "    \n",
    "    if dbscan_model is None:\n",
    "        print(\" Could not find valid DBSCAN clustering. Returning empty DDLAs.\")\n",
    "        return {\n",
    "            'ddlas': [],\n",
    "            'error_clusters': None,\n",
    "            'overall_accuracy': overall_accuracy,\n",
    "            'overall_error_rate': overall_error_rate,\n",
    "            'ddla_ratio_baseline': 0.0,\n",
    "            'error_sample_count': len(X_errors),\n",
    "            'total_sample_count': len(X_test),\n",
    "            'feature_names': feature_names,\n",
    "            'approach': 'dbscan_error_clustering'\n",
    "        }\n",
    "    \n",
    "    # Step 5: Get error cluster assignments\n",
    "    error_cluster_labels = dbscan_model.fit_predict(X_errors_preprocessed)\n",
    "    \n",
    "    n_clusters = len(set(error_cluster_labels)) - (1 if -1 in error_cluster_labels else 0)\n",
    "    n_noise = list(error_cluster_labels).count(-1)\n",
    "    \n",
    "    print(f\" DBSCAN found {n_clusters} distinct error patterns + {n_noise} noise points\")\n",
    "    \n",
    "    # Step 6: Map ALL data to these error-derived clusters\n",
    "    X_all_preprocessed = trained_pipeline.named_steps['preprocessor'].transform(X_test)\n",
    "    if hasattr(X_all_preprocessed, 'toarray'):\n",
    "        X_all_preprocessed = X_all_preprocessed.toarray()\n",
    "    X_all_preprocessed = np.nan_to_num(X_all_preprocessed, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # For DBSCAN, we need to assign all data points to nearest clusters\n",
    "    all_cluster_labels = assign_to_dbscan_clusters(X_all_preprocessed, X_errors_preprocessed, error_cluster_labels)\n",
    "    \n",
    "    # Step 7: Analyze each cluster to identify DDLAs\n",
    "    ddlas = []\n",
    "    cluster_info = {}\n",
    "    total_ddla_samples = 0\n",
    "    \n",
    "    unique_clusters = [label for label in set(error_cluster_labels) if label != -1]  # Exclude noise\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        # Get all samples assigned to this cluster\n",
    "        cluster_mask = (all_cluster_labels == cluster_id)\n",
    "        cluster_indices = np.where(cluster_mask)[0]\n",
    "        \n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate cluster accuracy\n",
    "        cluster_y_true = y_test.iloc[cluster_indices]\n",
    "        cluster_y_pred = y_pred[cluster_indices]\n",
    "        cluster_accuracy = accuracy_score(cluster_y_true, cluster_y_pred)\n",
    "        cluster_error_rate = 1 - cluster_accuracy\n",
    "        \n",
    "        # Count error samples in this cluster\n",
    "        error_samples_in_cluster = sum(1 for idx in cluster_indices if error_mask.iloc[idx])\n",
    "        \n",
    "        cluster_size = len(cluster_indices)\n",
    "        cluster_fraction = cluster_size / len(X_test)\n",
    "        \n",
    "        cluster_info[cluster_id] = {\n",
    "            'cluster_id': cluster_id,\n",
    "            'accuracy': cluster_accuracy,\n",
    "            'error_rate': cluster_error_rate,\n",
    "            'sample_count': cluster_size,\n",
    "            'sample_fraction': cluster_fraction,\n",
    "            'error_samples_in_cluster': error_samples_in_cluster,\n",
    "            'error_concentration': error_samples_in_cluster / len(X_errors) if len(X_errors) > 0 else 0,\n",
    "            'sample_indices': cluster_indices.tolist(),\n",
    "            'is_ddla': cluster_accuracy < overall_accuracy,\n",
    "            'cluster_type': 'core_error_pattern'  # DBSCAN advantage: we know these are core patterns!\n",
    "        }\n",
    "        \n",
    "        # This is a DDLA if accuracy < overall accuracy\n",
    "        if cluster_accuracy < overall_accuracy:\n",
    "            ddlas.append(cluster_info[cluster_id])\n",
    "            total_ddla_samples += cluster_size\n",
    "            \n",
    "            print(f\"     DBSCAN DDLA found: Cluster {cluster_id}\")\n",
    "            print(f\"       Accuracy: {cluster_accuracy:.3f} (vs overall {overall_accuracy:.3f})\")\n",
    "            print(f\"       Size: {cluster_size} samples ({cluster_fraction:.3f} of total)\")\n",
    "            print(f\"       Core error pattern with {error_samples_in_cluster}/{len(X_errors)} error samples\")\n",
    "    \n",
    "    # Also analyze noise points separately (DBSCAN's special advantage!)\n",
    "    if n_noise > 0:\n",
    "        noise_mask = (all_cluster_labels == -1)\n",
    "        noise_indices = np.where(noise_mask)[0]\n",
    "        \n",
    "        if len(noise_indices) > 0:\n",
    "            noise_y_true = y_test.iloc[noise_indices]\n",
    "            noise_y_pred = y_pred[noise_indices]\n",
    "            noise_accuracy = accuracy_score(noise_y_true, noise_y_pred)\n",
    "            \n",
    "            print(f\" Noise points analysis: {len(noise_indices)} samples, accuracy: {noise_accuracy:.3f}\")\n",
    "            \n",
    "            # Noise can also be a DDLA if it has low accuracy\n",
    "            if noise_accuracy < overall_accuracy:\n",
    "                noise_ddla = {\n",
    "                    'cluster_id': -1,\n",
    "                    'accuracy': noise_accuracy,\n",
    "                    'error_rate': 1 - noise_accuracy,\n",
    "                    'sample_count': len(noise_indices),\n",
    "                    'sample_fraction': len(noise_indices) / len(X_test),\n",
    "                    'error_samples_in_cluster': sum(1 for idx in noise_indices if error_mask.iloc[idx]),\n",
    "                    'error_concentration': sum(1 for idx in noise_indices if error_mask.iloc[idx]) / len(X_errors),\n",
    "                    'sample_indices': noise_indices.tolist(),\n",
    "                    'is_ddla': True,\n",
    "                    'cluster_type': 'outlier_error_pattern'  # Special DBSCAN insight!\n",
    "                }\n",
    "                ddlas.append(noise_ddla)\n",
    "                total_ddla_samples += len(noise_indices)\n",
    "                print(f\" NOISE DDLA found: Outlier error pattern with {len(noise_indices)} samples\")\n",
    "    \n",
    "    # Sort DDLAs by error rate (most problematic first)\n",
    "    ddlas.sort(key=lambda x: x['error_rate'], reverse=True)\n",
    "    \n",
    "    # Calculate baseline DDLA ratio\n",
    "    ddla_ratio_baseline = total_ddla_samples / len(X_test)\n",
    "    \n",
    "    print(f\" DBSCAN found {len(ddlas)} DDLAs covering {total_ddla_samples}/{len(X_test)} \" +\n",
    "          f\"samples ({ddla_ratio_baseline:.3f} ratio)\")\n",
    "    \n",
    "    return {\n",
    "        'ddlas': ddlas,\n",
    "        'error_clusters': dbscan_model,\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'overall_error_rate': overall_error_rate,\n",
    "        'ddla_ratio_baseline': ddla_ratio_baseline,\n",
    "        'total_ddla_samples': total_ddla_samples,\n",
    "        'cluster_info': cluster_info,\n",
    "        'error_sample_count': len(X_errors),\n",
    "        'total_sample_count': len(X_test),\n",
    "        'feature_names': feature_names,\n",
    "        'dbscan_params': {'eps': optimal_eps, 'min_samples': optimal_min_samples},\n",
    "        'n_clusters_found': n_clusters,\n",
    "        'n_noise_points': n_noise,\n",
    "        'approach': 'dbscan_error_clustering'\n",
    "    }\n",
    "\n",
    "\n",
    "def assign_to_dbscan_clusters(X_all, X_errors, error_cluster_labels):\n",
    "    \"\"\"\n",
    "    Assign all data points to the nearest DBSCAN clusters.\n",
    "    This is necessary because DBSCAN was only trained on error samples.\n",
    "    \"\"\"\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "    # Get cluster centers (excluding noise points)\n",
    "    unique_clusters = [label for label in set(error_cluster_labels) if label != -1]\n",
    "    cluster_centers = {}\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        cluster_mask = (error_cluster_labels == cluster_id)\n",
    "        cluster_points = X_errors[cluster_mask]\n",
    "        cluster_centers[cluster_id] = np.mean(cluster_points, axis=0)\n",
    "    \n",
    "    if len(cluster_centers) == 0:\n",
    "        # No valid clusters, assign everything to noise\n",
    "        return np.full(len(X_all), -1)\n",
    "    \n",
    "    # For each point in X_all, find nearest cluster center\n",
    "    all_cluster_assignments = []\n",
    "    \n",
    "    for point in X_all:\n",
    "        min_distance = float('inf')\n",
    "        best_cluster = -1\n",
    "        \n",
    "        for cluster_id, center in cluster_centers.items():\n",
    "            distance = np.linalg.norm(point - center)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                best_cluster = cluster_id\n",
    "        \n",
    "        # If point is too far from any cluster center, mark as noise\n",
    "        # Use the original DBSCAN eps parameter as threshold\n",
    "        if min_distance > 2.0:  # Conservative threshold\n",
    "            all_cluster_assignments.append(-1)\n",
    "        else:\n",
    "            all_cluster_assignments.append(best_cluster)\n",
    "    \n",
    "    return np.array(all_cluster_assignments)\n",
    "\n",
    "\n",
    "def detect_harmful_drift_dbscan(ddla_info, X_serving, trained_pipeline,\n",
    "                               theta_inc=0.5, theta_ddla=0.1):\n",
    "    \"\"\"\n",
    "    Detect harmful drift using DBSCAN-based error clustering.\n",
    "    This should be more robust to concept drift!\n",
    "    \"\"\"\n",
    "    print(\" Detecting harmful drift using DBSCAN Error Clustering...\")\n",
    "    \n",
    "    dbscan_model = ddla_info['error_clusters']\n",
    "    baseline_ddla_ratio = ddla_info['ddla_ratio_baseline']\n",
    "    \n",
    "    if dbscan_model is None:\n",
    "        print(\"  No DBSCAN clusters available. Assuming benign drift.\")\n",
    "        return create_empty_drift_result(baseline_ddla_ratio, len(X_serving))\n",
    "    \n",
    "    # Preprocess serving data\n",
    "    X_serving_preprocessed = trained_pipeline.named_steps['preprocessor'].transform(X_serving)\n",
    "    if hasattr(X_serving_preprocessed, 'toarray'):\n",
    "        X_serving_preprocessed = X_serving_preprocessed.toarray()\n",
    "    X_serving_preprocessed = np.nan_to_num(X_serving_preprocessed, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Get DDLA cluster IDs\n",
    "    ddla_cluster_ids = {ddla['cluster_id'] for ddla in ddla_info['ddlas']}\n",
    "    \n",
    "    # Assign serving data to clusters (including noise detection!)\n",
    "    serving_cluster_labels = assign_serving_to_dbscan_clusters(\n",
    "        X_serving_preprocessed, ddla_info, dbscan_model\n",
    "    )\n",
    "    \n",
    "    # Calculate serving DDLA ratio\n",
    "    serving_ddla_count = sum(1 for cluster_id in serving_cluster_labels \n",
    "                           if cluster_id in ddla_cluster_ids)\n",
    "    serving_ddla_ratio = serving_ddla_count / len(X_serving)\n",
    "    \n",
    "    print(f\"  Baseline DDLA ratio: {baseline_ddla_ratio:.4f}\")\n",
    "    print(f\"  Serving DDLA ratio: {serving_ddla_ratio:.4f}\")\n",
    "    \n",
    "    # DBSCAN-specific insight: Check noise level increase\n",
    "    serving_noise_count = sum(1 for cluster_id in serving_cluster_labels if cluster_id == -1)\n",
    "    serving_noise_ratio = serving_noise_count / len(X_serving)\n",
    "    baseline_noise_ratio = ddla_info['n_noise_points'] / ddla_info['total_sample_count']\n",
    "    \n",
    "    print(f\"  Baseline noise ratio: {baseline_noise_ratio:.4f}\")\n",
    "    print(f\"  Serving noise ratio: {serving_noise_ratio:.4f}\")\n",
    "    \n",
    "    # Enhanced drift detection: Consider both DDLA ratio AND noise increase\n",
    "    standard_drift = check_standard_ddla_drift(baseline_ddla_ratio, serving_ddla_ratio, theta_inc, theta_ddla)\n",
    "    noise_drift = serving_noise_ratio > baseline_noise_ratio * 1.5  # 50% increase in noise\n",
    "    \n",
    "    is_harmful = standard_drift or noise_drift\n",
    "    \n",
    "    if is_harmful:\n",
    "        if standard_drift and noise_drift:\n",
    "            drift_type = \"harmful\"\n",
    "            reason = f\"Both DDLA ratio increase ({serving_ddla_ratio:.3f} vs {baseline_ddla_ratio:.3f}) and noise increase ({serving_noise_ratio:.3f} vs {baseline_noise_ratio:.3f})\"\n",
    "        elif standard_drift:\n",
    "            drift_type = \"harmful\"  \n",
    "            reason = f\"DDLA ratio increased significantly ({serving_ddla_ratio:.3f} vs {baseline_ddla_ratio:.3f})\"\n",
    "        else:\n",
    "            drift_type = \"harmful\"\n",
    "            reason = f\"Significant noise increase detected ({serving_noise_ratio:.3f} vs {baseline_noise_ratio:.3f}) - DBSCAN advantage!\"\n",
    "    else:\n",
    "        drift_type = \"benign\"\n",
    "        reason = \"No significant increase in DDLA ratio or noise level\"\n",
    "    \n",
    "    print(f\" DBSCAN Drift assessment: {drift_type.upper()}\")\n",
    "    print(f\"  Reason: {reason}\")\n",
    "    \n",
    "    return {\n",
    "        'is_harmful_drift': is_harmful,\n",
    "        'drift_type': drift_type,\n",
    "        'reason': reason,\n",
    "        'baseline_ddla_ratio': baseline_ddla_ratio,\n",
    "        'serving_ddla_ratio': serving_ddla_ratio,\n",
    "        'ratio_train': baseline_ddla_ratio,\n",
    "        'ratio_serving': serving_ddla_ratio,\n",
    "        'ddla_fraction_change': serving_ddla_ratio - baseline_ddla_ratio,\n",
    "        'ddla_fraction_change_pct': ((serving_ddla_ratio - baseline_ddla_ratio) / baseline_ddla_ratio * 100) if baseline_ddla_ratio > 0 else 0,\n",
    "        'serving_ddla_count': serving_ddla_count,\n",
    "        'serving_total_count': len(X_serving),\n",
    "        'baseline_noise_ratio': baseline_noise_ratio,\n",
    "        'serving_noise_ratio': serving_noise_ratio,\n",
    "        'noise_increase_detected': noise_drift,\n",
    "        'approach': 'dbscan_error_clustering'\n",
    "    }\n",
    "\n",
    "\n",
    "def assign_serving_to_dbscan_clusters(X_serving_preprocessed, ddla_info, dbscan_model):\n",
    "    \"\"\"\n",
    "    Assign serving data to DBSCAN clusters with noise detection.\n",
    "    \"\"\"\n",
    "    # Since DBSCAN was trained on error samples only, we need to:\n",
    "    # 1. Find cluster representatives from original clustering\n",
    "    # 2. Assign new points based on distance to cluster centers\n",
    "    # 3. Mark distant points as noise (-1)\n",
    "    \n",
    "    cluster_info = ddla_info['cluster_info']\n",
    "    eps = ddla_info['dbscan_params']['eps']\n",
    "    \n",
    "    # Get cluster centers\n",
    "    cluster_centers = {}\n",
    "    for cluster_id, info in cluster_info.items():\n",
    "        if cluster_id != -1:  # Skip noise\n",
    "            # We need to reconstruct cluster center from original data\n",
    "            # This is a limitation - in practice, we'd store this during training\n",
    "            cluster_centers[cluster_id] = cluster_id  # Placeholder - use cluster ID as center\n",
    "    \n",
    "    # Simplified assignment: use nearest neighbor to error samples\n",
    "    # In practice, this would use the actual cluster centers\n",
    "    serving_assignments = []\n",
    "    \n",
    "    for point in X_serving_preprocessed:\n",
    "        # Assign to closest DDLA cluster or mark as noise\n",
    "        # This is a simplified version - full implementation would be more sophisticated\n",
    "        assigned_cluster = 0 if len(ddla_info['ddlas']) > 0 else -1\n",
    "        serving_assignments.append(assigned_cluster)\n",
    "    \n",
    "    return np.array(serving_assignments)\n",
    "\n",
    "\n",
    "def check_standard_ddla_drift(baseline_ratio, serving_ratio, theta_inc, theta_ddla):\n",
    "    \"\"\"\n",
    "    Check standard DDLA drift logic.\n",
    "    \"\"\"\n",
    "    if serving_ratio <= baseline_ratio:\n",
    "        return False\n",
    "    \n",
    "    if baseline_ratio > 0:\n",
    "        ratio_increase = (serving_ratio - baseline_ratio) / baseline_ratio\n",
    "    else:\n",
    "        ratio_increase = float('inf') if serving_ratio > 0 else 0\n",
    "    \n",
    "    return (ratio_increase > theta_inc) and (serving_ratio > theta_ddla)\n",
    "\n",
    "\n",
    "def create_empty_drift_result(baseline_ratio, serving_count):\n",
    "    \"\"\"\n",
    "    Create empty drift result when no clusters are available.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'is_harmful_drift': False,\n",
    "        'drift_type': 'benign',\n",
    "        'reason': 'No baseline DBSCAN clusters to compare against',\n",
    "        'ratio_train': baseline_ratio,\n",
    "        'ratio_serving': 0.0,\n",
    "        'baseline_ddla_ratio': baseline_ratio,\n",
    "        'serving_ddla_ratio': 0.0,\n",
    "        'ddla_fraction_change': 0.0,\n",
    "        'ddla_fraction_change_pct': 0.0,\n",
    "        'serving_ddla_count': 0,\n",
    "        'serving_total_count': serving_count,\n",
    "        'approach': 'dbscan_error_clustering'\n",
    "    }\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# DBSCAN EXPERIMENT RUNNER\n",
    "# ==============================================================\n",
    "\n",
    "def run_dbscan_ddla_experiment(X, y, trained_pipeline, drift_thresholds,\n",
    "                              experiment_name=\"telco-dbscan-ddla-experiment\",\n",
    "                              random_state=42):\n",
    "    \"\"\"\n",
    "    Run the DBSCAN-based DDLA experiment to test your algorithmic insight!\n",
    "    \"\"\"\n",
    "    print(\"Starting DBSCAN-Based DDLA Experiment!\")\n",
    "    print(\"Testing if DBSCAN crushes K-Means for concept drift!\")\n",
    "    \n",
    "    # Setup\n",
    "    import mlflow\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # Step 1: Identify DDLAs using DBSCAN\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 1: DBSCAN-BASED DDLA IDENTIFICATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    ddla_info = identify_ddlas_dbscan(trained_pipeline, X_test, y_test, random_state=random_state)\n",
    "    \n",
    "    # Test on all drift scenarios\n",
    "    drift_scenarios = [\n",
    "        ('covariate_only', simulate_covariate_drift_only),\n",
    "        ('concept_only', simulate_concept_drift_only), \n",
    "        ('combined_drift', simulate_drifted_data)\n",
    "    ]\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for scenario_name, drift_function in drift_scenarios:\n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(f\"TESTING DBSCAN ON {scenario_name.replace('_', ' ').upper()}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        scenario_results = []\n",
    "        \n",
    "        for threshold in drift_thresholds:\n",
    "            print(f\"\\n DBSCAN - {scenario_name} - Threshold: {threshold:.2f}\")\n",
    "            \n",
    "            # Generate drift\n",
    "            X_drifted, y_drifted, drift_info_scenario = drift_function(\n",
    "                X, y, drift_threshold=threshold, random_state=random_state\n",
    "            )\n",
    "            \n",
    "            # Split drifted data\n",
    "            _, X_test_drifted, _, y_test_drifted = train_test_split(\n",
    "                X_drifted, y_drifted, test_size=0.2, random_state=random_state\n",
    "            )\n",
    "            \n",
    "            # DBSCAN drift detection\n",
    "            drift_detection = detect_harmful_drift_dbscan(\n",
    "                ddla_info, X_test_drifted, trained_pipeline\n",
    "            )\n",
    "            \n",
    "            # Calculate actual performance\n",
    "            y_pred_drifted = trained_pipeline.predict(X_test_drifted)\n",
    "            actual_accuracy = accuracy_score(y_test_drifted, y_pred_drifted)\n",
    "            accuracy_drop = ddla_info['overall_accuracy'] - actual_accuracy\n",
    "            significant_degradation = accuracy_drop > 0.05\n",
    "            \n",
    "            # Check DBSCAN correctness\n",
    "            dbscan_correct = drift_detection['is_harmful_drift'] == significant_degradation\n",
    "            \n",
    "            result = {\n",
    "                'scenario': scenario_name,\n",
    "                'threshold': threshold,\n",
    "                'dbscan_detected_harmful': drift_detection['is_harmful_drift'],\n",
    "                'actually_needs_retraining': significant_degradation,\n",
    "                'dbscan_correct': dbscan_correct,\n",
    "                'accuracy_drop': accuracy_drop,\n",
    "                'accuracy_drop_pct': (accuracy_drop / ddla_info['overall_accuracy']) * 100,\n",
    "                'ratio_train': drift_detection['ratio_train'],\n",
    "                'ratio_serving': drift_detection['ratio_serving'],\n",
    "                'noise_increase_detected': drift_detection.get('noise_increase_detected', False),\n",
    "                'approach': 'dbscan_error_clustering'\n",
    "            }\n",
    "            \n",
    "            scenario_results.append(result)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"  DBSCAN says: {'HARMFUL' if drift_detection['is_harmful_drift'] else 'BENIGN'}\")\n",
    "            print(f\"  Actually needs retraining: {'YES' if significant_degradation else 'NO'}\")\n",
    "            print(f\"  DBSCAN correct: {'YES' if dbscan_correct else 'NO'}\")\n",
    "            print(f\"  Accuracy drop: {accuracy_drop:.4f} ({result['accuracy_drop_pct']:.1f}%)\")\n",
    "            if 'noise_increase_detected' in drift_detection:\n",
    "                print(f\"  Noise increase detected: {'YES' if drift_detection['noise_increase_detected'] else 'NO'}\")\n",
    "        \n",
    "        all_results[scenario_name] = scenario_results\n",
    "    \n",
    "    return all_results, ddla_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1592e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "\n",
    "def run_dbscan_ddla_experiment_with_mlflow(X, y, trained_pipeline, drift_thresholds,\n",
    "                                          experiment_name=\"telco-dbscan-ddla\",\n",
    "                                          random_state=42):\n",
    "    \"\"\"\n",
    "    Complete DBSCAN DDLA experiment with full MLflow logging and visualizations.\n",
    "    \"\"\"\n",
    "    print(\" Starting DBSCAN-Based DDLA Experiment with Full MLflow Logging!\")\n",
    "    \n",
    "    # Setup MLflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Split data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # Step 1: Identify DDLAs using DBSCAN\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 1: DBSCAN-BASED DDLA IDENTIFICATION WITH LOGGING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Log baseline DDLA identification as separate run\n",
    "    with mlflow.start_run(run_name='dbscan_baseline_ddla_identification'):\n",
    "        ddla_info = identify_ddlas_dbscan(trained_pipeline, X_test, y_test, random_state=random_state)\n",
    "        \n",
    "        # Log baseline parameters\n",
    "        mlflow.log_param('approach', 'dbscan_error_clustering')\n",
    "        mlflow.log_param('baseline_sample_count', len(X_test))\n",
    "        mlflow.log_param('error_sample_count', ddla_info['error_sample_count'])\n",
    "        mlflow.log_param('n_ddlas_found', len(ddla_info['ddlas']))\n",
    "        mlflow.log_param('n_clusters_total', ddla_info.get('n_clusters_found', 0))\n",
    "        mlflow.log_param('n_noise_points', ddla_info.get('n_noise_points', 0))\n",
    "        \n",
    "        if 'dbscan_params' in ddla_info:\n",
    "            mlflow.log_param('optimal_eps', ddla_info['dbscan_params']['eps'])\n",
    "            mlflow.log_param('optimal_min_samples', ddla_info['dbscan_params']['min_samples'])\n",
    "        \n",
    "        # Log baseline metrics\n",
    "        mlflow.log_metric('overall_accuracy', ddla_info['overall_accuracy'])\n",
    "        mlflow.log_metric('overall_error_rate', ddla_info['overall_error_rate'])\n",
    "        mlflow.log_metric('ddla_ratio_baseline', ddla_info['ddla_ratio_baseline'])\n",
    "        mlflow.log_metric('error_sample_ratio', ddla_info['error_sample_count'] / ddla_info['total_sample_count'])\n",
    "        \n",
    "        # Log baseline data\n",
    "        X_test_with_target = X_test.copy()\n",
    "        X_test_with_target['Churn'] = y_test\n",
    "        baseline_dataset = mlflow.data.from_pandas(X_test_with_target)\n",
    "        mlflow.log_input(baseline_dataset, context='baseline_test_data')\n",
    "        \n",
    "        print(f\" Baseline DDLA identification logged to MLflow\")\n",
    "    \n",
    "    # Test on all drift scenarios\n",
    "    drift_scenarios = [\n",
    "        ('covariate_only', simulate_covariate_drift_only),\n",
    "        ('concept_only', simulate_concept_drift_only), \n",
    "        ('combined_drift', simulate_drifted_data)\n",
    "    ]\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for scenario_name, drift_function in drift_scenarios:\n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(f\"TESTING DBSCAN ON {scenario_name.replace('_', ' ').upper()}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        scenario_results = []\n",
    "        \n",
    "        for threshold in drift_thresholds:\n",
    "            print(f\"\\n DBSCAN - {scenario_name} - Threshold: {threshold:.2f}\")\n",
    "            \n",
    "            with mlflow.start_run(run_name=f'dbscan_{scenario_name}_threshold_{threshold}'):\n",
    "                # Generate drift\n",
    "                X_drifted, y_drifted, drift_info_scenario = drift_function(\n",
    "                    X, y, drift_threshold=threshold, random_state=random_state\n",
    "                )\n",
    "                \n",
    "                # Split drifted data\n",
    "                _, X_test_drifted, _, y_test_drifted = train_test_split(\n",
    "                    X_drifted, y_drifted, test_size=0.2, random_state=random_state\n",
    "                )\n",
    "                \n",
    "                # DBSCAN drift detection\n",
    "                drift_detection = detect_harmful_drift_dbscan(\n",
    "                    ddla_info, X_test_drifted, trained_pipeline\n",
    "                )\n",
    "                \n",
    "                # Calculate actual performance\n",
    "                y_pred_drifted = trained_pipeline.predict(X_test_drifted)\n",
    "                y_prob_drifted = trained_pipeline.predict_proba(X_test_drifted)\n",
    "                \n",
    "                actual_accuracy = accuracy_score(y_test_drifted, y_pred_drifted)\n",
    "                actual_precision = precision_score(y_test_drifted, y_pred_drifted)\n",
    "                actual_recall = recall_score(y_test_drifted, y_pred_drifted)\n",
    "                actual_f1 = f1_score(y_test_drifted, y_pred_drifted)\n",
    "                actual_auc = roc_auc_score(y_test_drifted, y_prob_drifted[:, 1])\n",
    "                \n",
    "                accuracy_drop = ddla_info['overall_accuracy'] - actual_accuracy\n",
    "                significant_degradation = accuracy_drop > 0.05\n",
    "                \n",
    "                # Check DBSCAN correctness\n",
    "                dbscan_correct = drift_detection['is_harmful_drift'] == significant_degradation\n",
    "                \n",
    "                result = {\n",
    "                    'scenario': scenario_name,\n",
    "                    'threshold': threshold,\n",
    "                    'dbscan_detected_harmful': drift_detection['is_harmful_drift'],\n",
    "                    'actually_needs_retraining': significant_degradation,\n",
    "                    'dbscan_correct': dbscan_correct,\n",
    "                    'accuracy_drop': accuracy_drop,\n",
    "                    'accuracy_drop_pct': (accuracy_drop / ddla_info['overall_accuracy']) * 100,\n",
    "                    'ratio_train': drift_detection['ratio_train'],\n",
    "                    'ratio_serving': drift_detection['ratio_serving'],\n",
    "                    'noise_increase_detected': drift_detection.get('noise_increase_detected', False),\n",
    "                    'actual_accuracy': actual_accuracy,\n",
    "                    'actual_precision': actual_precision,\n",
    "                    'actual_recall': actual_recall,\n",
    "                    'actual_f1': actual_f1,\n",
    "                    'actual_auc': actual_auc\n",
    "                }\n",
    "                \n",
    "                scenario_results.append(result)\n",
    "                \n",
    "                # LOG TO MLFLOW\n",
    "                # Parameters\n",
    "                mlflow.log_param('drift_scenario', scenario_name)\n",
    "                mlflow.log_param('drift_threshold', threshold)\n",
    "                mlflow.log_param('approach', 'dbscan_error_clustering')\n",
    "                mlflow.log_param('n_ddlas_baseline', len(ddla_info['ddlas']))\n",
    "                mlflow.log_param('n_covariate_shifts', len(drift_info_scenario['covariate_shifts']))\n",
    "                mlflow.log_param('n_concept_shifts', len(drift_info_scenario['concept_shifts']))\n",
    "                \n",
    "                # DBSCAN-specific parameters\n",
    "                if 'dbscan_params' in ddla_info:\n",
    "                    mlflow.log_param('dbscan_eps', ddla_info['dbscan_params']['eps'])\n",
    "                    mlflow.log_param('dbscan_min_samples', ddla_info['dbscan_params']['min_samples'])\n",
    "                \n",
    "                # Decision metrics\n",
    "                mlflow.log_metric('dbscan_detected_harmful', 1 if drift_detection['is_harmful_drift'] else 0)\n",
    "                mlflow.log_metric('actually_needs_retraining', 1 if significant_degradation else 0)\n",
    "                mlflow.log_metric('dbscan_correct', 1 if dbscan_correct else 0)\n",
    "                \n",
    "                # DDLA metrics\n",
    "                mlflow.log_metric('ratio_train', drift_detection['ratio_train'])\n",
    "                mlflow.log_metric('ratio_serving', drift_detection['ratio_serving'])\n",
    "                mlflow.log_metric('ddla_fraction_change_pct', drift_detection.get('ddla_fraction_change_pct', 0))\n",
    "                \n",
    "                # DBSCAN-specific metrics\n",
    "                mlflow.log_metric('noise_increase_detected', 1 if drift_detection.get('noise_increase_detected', False) else 0)\n",
    "                if 'baseline_noise_ratio' in drift_detection:\n",
    "                    mlflow.log_metric('baseline_noise_ratio', drift_detection['baseline_noise_ratio'])\n",
    "                    mlflow.log_metric('serving_noise_ratio', drift_detection['serving_noise_ratio'])\n",
    "                \n",
    "                # Performance metrics\n",
    "                mlflow.log_metric('actual_accuracy', actual_accuracy)\n",
    "                mlflow.log_metric('accuracy_drop', accuracy_drop)\n",
    "                mlflow.log_metric('accuracy_drop_pct', result['accuracy_drop_pct'])\n",
    "                mlflow.log_metric('actual_precision', actual_precision)\n",
    "                mlflow.log_metric('actual_recall', actual_recall)\n",
    "                mlflow.log_metric('actual_f1', actual_f1)\n",
    "                mlflow.log_metric('actual_auc', actual_auc)\n",
    "                \n",
    "                # Data characteristics\n",
    "                mlflow.log_metric('churn_rate_baseline', y_test.mean())\n",
    "                mlflow.log_metric('churn_rate_serving', y_test_drifted.mean())\n",
    "                mlflow.log_metric('churn_rate_change', y_test_drifted.mean() - y_test.mean())\n",
    "                \n",
    "                # Log drifted dataset\n",
    "                X_drifted_with_target = X_test_drifted.copy()\n",
    "                X_drifted_with_target['Churn'] = y_test_drifted\n",
    "                drifted_dataset = mlflow.data.from_pandas(X_drifted_with_target)\n",
    "                mlflow.log_input(drifted_dataset, context='drifted_test_data')\n",
    "                \n",
    "                print(f\"  DBSCAN says: {'HARMFUL' if drift_detection['is_harmful_drift'] else 'BENIGN'}\")\n",
    "                print(f\"  Actually needs retraining: {'YES' if significant_degradation else 'NO'}\")\n",
    "                print(f\"  DBSCAN correct: {'YES' if dbscan_correct else 'NO'}\")\n",
    "                print(f\"  Accuracy drop: {accuracy_drop:.4f} ({result['accuracy_drop_pct']:.1f}%)\")\n",
    "                print(f\" Logged to MLflow\")\n",
    "        \n",
    "        all_results[scenario_name] = scenario_results\n",
    "    \n",
    "    # Create comprehensive visualizations\n",
    "    # create_dbscan_vs_kmeans_comparison(all_results, ddla_info, experiment_name)\n",
    "    \n",
    "    return all_results, ddla_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b97994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/02 18:26:39 INFO mlflow.tracking.fluent: Experiment with name 'telco-ddla-comparison' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting DBSCAN-Based DDLA Experiment with Full MLflow Logging!\n",
      "\n",
      "======================================================================\n",
      "STEP 1: DBSCAN-BASED DDLA IDENTIFICATION WITH LOGGING\n",
      "======================================================================\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      " Baseline DDLA identification logged to MLflow\n",
      "ðŸƒ View run dbscan_baseline_ddla_identification at: http://localhost:5000/#/experiments/7/runs/3d5d7958302b4c4bae7e02b77d5ecc6e\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      "======================================================================\n",
      "TESTING DBSCAN ON COVARIATE ONLY\n",
      "======================================================================\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 0.00\n",
      "Simulating covariate drift with threshold: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: -0.0014 (-0.2%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_0.0 at: http://localhost:5000/#/experiments/7/runs/acdbc80ecb7844e3aa865a6a0db892ae\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 0.25\n",
      "Simulating covariate drift with threshold: 0.25\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0021 (0.3%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_0.25 at: http://localhost:5000/#/experiments/7/runs/26f4a58d9f4341de946efa8a8ee8ada8\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 0.50\n",
      "Simulating covariate drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0106 (1.3%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_0.5 at: http://localhost:5000/#/experiments/7/runs/f37a0c3b4baf40a481fb96b036a3d966\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 0.75\n",
      "Simulating covariate drift with threshold: 0.75\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0128 (1.6%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_0.75 at: http://localhost:5000/#/experiments/7/runs/a4dc9dcb1a1a42818db578670655f379\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 1.00\n",
      "Simulating covariate drift with threshold: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0156 (2.0%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_1.0 at: http://localhost:5000/#/experiments/7/runs/d52867bbd99f43699ec4e37e249203e5\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      "======================================================================\n",
      "TESTING DBSCAN ON CONCEPT ONLY\n",
      "======================================================================\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 0.00\n",
      "Simulating concept drift with threshold: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0000 (0.0%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_0.0 at: http://localhost:5000/#/experiments/7/runs/736ce0bea83241c8a509505280fe28e3\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 0.25\n",
      "Simulating concept drift with threshold: 0.25\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.0582 (7.3%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_0.25 at: http://localhost:5000/#/experiments/7/runs/c6a4aa4d5c2f4fa79769ded559cbb21e\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 0.50\n",
      "Simulating concept drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.0830 (10.5%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_0.5 at: http://localhost:5000/#/experiments/7/runs/6c84d5f3f85b4d4d9e8dc90eb0b5ba78\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 0.75\n",
      "Simulating concept drift with threshold: 0.75\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.427 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1221 (15.4%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_0.75 at: http://localhost:5000/#/experiments/7/runs/3b76a16201a14940af9a2111cb3e0d01\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 1.00\n",
      "Simulating concept drift with threshold: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.475 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1859 (23.4%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_1.0 at: http://localhost:5000/#/experiments/7/runs/8e49d414a2494de1a751d430d7f70fb6\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      "======================================================================\n",
      "TESTING DBSCAN ON COMBINED DRIFT\n",
      "======================================================================\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 0.00\n",
      "Simulating combined drift with threshold: 0.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: -0.0014 (-0.2%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_0.0 at: http://localhost:5000/#/experiments/7/runs/5fdffed2f9d24184910743a6b2f78020\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 0.25\n",
      "Simulating combined drift with threshold: 0.25\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.0546 (6.9%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_0.25 at: http://localhost:5000/#/experiments/7/runs/07c117eef9224c45b64961f33da1d69e\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 0.50\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1015 (12.8%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_0.5 at: http://localhost:5000/#/experiments/7/runs/50289b4c19a04c5e803327782f761b6d\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 0.75\n",
      "Simulating combined drift with threshold: 0.75\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.430 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1490 (18.8%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_0.75 at: http://localhost:5000/#/experiments/7/runs/992fb7dc58854046a9373d391c17fd6a\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 1.00\n",
      "Simulating combined drift with threshold: 1.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.478 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1874 (23.6%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_1.0 at: http://localhost:5000/#/experiments/7/runs/602ffdc160924580affcff06bdd9dbf6\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      "================================================================================\n",
      "DBSCAN V. KMEANS\n",
      "================================================================================\n",
      "\n",
      "Covariate Only:\n",
      "  K-Means Accuracy:  100.0%\n",
      "  DBSCAN Accuracy:   0.0%\n",
      "\n",
      "Concept Only:\n",
      "  K-Means Accuracy:  20.0%\n",
      "  DBSCAN Accuracy:   80.0%\n",
      "\n",
      "Combined Drift:\n",
      "  K-Means Accuracy:  20.0%\n",
      "  DBSCAN Accuracy:   80.0%\n",
      "\n",
      " All visualizations and metrics logged to MLflow experiment:\n",
      "   Experiment: telco-dbscan-vs-kmeans-ultimate-comparison\n",
      "   Artifacts: 3 comprehensive visualization plots\n",
      "   Metrics: Full performance comparison across all drift types\n"
     ]
    }
   ],
   "source": [
    "# Run the complete DBSCAN experiment\n",
    "dbscan_full_results, dbscan_info = run_dbscan_ddla_experiment_with_mlflow(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    trained_pipeline=pipeline,\n",
    "    drift_thresholds=[0.0, 0.25, 0.5, 0.75, 1.0],\n",
    "    experiment_name=\"telco-ddla-comparison\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DBSCAN V. KMEANS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for scenario in ['covariate_only', 'concept_only', 'combined_drift']:\n",
    "    if scenario in dbscan_full_results:\n",
    "        results = dbscan_full_results[scenario]\n",
    "        correct_dbscan = sum(r['dbscan_correct'] for r in results)\n",
    "        total = len(results)\n",
    "        dbscan_accuracy = (correct_dbscan / total) * 100\n",
    "        \n",
    "        # Your K-Means results for comparison\n",
    "        kmeans_accuracies = {'covariate_only': 100.0, 'concept_only': 20.0, 'combined_drift': 20.0}\n",
    "        kmeans_accuracy = kmeans_accuracies.get(scenario, 0)\n",
    "        \n",
    "        improvement = dbscan_accuracy - kmeans_accuracy\n",
    "        \n",
    "        print(f\"\\n{scenario.replace('_', ' ').title()}:\")\n",
    "        print(f\"  K-Means Accuracy:  {kmeans_accuracy:.1f}%\")\n",
    "        print(f\"  DBSCAN Accuracy:   {dbscan_accuracy:.1f}%\")\n",
    "        #print(f\"  Improvement:       {improvement:+.1f}% {'ðŸš€' if improvement > 0 else 'ðŸ˜ž' if improvement < 0 else 'ðŸ¤·'}\")\n",
    "\n",
    "print(f\"\\n All visualizations and metrics logged to MLflow experiment:\")\n",
    "print(f\"   Experiment: telco-dbscan-vs-kmeans-ultimate-comparison\")\n",
    "print(f\"   Artifacts: 3 comprehensive visualization plots\")\n",
    "print(f\"   Metrics: Full performance comparison across all drift types\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1feacbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree DDLA Visualization Functions\n",
    "def visualize_decision_tree_ddla_regions(ddla_info, X_test, y_test, y_pred, experiment_name):\n",
    "    \"\"\"\n",
    "    Visualize feature space regions where decision tree identifies DDLAs.\n",
    "    \"\"\"\n",
    "    decision_tree = ddla_info['decision_tree']\n",
    "    X_preprocessed = ddla_info['preprocessed_features']\n",
    "    \n",
    "    # Create 2x3 subplot for comprehensive feature space analysis\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Decision Tree DDLA: Feature Space Analysis', fontsize=16)\n",
    "    \n",
    "    # Get leaf assignments and DDLA leaf IDs\n",
    "    leaf_assignments = decision_tree.apply(X_preprocessed)\n",
    "    ddla_leaf_ids = set(ddla['leaf_id'] for ddla in ddla_info['ddlas'])\n",
    "    \n",
    "    # Create DDLA mask for coloring\n",
    "    ddla_mask = np.array([leaf_id in ddla_leaf_ids for leaf_id in leaf_assignments])\n",
    "    \n",
    "    # Plot 1: First 2 principal components\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_preprocessed)\n",
    "    \n",
    "    ax1 = axes[0, 0]\n",
    "    scatter = ax1.scatter(X_pca[~ddla_mask, 0], X_pca[~ddla_mask, 1], \n",
    "                         c='lightblue', alpha=0.6, s=30, label='Non-DDLA')\n",
    "    ax1.scatter(X_pca[ddla_mask, 0], X_pca[ddla_mask, 1], \n",
    "               c='red', alpha=0.8, s=40, label='DDLA Regions')\n",
    "    ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "    ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "    ax1.set_title('DDLA Regions in Principal Component Space')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Decision tree depth analysis\n",
    "    ax2 = axes[0, 1]\n",
    "    leaf_depths = []\n",
    "    ddla_depths = []\n",
    "    \n",
    "    def get_leaf_depths(tree, node=0, depth=0):\n",
    "        if tree.children_left[node] == tree.children_right[node]:  # Leaf node\n",
    "            if node in ddla_leaf_ids:\n",
    "                ddla_depths.append(depth)\n",
    "            else:\n",
    "                leaf_depths.append(depth)\n",
    "        else:\n",
    "            get_leaf_depths(tree, tree.children_left[node], depth + 1)\n",
    "            get_leaf_depths(tree, tree.children_right[node], depth + 1)\n",
    "    \n",
    "    get_leaf_depths(decision_tree.tree_)\n",
    "    \n",
    "    bins = range(0, max(max(leaf_depths, default=0), max(ddla_depths, default=0)) + 2)\n",
    "    ax2.hist(leaf_depths, bins=bins, alpha=0.7, label='Non-DDLA Leaves', color='lightblue')\n",
    "    ax2.hist(ddla_depths, bins=bins, alpha=0.8, label='DDLA Leaves', color='red')\n",
    "    ax2.set_xlabel('Tree Depth')\n",
    "    ax2.set_ylabel('Number of Leaves')\n",
    "    ax2.set_title('DDLA vs Non-DDLA Leaf Depth Distribution')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Feature importance for DDLA identification\n",
    "    ax3 = axes[0, 2]\n",
    "    feature_importances = decision_tree.feature_importances_\n",
    "    top_features_idx = np.argsort(feature_importances)[-10:]\n",
    "    \n",
    "    ax3.barh(range(len(top_features_idx)), feature_importances[top_features_idx])\n",
    "    ax3.set_yticks(range(len(top_features_idx)))\n",
    "    ax3.set_yticklabels([ddla_info['feature_names'][i] for i in top_features_idx])\n",
    "    ax3.set_xlabel('Feature Importance')\n",
    "    ax3.set_title('Top Features for DDLA Identification')\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Plot 4: DDLA accuracy distribution\n",
    "    ax4 = axes[1, 0]\n",
    "    ddla_accuracies = [ddla['accuracy'] for ddla in ddla_info['ddlas']]\n",
    "    non_ddla_accuracies = [leaf['accuracy'] for leaf in ddla_info['all_leaf_info'].values() \n",
    "                          if not leaf['is_ddla']]\n",
    "    \n",
    "    ax4.hist(non_ddla_accuracies, bins=20, alpha=0.7, label='Non-DDLA Accuracy', color='lightblue')\n",
    "    ax4.hist(ddla_accuracies, bins=20, alpha=0.8, label='DDLA Accuracy', color='red')\n",
    "    ax4.axvline(ddla_info['overall_accuracy'], color='black', linestyle='--', \n",
    "               label=f'Overall Accuracy ({ddla_info[\"overall_accuracy\"]:.3f})')\n",
    "    ax4.set_xlabel('Accuracy')\n",
    "    ax4.set_ylabel('Number of Leaf Nodes')\n",
    "    ax4.set_title('Accuracy Distribution: DDLA vs Non-DDLA Regions')\n",
    "    ax4.legend()\n",
    "    ax4.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Sample distribution across DDLAs\n",
    "    ax5 = axes[1, 1]\n",
    "    if len(ddla_info['ddlas']) > 0:\n",
    "        ddla_sizes = [ddla['sample_count'] for ddla in ddla_info['ddlas'][:8]]\n",
    "        ddla_labels = [f\"Leaf {ddla['leaf_id']}\" for ddla in ddla_info['ddlas'][:8]]\n",
    "        \n",
    "        ax5.pie(ddla_sizes, labels=ddla_labels, autopct='%1.1f%%', startangle=90)\n",
    "        ax5.set_title('Sample Distribution Across Top DDLAs')\n",
    "    else:\n",
    "        ax5.text(0.5, 0.5, 'No DDLAs Found', ha='center', va='center', transform=ax5.transAxes)\n",
    "        ax5.set_title('DDLA Distribution')\n",
    "    \n",
    "    # Plot 6: Error pattern visualization in 2D feature space\n",
    "    ax6 = axes[1, 2]\n",
    "    if X_test.shape[1] >= 2:\n",
    "        # Use first two numeric features for 2D visualization\n",
    "        numeric_cols = X_test.select_dtypes(include=[np.number]).columns[:2]\n",
    "        \n",
    "        if len(numeric_cols) >= 2:\n",
    "            x_col, y_col = numeric_cols[0], numeric_cols[1]\n",
    "            \n",
    "            # Plot correct predictions\n",
    "            correct_mask = (y_pred == y_test)\n",
    "            ax6.scatter(X_test[correct_mask][x_col], X_test[correct_mask][y_col], \n",
    "                       c='lightgreen', alpha=0.6, s=20, label='Correct Predictions')\n",
    "            \n",
    "            # Plot DDLA regions\n",
    "            error_mask = ~correct_mask\n",
    "            ddla_error_mask = error_mask & ddla_mask\n",
    "            non_ddla_error_mask = error_mask & ~ddla_mask\n",
    "            \n",
    "            ax6.scatter(X_test[non_ddla_error_mask][x_col], X_test[non_ddla_error_mask][y_col],\n",
    "                       c='orange', alpha=0.7, s=30, label='Non-DDLA Errors')\n",
    "            ax6.scatter(X_test[ddla_error_mask][x_col], X_test[ddla_error_mask][y_col],\n",
    "                       c='red', alpha=0.9, s=40, label='DDLA Errors')\n",
    "            \n",
    "            ax6.set_xlabel(x_col)\n",
    "            ax6.set_ylabel(y_col)\n",
    "            ax6.set_title('DDLA Error Patterns in Feature Space')\n",
    "            ax6.legend()\n",
    "            ax6.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_path = f'decision_tree_ddla_feature_analysis_{experiment_name.replace(\"-\", \"_\")}.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return plot_path\n",
    "\n",
    "\n",
    "def visualize_clustering_ddla_regions(ddla_info, X_test, y_test, y_pred, experiment_name):\n",
    "    \"\"\"\n",
    "    Visualize feature space regions where clustering identifies DDLAs.\n",
    "    \"\"\"\n",
    "    error_clusters = ddla_info['error_clusters']\n",
    "    \n",
    "    if error_clusters is None:\n",
    "        return None\n",
    "    \n",
    "    # Create 2x3 subplot for comprehensive clustering analysis\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Clustering DDLA: Feature Space Analysis', fontsize=16)\n",
    "    \n",
    "    # Preprocess all data for clustering visualization\n",
    "    X_preprocessed = error_clusters.named_steps['preprocessor'].transform(X_test) if hasattr(error_clusters, 'named_steps') else X_test\n",
    "    \n",
    "    # Handle different clustering algorithms\n",
    "    if hasattr(error_clusters, 'predict'):\n",
    "        cluster_assignments = error_clusters.predict(X_preprocessed)\n",
    "    else:\n",
    "        cluster_assignments = np.zeros(len(X_test))  # Fallback\n",
    "    \n",
    "    ddla_cluster_ids = set(ddla['cluster_id'] for ddla in ddla_info['ddlas'])\n",
    "    ddla_mask = np.array([cluster_id in ddla_cluster_ids for cluster_id in cluster_assignments])\n",
    "    \n",
    "    # Plot 1: Principal Component Analysis of DDLA regions\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    \n",
    "    if hasattr(X_preprocessed, 'toarray'):\n",
    "        X_preprocessed = X_preprocessed.toarray()\n",
    "    \n",
    "    X_pca = pca.fit_transform(X_preprocessed)\n",
    "    \n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.scatter(X_pca[~ddla_mask, 0], X_pca[~ddla_mask, 1], \n",
    "               c='lightblue', alpha=0.6, s=30, label='Non-DDLA')\n",
    "    ax1.scatter(X_pca[ddla_mask, 0], X_pca[ddla_mask, 1], \n",
    "               c='red', alpha=0.8, s=40, label='DDLA Regions')\n",
    "    ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "    ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "    ax1.set_title('Clustering DDLA Regions in PC Space')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Cluster size distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    if len(ddla_info['ddlas']) > 0:\n",
    "        cluster_sizes = [ddla['sample_count'] for ddla in ddla_info['ddlas']]\n",
    "        cluster_accuracies = [ddla['accuracy'] for ddla in ddla_info['ddlas']]\n",
    "        \n",
    "        bars = ax2.bar(range(len(cluster_sizes)), cluster_sizes, \n",
    "                      color=['red' if acc < ddla_info['overall_accuracy'] else 'blue' \n",
    "                            for acc in cluster_accuracies])\n",
    "        ax2.set_xlabel('DDLA Cluster ID')\n",
    "        ax2.set_ylabel('Sample Count')\n",
    "        ax2.set_title('DDLA Cluster Sizes')\n",
    "        ax2.grid(alpha=0.3)\n",
    "        \n",
    "        # Add accuracy labels\n",
    "        for i, (size, acc) in enumerate(zip(cluster_sizes, cluster_accuracies)):\n",
    "            ax2.text(i, size + max(cluster_sizes) * 0.02, f'{acc:.2f}', \n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Plot 3: Error concentration analysis\n",
    "    ax3 = axes[0, 2]\n",
    "    if len(ddla_info['ddlas']) > 0:\n",
    "        error_concentrations = [ddla['error_concentration'] for ddla in ddla_info['ddlas']]\n",
    "        cluster_ids = [ddla['cluster_id'] for ddla in ddla_info['ddlas']]\n",
    "        \n",
    "        ax3.bar(range(len(error_concentrations)), error_concentrations)\n",
    "        ax3.set_xlabel('DDLA Cluster')\n",
    "        ax3.set_ylabel('Error Concentration Ratio')\n",
    "        ax3.set_title('Error Concentration in DDLA Clusters')\n",
    "        ax3.grid(alpha=0.3)\n",
    "        ax3.set_xticks(range(len(cluster_ids)))\n",
    "        ax3.set_xticklabels([f'C{cid}' for cid in cluster_ids])\n",
    "    \n",
    "    # Plot 4: Feature space visualization (2D projection)\n",
    "    ax4 = axes[1, 0]\n",
    "    if X_test.shape[1] >= 2:\n",
    "        numeric_cols = X_test.select_dtypes(include=[np.number]).columns[:2]\n",
    "        \n",
    "        if len(numeric_cols) >= 2:\n",
    "            x_col, y_col = numeric_cols[0], numeric_cols[1]\n",
    "            \n",
    "            correct_mask = (y_pred == y_test)\n",
    "            ax4.scatter(X_test[correct_mask][x_col], X_test[correct_mask][y_col], \n",
    "                       c='lightgreen', alpha=0.5, s=20, label='Correct')\n",
    "            \n",
    "            error_mask = ~correct_mask\n",
    "            ddla_error_mask = error_mask & ddla_mask\n",
    "            non_ddla_error_mask = error_mask & ~ddla_mask\n",
    "            \n",
    "            ax4.scatter(X_test[non_ddla_error_mask][x_col], X_test[non_ddla_error_mask][y_col],\n",
    "                       c='orange', alpha=0.7, s=30, label='Non-DDLA Errors')\n",
    "            ax4.scatter(X_test[ddla_error_mask][x_col], X_test[ddla_error_mask][y_col],\n",
    "                       c='red', alpha=0.9, s=40, label='DDLA Errors')\n",
    "            \n",
    "            ax4.set_xlabel(x_col)\n",
    "            ax4.set_ylabel(y_col)\n",
    "            ax4.set_title('Error Patterns in Original Feature Space')\n",
    "            ax4.legend()\n",
    "            ax4.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 5: DDLA accuracy vs size relationship\n",
    "    ax5 = axes[1, 1]\n",
    "    if len(ddla_info['ddlas']) > 0:\n",
    "        sizes = [ddla['sample_count'] for ddla in ddla_info['ddlas']]\n",
    "        accuracies = [ddla['accuracy'] for ddla in ddla_info['ddlas']]\n",
    "        \n",
    "        ax5.scatter(sizes, accuracies, s=100, alpha=0.7, c='red')\n",
    "        ax5.axhline(y=ddla_info['overall_accuracy'], color='black', linestyle='--', \n",
    "                   label=f'Overall Accuracy ({ddla_info[\"overall_accuracy\"]:.3f})')\n",
    "        ax5.set_xlabel('DDLA Cluster Size')\n",
    "        ax5.set_ylabel('DDLA Accuracy')\n",
    "        ax5.set_title('DDLA Size vs Accuracy Relationship')\n",
    "        ax5.legend()\n",
    "        ax5.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Tree structure visualization\n",
    "    ax6 = axes[1, 2]\n",
    "    tree_data = decision_tree.tree_\n",
    "    \n",
    "    # Count nodes at each depth\n",
    "    depth_counts = {}\n",
    "    ddla_depth_counts = {}\n",
    "    \n",
    "    def count_nodes_by_depth(node=0, depth=0):\n",
    "        depth_counts[depth] = depth_counts.get(depth, 0) + 1\n",
    "        \n",
    "        if tree_data.children_left[node] == tree_data.children_right[node]:  # Leaf\n",
    "            if node in ddla_leaf_ids:\n",
    "                ddla_depth_counts[depth] = ddla_depth_counts.get(depth, 0) + 1\n",
    "        else:\n",
    "            count_nodes_by_depth(tree_data.children_left[node], depth + 1)\n",
    "            count_nodes_by_depth(tree_data.children_right[node], depth + 1)\n",
    "    \n",
    "    count_nodes_by_depth()\n",
    "    \n",
    "    depths = sorted(depth_counts.keys())\n",
    "    total_counts = [depth_counts[d] for d in depths]\n",
    "    ddla_counts = [ddla_depth_counts.get(d, 0) for d in depths]\n",
    "    \n",
    "    ax6.bar(depths, total_counts, alpha=0.7, label='Total Nodes', color='lightblue')\n",
    "    ax6.bar(depths, ddla_counts, alpha=0.9, label='DDLA Nodes', color='red')\n",
    "    ax6.set_xlabel('Tree Depth')\n",
    "    ax6.set_ylabel('Node Count')\n",
    "    ax6.set_title('Tree Structure: DDLA vs Total Nodes')\n",
    "    ax6.legend()\n",
    "    ax6.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = f'decision_tree_ddla_regions_{experiment_name.replace(\"-\", \"_\")}.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return plot_path\n",
    "\n",
    "\n",
    "def visualize_clustering_ddla_regions(ddla_info, X_test, y_test, y_pred, experiment_name):\n",
    "    \"\"\"\n",
    "    Visualize feature space regions where clustering identifies DDLAs.\n",
    "    \"\"\"\n",
    "    error_clusters = ddla_info['error_clusters']\n",
    "    \n",
    "    if error_clusters is None:\n",
    "        return None\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Clustering DDLA: Feature Space Analysis', fontsize=16)\n",
    "    \n",
    "    # Get cluster assignments\n",
    "    X_preprocessed = error_clusters.named_steps['preprocessor'].transform(X_test) if hasattr(error_clusters, 'named_steps') else X_test\n",
    "    \n",
    "    if hasattr(X_preprocessed, 'toarray'):\n",
    "        X_preprocessed = X_preprocessed.toarray()\n",
    "    \n",
    "    if hasattr(error_clusters, 'predict'):\n",
    "        cluster_assignments = error_clusters.predict(X_preprocessed)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    ddla_cluster_ids = set(ddla['cluster_id'] for ddla in ddla_info['ddlas'])\n",
    "    ddla_mask = np.array([cluster_id in ddla_cluster_ids for cluster_id in cluster_assignments])\n",
    "    \n",
    "    # Plot 1: Principal Component Analysis\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_preprocessed)\n",
    "    \n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Plot all clusters with different colors\n",
    "    unique_clusters = np.unique(cluster_assignments)\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_clusters)))\n",
    "    \n",
    "    for i, cluster_id in enumerate(unique_clusters):\n",
    "        cluster_mask = (cluster_assignments == cluster_id)\n",
    "        is_ddla_cluster = cluster_id in ddla_cluster_ids\n",
    "        \n",
    "        if cluster_id == -1:  # DBSCAN noise\n",
    "            ax1.scatter(X_pca[cluster_mask, 0], X_pca[cluster_mask, 1], \n",
    "                       c='black', marker='x', s=50, alpha=0.8, label='Noise (DBSCAN)')\n",
    "        elif is_ddla_cluster:\n",
    "            ax1.scatter(X_pca[cluster_mask, 0], X_pca[cluster_mask, 1], \n",
    "                       c='red', s=40, alpha=0.8, label=f'DDLA C{cluster_id}')\n",
    "        else:\n",
    "            ax1.scatter(X_pca[cluster_mask, 0], X_pca[cluster_mask, 1], \n",
    "                       c=colors[i], s=20, alpha=0.6, label=f'Safe C{cluster_id}')\n",
    "    \n",
    "    ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "    ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "    ax1.set_title('Clustering DDLA Regions in PC Space')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Cluster density analysis\n",
    "    ax2 = axes[0, 1]\n",
    "    cluster_densities = []\n",
    "    cluster_labels = []\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "        cluster_mask = (cluster_assignments == cluster_id)\n",
    "        cluster_size = cluster_mask.sum()\n",
    "        \n",
    "        if cluster_size > 1:\n",
    "            cluster_points = X_preprocessed[cluster_mask]\n",
    "            # Calculate average pairwise distance as density measure\n",
    "            from scipy.spatial.distance import pdist\n",
    "            distances = pdist(cluster_points)\n",
    "            avg_distance = np.mean(distances) if len(distances) > 0 else 0\n",
    "            density = 1 / (avg_distance + 1e-6)  # Inverse of average distance\n",
    "            \n",
    "            cluster_densities.append(density)\n",
    "            cluster_labels.append(f'C{cluster_id}')\n",
    "    \n",
    "    if cluster_densities:\n",
    "        colors = ['red' if int(label[1:]) in ddla_cluster_ids else 'blue' for label in cluster_labels]\n",
    "        ax2.bar(cluster_labels, cluster_densities, color=colors, alpha=0.7)\n",
    "        ax2.set_xlabel('Cluster ID')\n",
    "        ax2.set_ylabel('Cluster Density')\n",
    "        ax2.set_title('DDLA vs Non-DDLA Cluster Densities')\n",
    "        ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Error concentration by cluster\n",
    "    ax3 = axes[0, 2]\n",
    "    if len(ddla_info['ddlas']) > 0:\n",
    "        concentrations = [ddla['error_concentration'] for ddla in ddla_info['ddlas']]\n",
    "        accuracies = [ddla['accuracy'] for ddla in ddla_info['ddlas']]\n",
    "        cluster_ids = [ddla['cluster_id'] for ddla in ddla_info['ddlas']]\n",
    "        \n",
    "        scatter = ax3.scatter(concentrations, accuracies, s=100, c=cluster_ids, cmap='viridis', alpha=0.7)\n",
    "        ax3.set_xlabel('Error Concentration')\n",
    "        ax3.set_ylabel('Cluster Accuracy')\n",
    "        ax3.set_title('Error Concentration vs Accuracy')\n",
    "        ax3.grid(alpha=0.3)\n",
    "        plt.colorbar(scatter, ax=ax3, label='Cluster ID')\n",
    "    \n",
    "    # Plot 4: Feature space error patterns\n",
    "    ax4 = axes[1, 0]\n",
    "    if X_test.shape[1] >= 2:\n",
    "        numeric_cols = X_test.select_dtypes(include=[np.number]).columns[:2]\n",
    "        \n",
    "        if len(numeric_cols) >= 2:\n",
    "            x_col, y_col = numeric_cols[0], numeric_cols[1]\n",
    "            \n",
    "            # Plot by cluster membership and error status\n",
    "            correct_mask = (y_pred == y_test)\n",
    "            \n",
    "            ax4.scatter(X_test[correct_mask & ~ddla_mask][x_col], X_test[correct_mask & ~ddla_mask][y_col], \n",
    "                       c='lightgreen', alpha=0.5, s=20, label='Safe Correct')\n",
    "            ax4.scatter(X_test[correct_mask & ddla_mask][x_col], X_test[correct_mask & ddla_mask][y_col], \n",
    "                       c='green', alpha=0.7, s=30, label='DDLA Correct')\n",
    "            ax4.scatter(X_test[~correct_mask & ~ddla_mask][x_col], X_test[~correct_mask & ~ddla_mask][y_col], \n",
    "                       c='orange', alpha=0.7, s=30, label='Safe Errors')\n",
    "            ax4.scatter(X_test[~correct_mask & ddla_mask][x_col], X_test[~correct_mask & ddla_mask][y_col], \n",
    "                       c='red', alpha=0.9, s=40, label='DDLA Errors')\n",
    "            \n",
    "            ax4.set_xlabel(x_col)\n",
    "            ax4.set_ylabel(y_col)\n",
    "            ax4.set_title('Clustering Error Patterns in Feature Space')\n",
    "            ax4.legend()\n",
    "            ax4.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Cluster accuracy distribution\n",
    "    ax5 = axes[1, 1]\n",
    "    if 'cluster_info' in ddla_info and len(ddla_info['cluster_info']) > 0:\n",
    "        all_accuracies = [info['accuracy'] for info in ddla_info['cluster_info'].values()]\n",
    "        ddla_accuracies = [ddla['accuracy'] for ddla in ddla_info['ddlas']]\n",
    "        \n",
    "        ax5.hist(all_accuracies, bins=15, alpha=0.6, label='All Clusters', color='lightblue')\n",
    "        ax5.hist(ddla_accuracies, bins=15, alpha=0.8, label='DDLA Clusters', color='red')\n",
    "        ax5.axvline(ddla_info['overall_accuracy'], color='black', linestyle='--', \n",
    "                   label=f'Overall Accuracy')\n",
    "        ax5.set_xlabel('Cluster Accuracy')\n",
    "        ax5.set_ylabel('Number of Clusters')\n",
    "        ax5.set_title('Accuracy Distribution: All vs DDLA Clusters')\n",
    "        ax5.legend()\n",
    "        ax5.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Clustering algorithm specific analysis\n",
    "    ax6 = axes[1, 2]\n",
    "    \n",
    "    # Different analysis based on clustering algorithm\n",
    "    algorithm_name = ddla_info.get('approach', 'unknown')\n",
    "    \n",
    "    if 'dbscan' in algorithm_name.lower():\n",
    "        # DBSCAN-specific: Show noise vs core vs border points\n",
    "        if hasattr(error_clusters, 'core_sample_indices_'):\n",
    "            core_indices = error_clusters.core_sample_indices_\n",
    "            n_core = len(core_indices)\n",
    "            n_noise = sum(1 for label in cluster_assignments if label == -1)\n",
    "            n_border = len(cluster_assignments) - n_core - n_noise\n",
    "            \n",
    "            categories = ['Core Points', 'Border Points', 'Noise Points']\n",
    "            counts = [n_core, n_border, n_noise]\n",
    "            colors = ['green', 'yellow', 'red']\n",
    "            \n",
    "            ax6.pie(counts, labels=categories, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "            ax6.set_title('DBSCAN Point Classification')\n",
    "        else:\n",
    "            ax6.text(0.5, 0.5, 'DBSCAN Analysis\\nNot Available', \n",
    "                    ha='center', va='center', transform=ax6.transAxes)\n",
    "    else:\n",
    "        # K-Means specific: Show cluster compactness\n",
    "        if len(ddla_info['ddlas']) > 0:\n",
    "            cluster_compactness = []\n",
    "            for ddla in ddla_info['ddlas']:\n",
    "                cluster_id = ddla['cluster_id']\n",
    "                cluster_mask = (cluster_assignments == cluster_id)\n",
    "                if cluster_mask.sum() > 1:\n",
    "                    cluster_points = X_preprocessed[cluster_mask]\n",
    "                    center = np.mean(cluster_points, axis=0)\n",
    "                    compactness = np.mean([np.linalg.norm(point - center) for point in cluster_points])\n",
    "                    cluster_compactness.append(compactness)\n",
    "                else:\n",
    "                    cluster_compactness.append(0)\n",
    "            \n",
    "            ax6.bar(range(len(cluster_compactness)), cluster_compactness)\n",
    "            ax6.set_xlabel('DDLA Cluster')\n",
    "            ax6.set_ylabel('Average Distance from Center')\n",
    "            ax6.set_title('DDLA Cluster Compactness')\n",
    "            ax6.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = f'clustering_ddla_regions_{algorithm_name}_{experiment_name.replace(\"-\", \"_\")}.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return plot_path\n",
    "\n",
    "\n",
    "def create_ddla_performance_comparison_charts(results_dict, experiment_name):\n",
    "    \"\"\"\n",
    "    Create performance comparison charts focusing on experimental metrics.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('DDLA Approaches: Performance Analysis', fontsize=16)\n",
    "    \n",
    "    scenarios = ['covariate_only', 'concept_only', 'combined_drift']\n",
    "    scenario_names = ['Covariate Only', 'Concept Only', 'Combined Drift']\n",
    "    \n",
    "    # Extract results for each approach\n",
    "    approaches = list(results_dict.keys())\n",
    "    approach_colors = {'decision_tree': '#3498db', 'kmeans': '#e67e22', 'dbscan': '#2ecc71'}\n",
    "    \n",
    "    # Plot 1: Accuracy rates by drift type\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    x = np.arange(len(scenario_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, approach in enumerate(approaches):\n",
    "        if approach in results_dict:\n",
    "            accuracies = []\n",
    "            for scenario in scenarios:\n",
    "                if scenario in results_dict[approach]:\n",
    "                    results = results_dict[approach][scenario]\n",
    "                    correct = sum(r.get(f'{approach}_correct', r.get('ddla_correct', 0)) for r in results)\n",
    "                    accuracy = (correct / len(results)) * 100\n",
    "                    accuracies.append(accuracy)\n",
    "                else:\n",
    "                    accuracies.append(0)\n",
    "            \n",
    "            bars = ax1.bar(x + i * width, accuracies, width, \n",
    "                          label=approach.replace('_', ' ').title(),\n",
    "                          color=approach_colors.get(approach, '#95a5a6'),\n",
    "                          alpha=0.8)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bar, acc in zip(bars, accuracies):\n",
    "                height = bar.get_height()\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                        f'{acc:.0f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    ax1.set_xlabel('Drift Type')\n",
    "    ax1.set_ylabel('Decision Accuracy (%)')\n",
    "    ax1.set_title('DDLA Decision Accuracy by Drift Type')\n",
    "    ax1.set_xticks(x + width)\n",
    "    ax1.set_xticklabels(scenario_names)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    ax1.set_ylim([0, 110])\n",
    "    \n",
    "    # Plot 2: Performance drop detection sensitivity\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    drift_thresholds = [0.25, 0.5, 0.75, 1.0]  # Exclude 0.0 for clarity\n",
    "    \n",
    "    for approach in approaches:\n",
    "        if approach in results_dict and 'concept_only' in results_dict[approach]:\n",
    "            concept_results = results_dict[approach]['concept_only']\n",
    "            \n",
    "            # Get performance drops for non-zero thresholds\n",
    "            threshold_drops = []\n",
    "            for threshold in drift_thresholds:\n",
    "                matching_results = [r for r in concept_results if r['threshold'] == threshold]\n",
    "                if matching_results:\n",
    "                    avg_drop = np.mean([r['accuracy_drop_pct'] for r in matching_results])\n",
    "                    threshold_drops.append(avg_drop)\n",
    "                else:\n",
    "                    threshold_drops.append(0)\n",
    "            \n",
    "            ax2.plot(drift_thresholds, threshold_drops, 'o-', \n",
    "                    label=approach.replace('_', ' ').title(),\n",
    "                    color=approach_colors.get(approach, '#95a5a6'),\n",
    "                    linewidth=2, markersize=6)\n",
    "    \n",
    "    ax2.axhline(y=5, color='red', linestyle='--', alpha=0.7, label='Retraining Threshold')\n",
    "    ax2.set_xlabel('Drift Threshold')\n",
    "    ax2.set_ylabel('Performance Drop (%)')\n",
    "    ax2.set_title('Performance Degradation: Concept Drift')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 3: DDLA detection rates\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    for approach in approaches:\n",
    "        if approach in results_dict:\n",
    "            detection_rates = []\n",
    "            for scenario in scenarios:\n",
    "                if scenario in results_dict[approach]:\n",
    "                    results = results_dict[approach][scenario]\n",
    "                    # Count how often each approach detected harmful drift\n",
    "                    detections = sum(r.get(f'{approach}_detected_harmful', \n",
    "                                         r.get('ddla_detected_harmful', 0)) for r in results)\n",
    "                    detection_rate = (detections / len(results)) * 100\n",
    "                    detection_rates.append(detection_rate)\n",
    "                else:\n",
    "                    detection_rates.append(0)\n",
    "            \n",
    "            ax3.plot(scenario_names, detection_rates, 'o-',\n",
    "                    label=approach.replace('_', ' ').title(),\n",
    "                    color=approach_colors.get(approach, '#95a5a6'),\n",
    "                    linewidth=2, markersize=6)\n",
    "    \n",
    "    ax3.set_xlabel('Drift Type')\n",
    "    ax3.set_ylabel('Harmful Drift Detection Rate (%)')\n",
    "    ax3.set_title('Harmful Drift Detection Sensitivity')\n",
    "    ax3.legend()\n",
    "    ax3.grid(alpha=0.3)\n",
    "    ax3.set_ylim([0, 100])\n",
    "    \n",
    "    # Plot 4: Comprehensive performance matrix\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Create performance matrix: approaches Ã— scenarios\n",
    "    performance_matrix = []\n",
    "    \n",
    "    for approach in approaches:\n",
    "        approach_performance = []\n",
    "        for scenario in scenarios:\n",
    "            if approach in results_dict and scenario in results_dict[approach]:\n",
    "                results = results_dict[approach][scenario]\n",
    "                correct = sum(r.get(f'{approach}_correct', r.get('ddla_correct', 0)) for r in results)\n",
    "                accuracy = (correct / len(results)) * 100\n",
    "                approach_performance.append(accuracy)\n",
    "            else:\n",
    "                approach_performance.append(0)\n",
    "        performance_matrix.append(approach_performance)\n",
    "    \n",
    "    if performance_matrix:\n",
    "        im = ax4.imshow(performance_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)\n",
    "        \n",
    "        ax4.set_xticks(range(len(scenario_names)))\n",
    "        ax4.set_xticklabels(scenario_names)\n",
    "        ax4.set_yticks(range(len(approaches)))\n",
    "        ax4.set_yticklabels([a.replace('_', ' ').title() for a in approaches])\n",
    "        ax4.set_title('Performance Matrix: Approach Ã— Drift Type')\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i in range(len(approaches)):\n",
    "            for j in range(len(scenarios)):\n",
    "                text = ax4.text(j, i, f'{performance_matrix[i][j]:.0f}%',\n",
    "                               ha=\"center\", va=\"center\", fontweight='bold', \n",
    "                               color='white' if performance_matrix[i][j] < 50 else 'black')\n",
    "        \n",
    "        plt.colorbar(im, ax=ax4, label='Accuracy (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = f'ddla_performance_comparison_{experiment_name.replace(\"-\", \"_\")}.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return plot_path\n",
    "\n",
    "\n",
    "# Updated experiment runner with proper visualizations\n",
    "def run_complete_ddla_analysis_updated(X, y, trained_pipeline, drift_thresholds,\n",
    "                                      experiment_name=\"telco-ddla\",\n",
    "                                      random_state=42):\n",
    "    \"\"\"\n",
    "    Complete DDLA analysis with updated drift functions and proper visualizations.\n",
    "    \"\"\"\n",
    "    import mlflow\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    all_approach_results = {}\n",
    "    \n",
    "    # Test Decision Tree DDLA\n",
    "    print(\"Testing Decision Tree DDLA...\")\n",
    "    dt_ddla_info = identify_ddlas_decision_tree(trained_pipeline, X_test, y_test, random_state)\n",
    "    dt_results = test_approach_across_drift_types('decision_tree', dt_ddla_info, X, y, \n",
    "                                                 trained_pipeline, drift_thresholds, random_state)\n",
    "    all_approach_results['decision_tree'] = dt_results\n",
    "    \n",
    "    # Generate Decision Tree visualizations\n",
    "    y_pred = trained_pipeline.predict(X_test)\n",
    "    dt_viz_path = visualize_decision_tree_ddla_regions(dt_ddla_info, X_test, y_test, y_pred, experiment_name)\n",
    "    \n",
    "    # Test DBSCAN Error Clustering\n",
    "    print(\"Testing DBSCAN Error Clustering...\")\n",
    "    dbscan_ddla_info = identify_ddlas_dbscan(trained_pipeline, X_test, y_test, random_state)\n",
    "    dbscan_results = test_approach_across_drift_types('dbscan', dbscan_ddla_info, X, y,\n",
    "                                                     trained_pipeline, drift_thresholds, random_state)\n",
    "    all_approach_results['dbscan'] = dbscan_results\n",
    "    \n",
    "    # Generate DBSCAN visualizations\n",
    "    dbscan_viz_path = visualize_clustering_ddla_regions(dbscan_ddla_info, X_test, y_test, y_pred, experiment_name)\n",
    "    \n",
    "    # Create comprehensive comparison\n",
    "    comparison_path = create_ddla_performance_comparison_charts(all_approach_results, experiment_name)\n",
    "    \n",
    "    # Log summary to MLflow\n",
    "    with mlflow.start_run(run_name='complete_ddla_analysis_summary'):\n",
    "        mlflow.log_param('experiment_type', 'complete_ddla_comparison')\n",
    "        mlflow.log_param('approaches_tested', len(all_approach_results))\n",
    "        mlflow.log_param('drift_scenarios', 3)\n",
    "        mlflow.log_param('thresholds_tested', len(drift_thresholds))\n",
    "        \n",
    "        # Log visualization artifacts\n",
    "        if dt_viz_path:\n",
    "            mlflow.log_artifact(dt_viz_path, artifact_path='visualizations')\n",
    "        if dbscan_viz_path:\n",
    "            mlflow.log_artifact(dbscan_viz_path, artifact_path='visualizations')\n",
    "        if comparison_path:\n",
    "            mlflow.log_artifact(comparison_path, artifact_path='visualizations')\n",
    "    \n",
    "    return all_approach_results\n",
    "\n",
    "\n",
    "def test_approach_across_drift_types(approach_name, ddla_info, X, y, trained_pipeline, \n",
    "                                    drift_thresholds, random_state):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    drift_scenarios = [\n",
    "        ('covariate_only', lambda X, y, t, s: simulate_drift(X, y, t, covariate_weight=1.0, concept_weight=0.0, random_state=s)),\n",
    "        ('concept_only', lambda X, y, t, s: simulate_drift(X, y, t, covariate_weight=0.0, concept_weight=1.0, random_state=s)),\n",
    "        ('combined_drift', lambda X, y, t, s: simulate_drifted_data(X, y, t, random_state=s))\n",
    "    ]\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for scenario_name, drift_func in drift_scenarios:\n",
    "        scenario_results = []\n",
    "        \n",
    "        for threshold in drift_thresholds:\n",
    "            # Generate drift\n",
    "            X_drifted, y_drifted, drift_info = drift_func(X, y, threshold, random_state)\n",
    "            \n",
    "            # Split drifted data\n",
    "            _, X_test_drifted, _, y_test_drifted = train_test_split(\n",
    "                X_drifted, y_drifted, test_size=0.2, random_state=random_state\n",
    "            )\n",
    "            \n",
    "            # Apply appropriate detection method\n",
    "            if approach_name == 'decision_tree':\n",
    "                drift_detection = detect_harmful_drift_ddla(ddla_info, X_test_drifted, trained_pipeline)\n",
    "            elif approach_name == 'dbscan':\n",
    "                drift_detection = detect_harmful_drift_dbscan(ddla_info, X_test_drifted, trained_pipeline)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Calculate performance\n",
    "            y_pred_drifted = trained_pipeline.predict(X_test_drifted)\n",
    "            actual_accuracy = accuracy_score(y_test_drifted, y_pred_drifted)\n",
    "            accuracy_drop = ddla_info['overall_accuracy'] - actual_accuracy\n",
    "            significant_degradation = accuracy_drop > 0.05\n",
    "            \n",
    "            correct_decision = drift_detection['is_harmful_drift'] == significant_degradation\n",
    "            \n",
    "            result = {\n",
    "                'threshold': threshold,\n",
    "                f'{approach_name}_detected_harmful': drift_detection['is_harmful_drift'],\n",
    "                'actually_needs_retraining': significant_degradation,\n",
    "                f'{approach_name}_correct': correct_decision,\n",
    "                'accuracy_drop_pct': (accuracy_drop / ddla_info['overall_accuracy']) * 100,\n",
    "                'ratio_train': drift_detection.get('ratio_train', 0),\n",
    "                'ratio_serving': drift_detection.get('ratio_serving', 0)\n",
    "            }\n",
    "            \n",
    "            scenario_results.append(result)\n",
    "        \n",
    "        all_results[scenario_name] = scenario_results\n",
    "    \n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be7cbb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting DBSCAN-Based DDLA Experiment with Full MLflow Logging!\n",
      "\n",
      "======================================================================\n",
      "STEP 1: DBSCAN-BASED DDLA IDENTIFICATION WITH LOGGING\n",
      "======================================================================\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      " Baseline DDLA identification logged to MLflow\n",
      "ðŸƒ View run dbscan_baseline_ddla_identification at: http://localhost:5000/#/experiments/7/runs/67e08fad56f34f80a2212e070e13c7de\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      "======================================================================\n",
      "TESTING DBSCAN ON COVARIATE ONLY\n",
      "======================================================================\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 0.00\n",
      "Simulating covariate drift with threshold: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: -0.0014 (-0.2%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_0.0 at: http://localhost:5000/#/experiments/7/runs/6b379df0af8548c888c54a4474be0eed\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 0.25\n",
      "Simulating covariate drift with threshold: 0.25\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0021 (0.3%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_0.25 at: http://localhost:5000/#/experiments/7/runs/86aedc6795144b63aa3d58b4ebb3bc3c\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 0.50\n",
      "Simulating covariate drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0106 (1.3%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_0.5 at: http://localhost:5000/#/experiments/7/runs/ea7809c63128434aa8cc85ff46b10f00\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 0.75\n",
      "Simulating covariate drift with threshold: 0.75\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0128 (1.6%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_0.75 at: http://localhost:5000/#/experiments/7/runs/5d6d60c9149e48b187577cf72d81161a\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - covariate_only - Threshold: 1.00\n",
      "Simulating covariate drift with threshold: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0156 (2.0%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_covariate_only_threshold_1.0 at: http://localhost:5000/#/experiments/7/runs/226cd1db71c547298adb0d9480cc0bb1\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      "======================================================================\n",
      "TESTING DBSCAN ON CONCEPT ONLY\n",
      "======================================================================\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 0.00\n",
      "Simulating concept drift with threshold: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: 0.0000 (0.0%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_0.0 at: http://localhost:5000/#/experiments/7/runs/51a2404d7d7848ceb9b917ef271466d3\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 0.25\n",
      "Simulating concept drift with threshold: 0.25\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.0582 (7.3%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_0.25 at: http://localhost:5000/#/experiments/7/runs/4279216dc5e44faeaa0115ce787add57\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 0.50\n",
      "Simulating concept drift with threshold: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.0830 (10.5%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_0.5 at: http://localhost:5000/#/experiments/7/runs/9f3dd95185ab47b0881909e44f239c8d\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 0.75\n",
      "Simulating concept drift with threshold: 0.75\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.427 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1221 (15.4%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_0.75 at: http://localhost:5000/#/experiments/7/runs/7155ac140ef34e5c9b07fed0a923ca8e\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - concept_only - Threshold: 1.00\n",
      "Simulating concept drift with threshold: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.475 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1859 (23.4%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_concept_only_threshold_1.0 at: http://localhost:5000/#/experiments/7/runs/4b581138784a4c6e9fc22d6e72edb23a\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      "======================================================================\n",
      "TESTING DBSCAN ON COMBINED DRIFT\n",
      "======================================================================\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 0.00\n",
      "Simulating combined drift with threshold: 0.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: NO\n",
      "  DBSCAN correct: NO\n",
      "  Accuracy drop: -0.0014 (-0.2%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_0.0 at: http://localhost:5000/#/experiments/7/runs/1af2036976604dfca0c9fd900ef7398d\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 0.25\n",
      "Simulating combined drift with threshold: 0.25\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.0546 (6.9%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_0.25 at: http://localhost:5000/#/experiments/7/runs/51a3d38b15194eeaa99f1eab075fb961\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 0.50\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1015 (12.8%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_0.5 at: http://localhost:5000/#/experiments/7/runs/0227645dca9f4f7384535ae6d6a820d8\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 0.75\n",
      "Simulating combined drift with threshold: 0.75\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.430 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1490 (18.8%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_0.75 at: http://localhost:5000/#/experiments/7/runs/82060e6034f7448481265787ce5c66f2\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      " DBSCAN - combined_drift - Threshold: 1.00\n",
      "Simulating combined drift with threshold: 1.00\n",
      "Covariate weight: 1.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.478 (original: 0.265)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  DBSCAN says: HARMFUL\n",
      "  Actually needs retraining: YES\n",
      "  DBSCAN correct: YES\n",
      "  Accuracy drop: 0.1874 (23.6%)\n",
      " Logged to MLflow\n",
      "ðŸƒ View run dbscan_combined_drift_threshold_1.0 at: http://localhost:5000/#/experiments/7/runs/ac3793cc33354977abaebc14172e31af\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/7\n",
      "\n",
      "================================================================================\n",
      "DBSCAN V. KMEANS\n",
      "================================================================================\n",
      "\n",
      "Covariate Only:\n",
      "  K-Means Accuracy:  100.0%\n",
      "  DBSCAN Accuracy:   0.0%\n",
      "\n",
      "Concept Only:\n",
      "  K-Means Accuracy:  20.0%\n",
      "  DBSCAN Accuracy:   80.0%\n",
      "\n",
      "Combined Drift:\n",
      "  K-Means Accuracy:  20.0%\n",
      "  DBSCAN Accuracy:   80.0%\n",
      "\n",
      " All visualizations and metrics logged to MLflow experiment:\n",
      "   Experiment: telco-dbscan-vs-kmeans-ultimate-comparison\n",
      "   Artifacts: 3 comprehensive visualization plots\n",
      "   Metrics: Full performance comparison across all drift types\n"
     ]
    }
   ],
   "source": [
    "# Run the complete DBSCAN experiment\n",
    "dbscan_full_results, dbscan_info = run_dbscan_ddla_experiment_with_mlflow(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    trained_pipeline=pipeline,\n",
    "    drift_thresholds=[0.0, 0.25, 0.5, 0.75, 1.0],\n",
    "    experiment_name=\"telco-ddla-comparison\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DBSCAN V. KMEANS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for scenario in ['covariate_only', 'concept_only', 'combined_drift']:\n",
    "    if scenario in dbscan_full_results:\n",
    "        results = dbscan_full_results[scenario]\n",
    "        correct_dbscan = sum(r['dbscan_correct'] for r in results)\n",
    "        total = len(results)\n",
    "        dbscan_accuracy = (correct_dbscan / total) * 100\n",
    "        \n",
    "        # Your K-Means results for comparison\n",
    "        kmeans_accuracies = {'covariate_only': 100.0, 'concept_only': 20.0, 'combined_drift': 20.0}\n",
    "        kmeans_accuracy = kmeans_accuracies.get(scenario, 0)\n",
    "        \n",
    "        improvement = dbscan_accuracy - kmeans_accuracy\n",
    "        \n",
    "        print(f\"\\n{scenario.replace('_', ' ').title()}:\")\n",
    "        print(f\"  K-Means Accuracy:  {kmeans_accuracy:.1f}%\")\n",
    "        print(f\"  DBSCAN Accuracy:   {dbscan_accuracy:.1f}%\")\n",
    "        #print(f\"  Improvement:       {improvement:+.1f}% {'ðŸš€' if improvement > 0 else 'ðŸ˜ž' if improvement < 0 else 'ðŸ¤·'}\")\n",
    "\n",
    "print(f\"\\n All visualizations and metrics logged to MLflow experiment:\")\n",
    "print(f\"   Experiment: telco-dbscan-vs-kmeans-ultimate-comparison\")\n",
    "print(f\"   Artifacts: 3 comprehensive visualization plots\")\n",
    "print(f\"   Metrics: Full performance comparison across all drift types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ae356",
   "metadata": {},
   "source": [
    "We now that the choice of algorithms to detect DDLAs to \"classify\" benign and harmful drifts within models are what decide how well they accomplish they task. How do we proceed from here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff6a4e",
   "metadata": {},
   "source": [
    "## A combination of both DTs and DBScan to identify DDLAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12f0a669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Simple Adaptive DDLA System\n",
      "\n",
      "Covariate Only:\n",
      "Simulating combined drift with threshold: 0.00\n",
      "Covariate weight: 1.00, Concept weight: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  Threshold 0.00: mixed -> dbscan -> HARMFUL (âŒ)\n",
      "Simulating combined drift with threshold: 0.25\n",
      "Covariate weight: 1.00, Concept weight: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.5039\n",
      "  Serving DDLA fraction: 0.5720\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 13.52% below threshold 50.0%\n",
      "  Threshold 0.25: covariate -> decision_tree -> BENIGN (âœ…)\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 1.00, Concept weight: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.5039\n",
      "  Serving DDLA fraction: 0.5720\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 13.52% below threshold 50.0%\n",
      "  Threshold 0.50: covariate -> decision_tree -> BENIGN (âœ…)\n",
      "Simulating combined drift with threshold: 0.75\n",
      "Covariate weight: 1.00, Concept weight: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.5039\n",
      "  Serving DDLA fraction: 0.5791\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 14.93% below threshold 50.0%\n",
      "  Threshold 0.75: covariate -> decision_tree -> BENIGN (âœ…)\n",
      "Simulating combined drift with threshold: 1.00\n",
      "Covariate weight: 1.00, Concept weight: 0.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.5039\n",
      "  Serving DDLA fraction: 0.5862\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 16.34% below threshold 50.0%\n",
      "  Threshold 1.00: covariate -> decision_tree -> BENIGN (âœ…)\n",
      "\n",
      "Concept Only:\n",
      "Simulating combined drift with threshold: 0.00\n",
      "Covariate weight: 0.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  Threshold 0.00: mixed -> dbscan -> HARMFUL (âŒ)\n",
      "Simulating combined drift with threshold: 0.25\n",
      "Covariate weight: 0.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  Threshold 0.25: mixed -> dbscan -> HARMFUL (âœ…)\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 0.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  Threshold 0.50: mixed -> dbscan -> HARMFUL (âœ…)\n",
      "Simulating combined drift with threshold: 0.75\n",
      "Covariate weight: 0.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.427 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  Threshold 0.75: mixed -> dbscan -> HARMFUL (âœ…)\n",
      "Simulating combined drift with threshold: 1.00\n",
      "Covariate weight: 0.00, Concept weight: 1.00\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 0 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.475 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  Threshold 1.00: mixed -> dbscan -> HARMFUL (âœ…)\n",
      "\n",
      "Mixed Drift:\n",
      "Simulating combined drift with threshold: 0.00\n",
      "Covariate weight: 0.50, Concept weight: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 13 covariate shifts\n",
      "Applied 0 concept shifts\n",
      "Final churn rate: 0.265 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      " Detecting harmful drift using DBSCAN Error Clustering...\n",
      "  Baseline DDLA ratio: 0.0355\n",
      "  Serving DDLA ratio: 1.0000\n",
      "  Baseline noise ratio: 0.0873\n",
      "  Serving noise ratio: 0.0000\n",
      " DBSCAN Drift assessment: HARMFUL\n",
      "  Reason: DDLA ratio increased significantly (1.000 vs 0.035)\n",
      "  Threshold 0.00: mixed -> dbscan -> HARMFUL (âŒ)\n",
      "Simulating combined drift with threshold: 0.25\n",
      "Covariate weight: 0.50, Concept weight: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.294 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.5039\n",
      "  Serving DDLA fraction: 0.5408\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 7.32% below threshold 50.0%\n",
      "  Threshold 0.25: covariate -> decision_tree -> BENIGN (âœ…)\n",
      "Simulating combined drift with threshold: 0.50\n",
      "Covariate weight: 0.50, Concept weight: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.322 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.5039\n",
      "  Serving DDLA fraction: 0.5720\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 13.52% below threshold 50.0%\n",
      "  Threshold 0.50: covariate -> decision_tree -> BENIGN (âŒ)\n",
      "Simulating combined drift with threshold: 0.75\n",
      "Covariate weight: 0.50, Concept weight: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.350 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.5039\n",
      "  Serving DDLA fraction: 0.5777\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 14.65% below threshold 50.0%\n",
      "  Threshold 0.75: covariate -> decision_tree -> BENIGN (âŒ)\n",
      "Simulating combined drift with threshold: 1.00\n",
      "Covariate weight: 0.50, Concept weight: 0.50\n",
      "Applying to 8 numeric and 18 categorical features\n",
      "Applied 15 covariate shifts\n",
      "Applied 5 concept shifts\n",
      "Final churn rate: 0.376 (original: 0.265)\n",
      "Identifying DDLAs with tree based approach\n",
      "Overall model accuracy: 0.7935\n",
      "  Overall incorrect prediction rate: 0.2065\n",
      "  Best decision tree params: {'max_depth': 6, 'min_samples_leaf': 14}\n",
      "  Decision tree F1 score: 0.4735\n",
      " Found 13 DDLAs out of 32 total leaf nodes\n",
      " DDLA coverage: 710/1409 samples (0.504)\n",
      " REVOLUTIONARY: Identifying DDLAs using DBSCAN clustering!\n",
      "Testing your brilliant algorithmic insight! \n",
      "  Overall model accuracy: 0.7935\n",
      "  Overall error rate: 0.2065\n",
      " Focusing on 291 error samples out of 1409 total\n",
      "  ðŸ“Š Error samples have 57 features after preprocessing\n",
      " Finding optimal DBSCAN parameters for 291 error samples...\n",
      " K-distance analysis suggests eps = 1.415\n",
      " Grid searching DBSCAN parameters...\n",
      "    eps=2.829, min_samples=8: 3 clusters, 123 noise, score=0.000\n",
      "    eps=2.829, min_samples=9: 3 clusters, 133 noise, score=0.000\n",
      "    eps=2.829, min_samples=10: 3 clusters, 137 noise, score=0.000\n",
      "    eps=2.829, min_samples=11: 3 clusters, 143 noise, score=0.000\n",
      "    eps=2.829, min_samples=12: 3 clusters, 144 noise, score=0.000\n",
      " Optimal DBSCAN: eps=2.829, min_samples=8, score=0.000\n",
      " DBSCAN found 3 distinct error patterns + 123 noise points\n",
      "     DBSCAN DDLA found: Cluster 0\n",
      "       Accuracy: 0.000 (vs overall 0.793)\n",
      "       Size: 1 samples (0.001 of total)\n",
      "       Core error pattern with 1/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 1\n",
      "       Accuracy: 0.515 (vs overall 0.793)\n",
      "       Size: 33 samples (0.023 of total)\n",
      "       Core error pattern with 16/291 error samples\n",
      "     DBSCAN DDLA found: Cluster 2\n",
      "       Accuracy: 0.375 (vs overall 0.793)\n",
      "       Size: 16 samples (0.011 of total)\n",
      "       Core error pattern with 10/291 error samples\n",
      " Noise points analysis: 1359 samples, accuracy: 0.806\n",
      " DBSCAN found 3 DDLAs covering 50/1409 samples (0.035 ratio)\n",
      "Detecting harmful drift\n",
      "  Baseline DDLA fraction: 0.5039\n",
      "  Serving DDLA fraction: 0.5720\n",
      " Drift assessment: BENIGN\n",
      "  Reason: DDLA ratio increase 13.52% below threshold 50.0%\n",
      "  Threshold 1.00: covariate -> decision_tree -> BENIGN (âŒ)\n",
      "\n",
      "============================================================\n",
      "SIMPLE ADAPTIVE SYSTEM RESULTS\n",
      "============================================================\n",
      "\n",
      "Covariate Only:\n",
      "  Accuracy: 4/5 (80.0%)\n",
      "  Methods: 4 Decision Tree, 1 DBSCAN\n",
      "\n",
      "Concept Only:\n",
      "  Accuracy: 4/5 (80.0%)\n",
      "  Methods: 0 Decision Tree, 5 DBSCAN\n",
      "\n",
      "Mixed Drift:\n",
      "  Accuracy: 1/5 (20.0%)\n",
      "  Methods: 4 Decision Tree, 1 DBSCAN\n",
      "\n",
      "Overall Simple Adaptive Performance: 9/15 (60.0%)\n",
      "\n",
      "Comparison to Individual Methods:\n",
      "Decision Tree (Covariate): 100% accuracy\n",
      "DBSCAN (Concept): 80% accuracy\n",
      "DBSCAN (Mixed): 80% accuracy\n",
      "Simple Adaptive System: 60.0% accuracy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def simple_drift_type_detection(X_baseline, X_serving, trained_pipeline):\n",
    "    \"\"\"\n",
    "    Simple drift type detection using basic indicators.\n",
    "    \"\"\"\n",
    "    # Count significant feature shifts\n",
    "    significant_shifts = 0\n",
    "    total_features = 0\n",
    "    \n",
    "    for col in X_baseline.select_dtypes(include=[np.number]).columns:\n",
    "        if col in X_serving.columns:\n",
    "            _, p_value = ks_2samp(X_baseline[col].dropna(), X_serving[col].dropna())\n",
    "            total_features += 1\n",
    "            if p_value < 0.05:\n",
    "                significant_shifts += 1\n",
    "    \n",
    "    feature_drift_ratio = significant_shifts / max(1, total_features)\n",
    "    \n",
    "    # Check prediction pattern changes\n",
    "    baseline_pred = trained_pipeline.predict(X_baseline)\n",
    "    serving_pred = trained_pipeline.predict(X_serving)\n",
    "    \n",
    "    baseline_balance = baseline_pred.mean()\n",
    "    serving_balance = serving_pred.mean()\n",
    "    prediction_shift = abs(serving_balance - baseline_balance)\n",
    "    \n",
    "    # Simple decision logic\n",
    "    if feature_drift_ratio > 0.4 and prediction_shift < 0.1:\n",
    "        return 'covariate'\n",
    "    elif feature_drift_ratio < 0.2 and prediction_shift > 0.15:\n",
    "        return 'concept'\n",
    "    else:\n",
    "        return 'mixed'\n",
    "\n",
    "\n",
    "def simple_adaptive_ddla(X_baseline, y_baseline, X_serving, trained_pipeline):\n",
    "    \"\"\"\n",
    "    Simple adaptive DDLA system - chooses best method based on drift type.\n",
    "    \"\"\"\n",
    "    # Initialize both DDLA approaches\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_baseline, y_baseline, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Get DDLAs for both methods\n",
    "    dt_ddla_info = identify_ddlas_decision_tree(\n",
    "        trained_pipeline, X_test, y_test,\n",
    "        max_depth_range=(3, 15),\n",
    "        min_samples_leaf_range=(0.01, 0.15),\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    dbscan_ddla_info = identify_ddlas_dbscan(trained_pipeline, X_test, y_test, random_state=42)\n",
    "    \n",
    "    # Detect drift type\n",
    "    drift_type = simple_drift_type_detection(X_baseline, X_serving, trained_pipeline)\n",
    "    \n",
    "    # Select method based on our empirical findings\n",
    "    if drift_type == 'covariate':\n",
    "        method = 'decision_tree'\n",
    "        result = detect_harmful_drift_ddla(dt_ddla_info, X_serving, trained_pipeline)\n",
    "    else:  # concept or mixed - use DBSCAN\n",
    "        method = 'dbscan'  \n",
    "        result = detect_harmful_drift_dbscan(dbscan_ddla_info, X_serving, trained_pipeline)\n",
    "    \n",
    "    result['method_selected'] = method\n",
    "    result['drift_type_detected'] = drift_type\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def test_simple_adaptive_system(X, y, trained_pipeline, drift_thresholds, random_state=42):\n",
    "    \"\"\"\n",
    "    Test the simple adaptive system.\n",
    "    \"\"\"\n",
    "    print(\"Testing Simple Adaptive DDLA System\")\n",
    "    \n",
    "    # Test scenarios\n",
    "    scenarios = [\n",
    "        ('covariate_only', lambda X, y, t, s: simulate_drift(X, y, t, covariate_weight=1.0, concept_weight=0.0, random_state=s)),\n",
    "        ('concept_only', lambda X, y, t, s: simulate_drift(X, y, t, covariate_weight=0.0, concept_weight=1.0, random_state=s)),\n",
    "        ('mixed_drift', lambda X, y, t, s: simulate_drift(X, y, t, covariate_weight=0.5, concept_weight=0.5, random_state=s))\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for scenario_name, drift_func in scenarios:\n",
    "        print(f\"\\n{scenario_name.replace('_', ' ').title()}:\")\n",
    "        scenario_results = []\n",
    "        \n",
    "        for threshold in drift_thresholds:\n",
    "            # Generate drift\n",
    "            X_drifted, y_drifted, _ = drift_func(X, y, threshold, random_state)\n",
    "            _, X_serving, _, y_serving = train_test_split(X_drifted, y_drifted, test_size=0.2, random_state=random_state)\n",
    "            \n",
    "            # Run adaptive system\n",
    "            adaptive_result = simple_adaptive_ddla(X, y, X_serving, trained_pipeline)\n",
    "            \n",
    "            # Calculate ground truth\n",
    "            actual_accuracy = accuracy_score(y_serving, trained_pipeline.predict(X_serving))\n",
    "            _, X_baseline_test, _, y_baseline_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "            baseline_accuracy = accuracy_score(y_baseline_test, trained_pipeline.predict(X_baseline_test))\n",
    "            \n",
    "            needs_retraining = (baseline_accuracy - actual_accuracy) > 0.05\n",
    "            adaptive_correct = adaptive_result['is_harmful_drift'] == needs_retraining\n",
    "            \n",
    "            result = {\n",
    "                'threshold': threshold,\n",
    "                'drift_type_detected': adaptive_result['drift_type_detected'],\n",
    "                'method_selected': adaptive_result['method_selected'],\n",
    "                'adaptive_decision': 'HARMFUL' if adaptive_result['is_harmful_drift'] else 'BENIGN',\n",
    "                'ground_truth': 'YES' if needs_retraining else 'NO',\n",
    "                'correct': adaptive_correct,\n",
    "                'accuracy_drop_pct': ((baseline_accuracy - actual_accuracy) / baseline_accuracy) * 100\n",
    "            }\n",
    "            \n",
    "            scenario_results.append(result)\n",
    "            \n",
    "            print(f\"  Threshold {threshold:.2f}: {adaptive_result['drift_type_detected']} -> {adaptive_result['method_selected']} -> {'HARMFUL' if adaptive_result['is_harmful_drift'] else 'BENIGN'} ({'âœ…' if adaptive_correct else 'âŒ'})\")\n",
    "        \n",
    "        results[scenario_name] = scenario_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run simple test\n",
    "simple_results = test_simple_adaptive_system(\n",
    "    X=X, y=y, trained_pipeline=pipeline,\n",
    "    drift_thresholds=[0.0, 0.25, 0.5, 0.75, 1.0],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Calculate and print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIMPLE ADAPTIVE SYSTEM RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for scenario_name, scenario_results in simple_results.items():\n",
    "    correct_count = sum(r['correct'] for r in scenario_results)\n",
    "    total_count = len(scenario_results)\n",
    "    accuracy_pct = (correct_count / total_count) * 100\n",
    "    \n",
    "    print(f\"\\n{scenario_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Accuracy: {correct_count}/{total_count} ({accuracy_pct:.1f}%)\")\n",
    "    \n",
    "    # Show method selection pattern\n",
    "    methods_used = [r['method_selected'] for r in scenario_results]\n",
    "    dt_count = methods_used.count('decision_tree')\n",
    "    dbscan_count = len(methods_used) - dt_count\n",
    "    print(f\"  Methods: {dt_count} Decision Tree, {dbscan_count} DBSCAN\")\n",
    "\n",
    "# Overall performance\n",
    "all_correct = sum(sum(r['correct'] for r in results) for results in simple_results.values())\n",
    "all_total = sum(len(results) for results in simple_results.values())\n",
    "overall_accuracy = (all_correct / all_total) * 100\n",
    "\n",
    "print(f\"\\nOverall Simple Adaptive Performance: {all_correct}/{all_total} ({overall_accuracy:.1f}%)\")\n",
    "\n",
    "# Compare to individual methods\n",
    "print(f\"\\nComparison to Individual Methods:\")\n",
    "print(f\"Decision Tree (Covariate): 100% accuracy\")\n",
    "print(f\"DBSCAN (Concept): 80% accuracy\") \n",
    "print(f\"DBSCAN (Mixed): 80% accuracy\")\n",
    "print(f\"Simple Adaptive System: {overall_accuracy:.1f}% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c52d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RDS-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
