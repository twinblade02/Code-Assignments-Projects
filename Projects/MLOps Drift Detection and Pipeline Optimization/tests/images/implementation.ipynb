{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca89506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317954c",
   "metadata": {},
   "source": [
    "# Establishing baseline experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b7823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. VISUALIZATION & PREPROCESSING HELPERS ---\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def get_preprocessor(X):\n",
    "    \"\"\"\n",
    "    Creates a ColumnTransformer preprocessor based on column types in X.\n",
    "    \"\"\"\n",
    "    # Identify categorical and numerical features\n",
    "\n",
    "    numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "    categorical_features = [\n",
    "            'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "            'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "            'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
    "            'PaperlessBilling', 'PaymentMethod', 'SeniorCitizen'\n",
    "        ]\n",
    "\n",
    "    X.drop(columns=['customerID'], inplace=True)\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    X['TotalCharges'] = pd.to_numeric(X['TotalCharges'], errors='coerce')\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X[numerical_features] = imputer.fit_transform(X[numerical_features])\n",
    "\n",
    "\n",
    "    #categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    #numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # Create transformers\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Create the column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='drop' # drop everything\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, save_path):\n",
    "    \"\"\"\n",
    "    Generates and saves a confusion matrix plot.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['No Churn', 'Churn'], \n",
    "                yticklabels=['No Churn', 'Churn'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved visualization to {save_path}\")\n",
    "\n",
    "def plot_drift_distribution(df_original, df_drifted, feature_name, save_path):\n",
    "    \"\"\"\n",
    "    Generates and saves a KDE plot comparing a feature's distribution\n",
    "    before and after drift.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(df_original[feature_name], label='Original Test Data', color='blue', shade=True)\n",
    "    sns.kdeplot(df_drifted[feature_name], label='Drifted Test Data', color='red', shade=True)\n",
    "    plt.title(f'Distribution Shift for Feature: {feature_name}')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved visualization to {save_path}\")\n",
    "\n",
    "# --- 2. BASELINE TRAINING FUNCTION ---\n",
    "\n",
    "def run_baseline_training(preprocessed_data_path):\n",
    "    \"\"\"\n",
    "    Trains the initial baseline model.\n",
    "    - Encodes y to 0/1.\n",
    "    - Trains and evaluates the model on the test set.\n",
    "    - Logs model, metrics, visualizations, and data artifacts to MLflow.\n",
    "    \"\"\"\n",
    "    print(\"--- Running Part 1: Baseline Training ---\")\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"telco-baseline\")\n",
    "    \n",
    "    data = pd.read_csv(preprocessed_data_path)\n",
    "    X = data.drop('Churn', axis=1)\n",
    "    \n",
    "    # --- Clean Data Prep ---\n",
    "    # Encode y to numeric (0/1) from the start.\n",
    "    # This is cleaner and avoids all downstream errors.\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(data['Churn'])\n",
    "    print(f\"Target 'Churn' encoded. Positive class ('{le.classes_[1]}') is 1.\")\n",
    "\n",
    "    # Get the preprocessor\n",
    "    preprocessor = get_preprocessor(X)\n",
    "    \n",
    "    # Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Define the model\n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "    # Subbing this with LR for testing\n",
    "\n",
    "    #from sklearn.linear_model import LogisticRegression\n",
    "    # lr = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, random_state=42)\n",
    "\n",
    "    # Create the full pipeline\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', rf)\n",
    "    ])\n",
    "\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=\"Baseline-Model-Setup\") as run:\n",
    "        print(f\"MLflow Run ID: {run.info.run_id}\")\n",
    "        \n",
    "        # Train the model\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        from mlflow.models.signature import infer_signature\n",
    "        signature = infer_signature(X_train, y_train)\n",
    "\n",
    "        # Log parameters\n",
    "        mlflow.log_params(rf.get_params())\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model_pipeline.predict(X_test)\n",
    "        y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        #print(\"--Building analytic dataset for DDLA--\")\n",
    "\n",
    "        #error_mask = (y_pred != y_test)\n",
    "        #correct_mask = (y_pred == y_test)\n",
    "\n",
    "        #X_test_analytic = X_test.copy()\n",
    "\n",
    "        #X_test_analytic['ddla_target'] = 0\n",
    "        #X_test_analytic.loc[error_mask, 'ddla_target'] = 1\n",
    "\n",
    "        #analytic_path = \"analytic_dataset.csv\"\n",
    "        #X_test_analytic.to_csv(analytic_path, index=False)\n",
    "        #mlflow.log_artifact(analytic_path)\n",
    "\n",
    "        #if os.path.exists(analytic_path):\n",
    "        #    os.remove(analytic_path)\n",
    "        \n",
    "        # Log metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        print(f\"Baseline Model Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Baseline Model ROC AUC: {roc_auc:.4f}\")\n",
    "        mlflow.log_metric(\"baseline_accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"baseline_roc_auc\", roc_auc)\n",
    "\n",
    "        # Log the model pipeline\n",
    "        #mlflow.sklearn.log_model(model_pipeline, \"model_pipeline\")\n",
    "        mlflow.sklearn.log_model(\n",
    "            model_pipeline, \n",
    "            'model_pipeline',\n",
    "            signature=signature, \n",
    "            registered_model_name='telco-baseline'\n",
    "        )\n",
    "\n",
    "        # --- Save and log visualizations ---\n",
    "        cm_path = \"confusion_matrix_baseline.png\"\n",
    "        plot_confusion_matrix(y_test, y_pred, \"Baseline Model Confusion Matrix\", cm_path)\n",
    "        mlflow.log_artifact(cm_path)\n",
    "\n",
    "        # --- Save and log the data artifacts (with y as 0/1) ---\n",
    "        X_train.to_csv(\"X_train.csv\", index=False)\n",
    "        pd.Series(y_train, name=\"Churn\").to_csv(\"y_train.csv\", index=False, header=True)\n",
    "        X_test.to_csv(\"X_test.csv\", index=False)\n",
    "        pd.Series(y_test, name=\"Churn\").to_csv(\"y_test.csv\", index=False, header=True)\n",
    "        \n",
    "        mlflow.log_artifact(\"X_train.csv\")\n",
    "        mlflow.log_artifact(\"y_train.csv\")\n",
    "        mlflow.log_artifact(\"X_test.csv\")\n",
    "        mlflow.log_artifact(\"y_test.csv\")\n",
    "        \n",
    "        print(\"Logged model pipeline, parameters, metrics, visualizations, and data artifacts.\")\n",
    "        \n",
    "    # Clean up local files\n",
    "    for f in [\"X_train.csv\", \"y_train.csv\", \"X_test.csv\", \"y_test.csv\", cm_path]:\n",
    "        if os.path.exists(f):\n",
    "            os.remove(f)\n",
    "            \n",
    "    return run.info.run_id\n",
    "\n",
    "# --- 3. DRIFT SIMULATION FUNCTIONS ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def simulate_drift(df, target_col=\"Churn\", drift_type=\"covariate\", drift_fraction=0.3, intensity=0.3,\n",
    "    thresholds=None, random_state=None):\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    df_drifted = df.copy()\n",
    "\n",
    "    # Select subset to drift\n",
    "    drift_indices = np.random.choice(\n",
    "        df_drifted.index,\n",
    "        size=int(len(df_drifted) * drift_fraction),\n",
    "        replace=False\n",
    "    )\n",
    "\n",
    "    # Set default thresholds if not provided\n",
    "    if thresholds is None:\n",
    "        thresholds = {\n",
    "            \"tenure\": 12,\n",
    "            \"MonthlyCharges\": df_drifted[\"MonthlyCharges\"].median(),\n",
    "            \"TotalCharges\": df_drifted[\"TotalCharges\"].median(),\n",
    "            \"SeniorCitizen\": 0.5,\n",
    "        }\n",
    "\n",
    "    # === Covariate Drift ===\n",
    "    if drift_type == \"covariate\":\n",
    "        # Demographic drift\n",
    "        if \"tenure\" in df_drifted.columns:\n",
    "            mask = df_drifted.index.isin(drift_indices)\n",
    "            df_drifted.loc[mask, \"tenure\"] *= np.random.uniform(0.5, 1 - intensity)\n",
    "\n",
    "        if \"SeniorCitizen\" in df_drifted.columns:\n",
    "            mask = df_drifted.index.isin(drift_indices)\n",
    "            df_drifted.loc[mask, \"SeniorCitizen\"] = np.random.choice(\n",
    "                [0, 1],\n",
    "                size=mask.sum(),\n",
    "                p=[1 - thresholds[\"SeniorCitizen\"], thresholds[\"SeniorCitizen\"]]\n",
    "            )\n",
    "\n",
    "        # Plan drift (pricing + contracts)\n",
    "        if \"Contract\" in df_drifted.columns:\n",
    "            mask = df_drifted.index.isin(drift_indices)\n",
    "            df_drifted.loc[mask, \"Contract\"] = np.random.choice(\n",
    "                [\"Month-to-month\", \"One year\", \"Two year\"],\n",
    "                size=mask.sum(),\n",
    "                p=[0.7, 0.2, 0.1]\n",
    "            )\n",
    "\n",
    "        if \"MonthlyCharges\" in df_drifted.columns:\n",
    "            mask = df_drifted.index.isin(drift_indices)\n",
    "            df_drifted.loc[mask, \"MonthlyCharges\"] *= np.random.uniform(0.8, 1 - intensity / 2)\n",
    "            if \"TotalCharges\" in df_drifted.columns:\n",
    "                df_drifted.loc[mask, \"TotalCharges\"] = (\n",
    "                    df_drifted.loc[mask, \"MonthlyCharges\"] * df_drifted.loc[mask, \"tenure\"]\n",
    "                )\n",
    "\n",
    "        # Payment behavior drift\n",
    "        if \"PaymentMethod\" in df_drifted.columns:\n",
    "            mask = df_drifted.index.isin(drift_indices)\n",
    "            df_drifted.loc[mask, \"PaymentMethod\"] = np.random.choice(\n",
    "                [\n",
    "                    \"Electronic check\",\n",
    "                    \"Mailed check\",\n",
    "                    \"Bank transfer (automatic)\",\n",
    "                    \"Credit card (automatic)\",\n",
    "                ],\n",
    "                size=mask.sum(),\n",
    "                p=[0.6, 0.1, 0.15, 0.15],\n",
    "            )\n",
    "\n",
    "        if \"PaperlessBilling\" in df_drifted.columns:\n",
    "            df_drifted.loc[drift_indices, \"PaperlessBilling\"] = \"Yes\"\n",
    "\n",
    "    # === Concept Drift ===\n",
    "    elif drift_type == \"concept\":\n",
    "        flip_mask = np.zeros(len(df_drifted), dtype=bool)\n",
    "\n",
    "        # Economic drift ‚Äî churn increases for high cost and long tenure\n",
    "        if \"MonthlyCharges\" in df_drifted.columns and \"tenure\" in df_drifted.columns:\n",
    "            flip_mask |= (\n",
    "                (df_drifted[\"MonthlyCharges\"] > thresholds[\"MonthlyCharges\"]) &\n",
    "                (df_drifted[\"tenure\"] > thresholds[\"tenure\"])\n",
    "            )\n",
    "\n",
    "        # Service quality drift ‚Äî churn increases for Fiber + no support\n",
    "        if {\"InternetService\", \"TechSupport\"}.issubset(df_drifted.columns):\n",
    "            flip_mask |= (\n",
    "                (df_drifted[\"InternetService\"] == \"Fiber optic\") &\n",
    "                (df_drifted[\"TechSupport\"] == \"No\")\n",
    "            )\n",
    "\n",
    "        # Retention drift ‚Äî churn decreases for long tenure\n",
    "        if \"tenure\" in df_drifted.columns:\n",
    "            flip_mask |= (df_drifted[\"tenure\"] > 24) & (df_drifted[target_col] == \"Yes\")\n",
    "\n",
    "        # Apply drift only to fraction of data\n",
    "        indices_to_flip = df_drifted[flip_mask].sample(\n",
    "            frac=intensity, random_state=random_state\n",
    "        ).index if flip_mask.sum() > 0 else []\n",
    "\n",
    "        if df_drifted[target_col].dtype == \"object\":\n",
    "            df_drifted.loc[indices_to_flip, target_col] = df_drifted.loc[\n",
    "                indices_to_flip, target_col\n",
    "            ].apply(lambda x: \"No\" if x == \"Yes\" else \"Yes\")\n",
    "        else:\n",
    "            df_drifted.loc[indices_to_flip, target_col] = 1 - df_drifted.loc[\n",
    "                indices_to_flip, target_col\n",
    "            ]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"drift_type must be either 'covariate' or 'concept'\")\n",
    "\n",
    "    return df_drifted\n",
    "\n",
    "\n",
    "# --- 4. DRIFT EVALUATION FUNCTION ---\n",
    "\n",
    "def run_drift_evaluation(setup_run_id, drift_type):\n",
    "    \"\"\"\n",
    "    Simulates a drift scenario and evaluates the baseline model's performance on it.\n",
    "    - Loads the baseline model and test data from the 'setup_run_id'.\n",
    "    - Applies the specified 'drift_type' to the test data.\n",
    "    - Logs the model's new, drifted performance and comparison visualizations.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Part 1: Evaluation for: {drift_type} drift ---\")\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    local_download_path = \".\"\n",
    "    cleanup_files = []\n",
    "\n",
    "    try:\n",
    "        # --- 1. SETUP: Load Baseline Assets ---\n",
    "        print(f\"Loading assets from setup run: {setup_run_id}\")\n",
    "        \n",
    "        model_pipeline_uri = f\"runs:/{setup_run_id}/model_pipeline\"\n",
    "        baseline_model = mlflow.sklearn.load_model(model_pipeline_uri)\n",
    "        \n",
    "        # Download artifacts to the current directory\n",
    "        for f in [\"X_train.csv\", \"X_test.csv\", \"y_test.csv\"]:\n",
    "            client.download_artifacts(setup_run_id, f, local_download_path)\n",
    "            cleanup_files.append(f)\n",
    "        \n",
    "        # Load the downloaded files\n",
    "        X_train_original = pd.read_csv(\"X_train.csv\") # For viz\n",
    "        X_test_original = pd.read_csv(\"X_test.csv\")\n",
    "        y_test_original = pd.read_csv(\"y_test.csv\").squeeze() # Squeeze to make it a Series\n",
    "        \n",
    "        # Reconstruct the original test set for drift simulation (all numeric)\n",
    "        test_data_original = X_test_original.copy()\n",
    "        test_data_original['Churn'] = y_test_original\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading artifacts: {e}\")\n",
    "        return\n",
    "    \n",
    "    # --- 2. SIMULATE DRIFT ---\n",
    "    \n",
    "    if drift_type == 'covariate':\n",
    "        drifted_test_data = simulate_drift(test_data_original, drift_type='covariate', drift_fraction=0.4, intensity=0.5, random_state=42)\n",
    "    elif drift_type == 'concept':\n",
    "        drifted_test_data = simulate_drift(test_data_original, drift_type='concept', drift_fraction=0.4, intensity=0.5, thresholds= {\"tenure\": 12, \"MonthlyCharges\": 75}, \n",
    "                                           random_state=42)\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    X_test_drifted = drifted_test_data.drop('Churn', axis=1)\n",
    "    y_test_drifted = drifted_test_data['Churn'] # This is the new \"ground truth\"\n",
    "\n",
    "    # --- 3. MONITOR: Evaluate Baseline Model on New Data ---\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"Sim-Evaluate-{drift_type}-drift\", nested=True) as run:\n",
    "        print(f\"Logging simulation run: {run.info.run_id}\")\n",
    "        mlflow.log_param(\"drift_type\", drift_type)\n",
    "        mlflow.log_param(\"parent_setup_run_id\", setup_run_id)\n",
    "        \n",
    "        # Get \"ground truth\" performance of the old model on the new data\n",
    "        y_pred_drifted = baseline_model.predict(X_test_drifted)\n",
    "        y_pred_proba_drifted = baseline_model.predict_proba(X_test_drifted)[:, 1]\n",
    "        \n",
    "        drifted_accuracy = accuracy_score(y_test_drifted, y_pred_drifted)\n",
    "        drifted_roc_auc = roc_auc_score(y_test_drifted, y_pred_proba_drifted)\n",
    "    \n",
    "        print(f\"Baseline model accuracy on {drift_type} data: {drifted_accuracy:.4f}\")\n",
    "        mlflow.log_metric(\"drifted_accuracy\", drifted_accuracy)\n",
    "        mlflow.log_metric(\"drifted_roc_auc\", drifted_roc_auc)\n",
    "\n",
    "        # --- 4. LOG VISUALIZATIONS ---\n",
    "        \n",
    "        # Log new confusion matrix\n",
    "        cm_drifted_path = f\"confusion_matrix_{drift_type}.png\"\n",
    "        plot_confusion_matrix(y_test_drifted, y_pred_drifted, \n",
    "                              f\"Model Performance on {drift_type} Drift\", cm_drifted_path)\n",
    "        mlflow.log_artifact(cm_drifted_path)\n",
    "        cleanup_files.append(cm_drifted_path)\n",
    "        \n",
    "        # Log distribution shift plots for key features\n",
    "        if drift_type in ['covariate', 'combined']:\n",
    "            for feature in ['tenure', 'MonthlyCharges']:\n",
    "                dist_path = f\"drift_distribution_{feature}_{drift_type}.png\"\n",
    "                plot_drift_distribution(X_test_original, X_test_drifted, feature, dist_path)\n",
    "                mlflow.log_artifact(dist_path)\n",
    "                cleanup_files.append(dist_path)\n",
    "\n",
    "    # --- 5. CLEANUP ---\n",
    "#    finally:\n",
    "#        for f in cleanup_files:\n",
    "#            if os.path.exists(f):\n",
    "#                os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a7c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Part 1: Baseline Training ---\n",
      "Target 'Churn' encoded. Positive class ('Yes') is 1.\n",
      "MLflow Run ID: da7ff7eedbc9485fa1f7a25cbaf06021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/11/09 21:46:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 0.7963\n",
      "Baseline Model ROC AUC: 0.8369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'telco-baseline' already exists. Creating a new version of this model...\n",
      "2025/11/09 21:46:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: telco-baseline, version 30\n",
      "Created version '30' of model 'telco-baseline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualization to confusion_matrix_baseline.png\n",
      "Logged model pipeline, parameters, metrics, visualizations, and data artifacts.\n",
      "üèÉ View run Baseline-Model-Setup at: http://localhost:5000/#/experiments/1/runs/da7ff7eedbc9485fa1f7a25cbaf06021\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "\n",
      "--- Running Part 1: Evaluation for: covariate drift ---\n",
      "Loading assets from setup run: da7ff7eedbc9485fa1f7a25cbaf06021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [04:08<?, ?it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.48it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.70it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging simulation run: 0cebdcce8fca479b8db390b748d8a699\n",
      "Baseline model accuracy on covariate data: 0.7786\n",
      "Saved visualization to confusion_matrix_covariate.png\n",
      "Saved visualization to drift_distribution_tenure_covariate.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:73: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_original[feature_name], label='Original Test Data', color='blue', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:74: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_drifted[feature_name], label='Drifted Test Data', color='red', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:73: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_original[feature_name], label='Original Test Data', color='blue', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:74: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_drifted[feature_name], label='Drifted Test Data', color='red', shade=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualization to drift_distribution_MonthlyCharges_covariate.png\n",
      "üèÉ View run Sim-Evaluate-covariate-drift at: http://localhost:5000/#/experiments/1/runs/0cebdcce8fca479b8db390b748d8a699\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "\n",
      "--- Running Part 1: Evaluation for: concept drift ---\n",
      "Loading assets from setup run: da7ff7eedbc9485fa1f7a25cbaf06021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [04:07<?, ?it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.52it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging simulation run: 2c564d5c16ac4139b75b1ccf59226c63\n",
      "Baseline model accuracy on concept data: 0.6870\n",
      "Saved visualization to confusion_matrix_concept.png\n",
      "üèÉ View run Sim-Evaluate-concept-drift at: http://localhost:5000/#/experiments/1/runs/2c564d5c16ac4139b75b1ccf59226c63\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Users/ldmag/Documents/GitHub/Code-Assignments-Projects/Projects/MLOps Drift Detection and Pipeline Optimization/data/Telco-Churn.csv'\n",
    "run_id = run_baseline_training(file_path)\n",
    "\n",
    "run_drift_evaluation(run_id, 'covariate')\n",
    "run_drift_evaluation(run_id, 'concept')\n",
    "#run_drift_evaluation(run_id, 'combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4848c23e",
   "metadata": {},
   "source": [
    "# Monitoring and retraining for drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e444ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers for this approach\n",
    "\n",
    "def calculate_psi(expected, actual, bins=10):\n",
    "    \"\"\"\n",
    "    Calculate Population Stability Index (PSI) between two distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    expected : array-like\n",
    "        Reference distribution (e.g., training data)\n",
    "    actual : array-like\n",
    "        Current distribution (e.g., test data)\n",
    "    bins : int\n",
    "        Number of bins for discretization\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : PSI value\n",
    "        - PSI < 0.1: No significant drift\n",
    "        - 0.1 <= PSI < 0.25: Moderate drift\n",
    "        - PSI >= 0.25: Significant drift\n",
    "    \"\"\"\n",
    "    def psi_calc(e_perc, a_perc):\n",
    "        if a_perc == 0:\n",
    "            a_perc = 0.0001\n",
    "        if e_perc == 0:\n",
    "            e_perc = 0.0001\n",
    "        return (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "    \n",
    "    # Create breakpoints\n",
    "    breakpoints = np.linspace(\n",
    "        min(expected.min(), actual.min()),\n",
    "        max(expected.max(), actual.max()),\n",
    "        bins + 1\n",
    "    )\n",
    "    \n",
    "    # Calculate percentages in each bin\n",
    "    expected_percents = np.histogram(expected, breakpoints)[0] / len(expected)\n",
    "    actual_percents = np.histogram(actual, breakpoints)[0] / len(actual)\n",
    "    \n",
    "    # Calculate PSI\n",
    "    psi = sum([psi_calc(e, a) for e, a in zip(expected_percents, actual_percents)])\n",
    "    \n",
    "    return psi\n",
    "\n",
    "def calculate_all_psi_scores(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Calculate PSI for all features (numerical and categorical).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Feature name -> PSI score mapping\n",
    "    \"\"\"\n",
    "    psi_scores = {}\n",
    "    \n",
    "    # Numerical features\n",
    "    numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "    for feature in numerical_features:\n",
    "        if feature in X_train.columns:\n",
    "            psi = calculate_psi(X_train[feature].values, X_test[feature].values)\n",
    "            psi_scores[feature] = psi\n",
    "    \n",
    "    # Categorical features\n",
    "    categorical_features = [\n",
    "        'gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "        'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "        'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
    "        'PaperlessBilling', 'PaymentMethod', 'SeniorCitizen'\n",
    "    ]\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        if feature in X_train.columns:\n",
    "            psi = calculate_psi_categorical(X_train[feature], X_test[feature])\n",
    "            psi_scores[feature] = psi\n",
    "    \n",
    "    return psi_scores\n",
    "\n",
    "def adversarial_validation_score(X_train, X_test, preprocessor=None, n_estimators=100, max_depth=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Train an adversarial classifier to distinguish train from test data.\n",
    "    Returns the AUC score as a drift metric.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training data features\n",
    "    X_test : pd.DataFrame\n",
    "        Test data features\n",
    "    n_estimators : int\n",
    "        Number of trees in random forest\n",
    "    max_depth : int\n",
    "        Maximum depth of trees\n",
    "    random_state : int\n",
    "        Random seed\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : AUC score\n",
    "        - AUC ‚âà 0.5: No drift (can't distinguish train from test)\n",
    "        - AUC ‚Üí 1.0: Significant drift (easy to distinguish)\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    if preprocessor is None:\n",
    "        preprocessor = get_preprocessor(X_train)\n",
    "\n",
    "    X_train_cleaned = preprocessor.fit_transform(X_train)\n",
    "    X_test_cleaned = preprocessor.fit_transform(X_test)\n",
    "\n",
    "    if hasattr(X_train_cleaned, 'toarray'):\n",
    "        X_train_cleaned = X_train_cleaned.toarray()\n",
    "        X_test_cleaned = X_test_cleaned.toarray()\n",
    "    \n",
    "    # Combine data\n",
    "    X_combined = np.vstack([X_train_cleaned, X_test_cleaned])\n",
    "    \n",
    "    # Create labels: 0 = train, 1 = test\n",
    "    y_domain = np.concatenate([\n",
    "        np.zeros(len(X_train_cleaned)),\n",
    "        np.ones(len(X_test_cleaned))\n",
    "    ])\n",
    "    \n",
    "    # Train adversarial classifier\n",
    "    adv_classifier = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    adv_classifier.fit(X_combined, y_domain)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_proba = adv_classifier.predict_proba(X_combined)[:, 1]\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc_score = roc_auc_score(y_domain, y_pred_proba)\n",
    "\n",
    "    # feature name handling\n",
    "    feature_names = get_feature_names(preprocessor, X_train)\n",
    "    feature_imp = dict(zip(feature_names, adv_classifier.feature_importances_))\n",
    "    feature_imp = dict(sorted(feature_imp.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    return auc_score, adv_classifier, feature_imp\n",
    "\n",
    "def get_feature_names(preprocessor, X):\n",
    "    feature_names = []\n",
    "    \n",
    "    for name, transformer, columns in preprocessor.transformers_:\n",
    "        if name == 'num':\n",
    "            # Numerical features keep their names\n",
    "            feature_names.extend(columns)\n",
    "        elif name == 'cat':\n",
    "            # Categorical features get one-hot encoded names\n",
    "            if hasattr(transformer.named_steps['onehot'], 'get_feature_names_out'):\n",
    "                cat_features = transformer.named_steps['onehot'].get_feature_names_out(columns)\n",
    "                feature_names.extend(cat_features)\n",
    "            else:\n",
    "                # Fallback for older sklearn versions\n",
    "                feature_names.extend([f\"{col}_{val}\" for col in columns \n",
    "                                     for val in transformer.named_steps['onehot'].categories_])\n",
    "    \n",
    "    return feature_names\n",
    "\n",
    "def calculate_psi_categorical(expected, actual):\n",
    "    \"\"\"\n",
    "    Calculate PSI for categorical features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    expected : pd.Series or np.array\n",
    "        Reference categorical distribution (training)\n",
    "    actual : pd.Series or np.array\n",
    "        Current categorical distribution (test)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : PSI value\n",
    "    \"\"\"\n",
    "    # Get unique categories from both\n",
    "    all_categories = sorted(set(expected) | set(actual))\n",
    "    \n",
    "    # Calculate proportions\n",
    "    expected_counts = pd.Series(expected).value_counts(normalize=True)\n",
    "    actual_counts = pd.Series(actual).value_counts(normalize=True)\n",
    "    \n",
    "    psi = 0.0\n",
    "    epsilon = 0.0001  # To avoid log(0)\n",
    "    \n",
    "    for category in all_categories:\n",
    "        e_perc = expected_counts.get(category, 0) + epsilon\n",
    "        a_perc = actual_counts.get(category, 0) + epsilon\n",
    "        \n",
    "        psi += (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "    \n",
    "    return psi\n",
    "\n",
    "def estimate_density_ratio_adversarial(X_train, X_test, preprocessor=None, n_estimators=100, max_depth=3):\n",
    "    \"\"\"\n",
    "    Estimate density ratios using adversarial validation approach.\n",
    "    More stable than direct density estimation methods.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training data features\n",
    "    X_test : pd.DataFrame\n",
    "        Test data features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array : Density ratios for training samples\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "    # Combine data\n",
    "    #X_combined = pd.concat([X_train, X_test], axis=0)\n",
    "    if preprocessor is None:\n",
    "        preprocessor = get_preprocessor(X_train)\n",
    "\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.fit_transform(X_test)\n",
    "\n",
    "    if hasattr(X_train_transformed, 'toarray'):\n",
    "        X_train_transformed = X_train_transformed.toarray()\n",
    "    if hasattr(X_test_transformed, 'toarray'):\n",
    "        X_test_transformed = X_test_transformed.toarray()\n",
    "\n",
    "    X_combined = np.vstack([X_train_transformed, X_test_transformed])\n",
    "\n",
    "    y_domain = np.concatenate([\n",
    "        np.zeros(len(X_train_transformed)),\n",
    "        np.ones(len(X_test_transformed))\n",
    "    ])\n",
    "    \n",
    "    # Train discriminator\n",
    "    discriminator = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    discriminator.fit(X_combined, y_domain)\n",
    "    \n",
    "    # Get probabilities for training data\n",
    "    test_proba = discriminator.predict_proba(X_train_transformed)[:, 1]\n",
    "    \n",
    "    # Calculate density ratio: r(x) = P(test|x) / P(train|x)\n",
    "    epsilon = 1e-6  # for numerical stability\n",
    "    density_ratios = (test_proba + epsilon) / (1 - test_proba + epsilon)\n",
    "    \n",
    "    # Clip extreme values to reduce variance\n",
    "    density_ratios = np.clip(density_ratios, 0.3, 3.0)\n",
    "    \n",
    "    return density_ratios\n",
    "\n",
    "def plot_adversarial_auc_over_batches(auc_scores, drift_type, save_path):\n",
    "    \"\"\"\n",
    "    Plot adversarial validation AUC scores over batches/time.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    batches = np.arange(len(auc_scores))\n",
    "    plt.plot(batches, auc_scores, marker='o', linewidth=2, markersize=8, \n",
    "             label=f'{drift_type.capitalize()} Drift AUC', color='red')\n",
    "    \n",
    "    # Add reference line at 0.5 (no drift)\n",
    "    plt.axhline(y=0.5, color='green', linestyle='--', linewidth=2, \n",
    "                label='No Drift (AUC=0.5)')\n",
    "    \n",
    "    # Add threshold lines\n",
    "    plt.axhline(y=0.7, color='orange', linestyle=':', linewidth=1.5, \n",
    "                label='Moderate Drift Threshold (0.7)')\n",
    "    plt.axhline(y=0.8, color='darkred', linestyle=':', linewidth=1.5, \n",
    "                label='Severe Drift Threshold (0.8)')\n",
    "    \n",
    "    plt.xlabel('Batch Index', fontsize=12)\n",
    "    plt.ylabel('Adversarial AUC Score', fontsize=12)\n",
    "    plt.title(f'Adversarial Validation Drift Detection: {drift_type.capitalize()} Drift', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved visualization to {save_path}\")\n",
    "\n",
    "\n",
    "def plot_psi_scores(psi_scores_dict, drift_type, save_path):\n",
    "    \"\"\"\n",
    "    Plot PSI scores for multiple features.\n",
    "    \"\"\"\n",
    "    features = list(psi_scores_dict.keys())\n",
    "    psi_values = list(psi_scores_dict.values())\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = ['green' if psi < 0.1 else 'orange' if psi < 0.25 else 'red' \n",
    "              for psi in psi_values]\n",
    "    \n",
    "    bars = plt.bar(features, psi_values, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Add reference lines\n",
    "    plt.axhline(y=0.1, color='orange', linestyle='--', linewidth=1.5, \n",
    "                label='Moderate Drift (0.1)')\n",
    "    plt.axhline(y=0.25, color='red', linestyle='--', linewidth=1.5, \n",
    "                label='Severe Drift (0.25)')\n",
    "    \n",
    "    plt.xlabel('Features', fontsize=12)\n",
    "    plt.ylabel('PSI Score', fontsize=12)\n",
    "    plt.title(f'Population Stability Index by Feature: {drift_type.capitalize()} Drift', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved visualization to {save_path}\")\n",
    "\n",
    "\n",
    "def plot_model_performance_comparison(baseline_metrics, adapted_metrics, drift_type, save_path):\n",
    "    \"\"\"\n",
    "    Compare baseline vs adapted model performance.\n",
    "    \"\"\"\n",
    "    metrics = ['Accuracy', 'ROC-AUC']\n",
    "    baseline_vals = [baseline_metrics['accuracy'], baseline_metrics['roc_auc']]\n",
    "    adapted_vals = [adapted_metrics['accuracy'], adapted_metrics['roc_auc']]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars1 = ax.bar(x - width/2, baseline_vals, width, label='Baseline Model', \n",
    "                   color='steelblue', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, adapted_vals, width, label='Adapted Model (Reweighted)', \n",
    "                   color='forestgreen', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Metrics', fontsize=12)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title(f'Model Performance Comparison: {drift_type.capitalize()} Drift', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved visualization to {save_path}\")\n",
    "\n",
    "def run_adversarial_drift_experiment(setup_run_id, drift_type='covariate', \n",
    "                                      drift_threshold=0.7, use_reweighting=True, drift_intensity=0.5):\n",
    "    \"\"\"\n",
    "    Complete experimental pipeline for ensemble drift detection with adversarial validation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    setup_run_id : str\n",
    "        MLflow run ID from baseline training\n",
    "    drift_type : str\n",
    "        Type of drift to simulate ('covariate' or 'concept')\n",
    "    drift_threshold : float\n",
    "        Adversarial AUC threshold to trigger reweighting (default: 0.7)\n",
    "    use_reweighting : bool\n",
    "        Whether to apply density ratio reweighting when drift detected\n",
    "    drift_intensity: float\n",
    "        Sets intensity of the drift when calling the simulate_drift function (default: 0.5)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Experiment results including metrics and drift scores\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ADVERSARIAL DRIFT DETECTION EXPERIMENT: {drift_type.upper()} DRIFT\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Setup MLflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"telco-adversarial-drift-detection\")\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    local_download_path = \".\"\n",
    "    cleanup_files = []\n",
    "\n",
    "    #model_pipeline_uri = f\"runs:/{setup_run_id}/model_pipeline\"\n",
    "    #baseline_model = mlflow.sklearn.load_model(model_pipeline_uri)\n",
    "    \n",
    "    try:\n",
    "        print(\"STEP 1: Loading baseline model and data...\")\n",
    "        \n",
    "        model_pipeline_uri = f\"runs:/{setup_run_id}/model_pipeline\"\n",
    "        baseline_model = mlflow.sklearn.load_model(model_pipeline_uri)\n",
    "\n",
    "        preprocessor = baseline_model.named_steps['preprocessor']\n",
    "        \n",
    "        for f in [\"X_train.csv\", \"X_test.csv\", \"y_train.csv\", \"y_test.csv\"]:\n",
    "            client.download_artifacts(setup_run_id, f, local_download_path)\n",
    "            cleanup_files.append(f)\n",
    "        \n",
    "        X_train_original = pd.read_csv(\"X_train.csv\")\n",
    "        y_train_original = pd.read_csv(\"y_train.csv\").squeeze()\n",
    "        X_test_original = pd.read_csv(\"X_test.csv\")\n",
    "        y_test_original = pd.read_csv(\"y_test.csv\").squeeze()\n",
    "        \n",
    "        test_data_original = X_test_original.copy()\n",
    "        test_data_original['Churn'] = y_test_original\n",
    "        \n",
    "        print(f\"Loaded {len(X_train_original)} training samples\")\n",
    "        print(f\"Loaded {len(X_test_original)} test samples\\n\")\n",
    "        \n",
    "        print(f\"STEP 2: Simulating {drift_type} drift...\")\n",
    "        \n",
    "        if drift_type == 'covariate':\n",
    "            drifted_test_data = simulate_drift(\n",
    "                test_data_original, \n",
    "                drift_type='covariate',\n",
    "                drift_fraction=0.4, \n",
    "                intensity=drift_intensity, \n",
    "                random_state=42\n",
    "            )\n",
    "        elif drift_type == 'concept':\n",
    "            drifted_test_data = simulate_drift(\n",
    "                test_data_original, \n",
    "                drift_type='concept',\n",
    "                drift_fraction=0.4, \n",
    "                intensity=drift_intensity, \n",
    "                thresholds={\"tenure\": 12, \"MonthlyCharges\": 75},\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"drift_type must be 'covariate' or 'concept'\")\n",
    "        \n",
    "        X_test_drifted = drifted_test_data.drop('Churn', axis=1)\n",
    "        y_test_drifted = drifted_test_data['Churn']\n",
    "        \n",
    "        print(f\"Applied {drift_type} drift to test data\\n\")\n",
    "        \n",
    "        print(\"STEP 3: Running adversarial validation...\")\n",
    "        \n",
    "        # Get preprocessor from baseline model\n",
    "        preprocessor = baseline_model.named_steps['preprocessor']\n",
    "\n",
    "        print(\"Running validation on features\")\n",
    "\n",
    "        adv_auc, adv_classifier, feature_importances = adversarial_validation_score(\n",
    "            X_train_original,\n",
    "            X_test_drifted,\n",
    "            preprocessor=preprocessor\n",
    "        )\n",
    "\n",
    "        #print(\"Drifted feature importances:\")\n",
    "        #for i, (feature, importance) in enumerate(list(feature_importances.items())[:5]):\n",
    "        #    print(f\"  {i+1}. {feature}: {importance:.4f}\")\n",
    "        \n",
    "        # Transform data for adversarial validation (use numerical features only)\n",
    "        #numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "        #X_train_num = X_train_original[numerical_features]\n",
    "        #X_test_drifted_num = X_test_drifted[numerical_features]\n",
    "        \n",
    "        # Calculate adversarial AUC\n",
    "        #adv_auc, adv_classifier = adversarial_validation_score(\n",
    "        #    X_train_num, \n",
    "        #    X_test_drifted_num,\n",
    "        #    preprocessor=preprocessor\n",
    "        #)\n",
    "        \n",
    "        print(f\"Adversarial AUC Score: {adv_auc:.4f}\")\n",
    "        \n",
    "        if adv_auc < 0.6:\n",
    "            drift_severity = \"MINIMAL\"\n",
    "        elif adv_auc < 0.7:\n",
    "            drift_severity = \"MODERATE\"\n",
    "        elif adv_auc < 0.8:\n",
    "            drift_severity = \"SIGNIFICANT\"\n",
    "        else:\n",
    "            drift_severity = \"SEVERE\"\n",
    "        \n",
    "        print(f\"  ‚Üí Drift Severity: {drift_severity}\\n\")\n",
    "\n",
    "        print(\"STEP 4: Calculating PSI scores per feature...\")\n",
    "        \n",
    "        psi_scores = calculate_all_psi_scores(X_train_original, X_test_drifted)\n",
    "        #for feature in numerical_features:\n",
    "        #    psi = calculate_psi(\n",
    "        #        X_train_original[feature].values,\n",
    "        #        X_test_drifted[feature].values\n",
    "        #    )\n",
    "        #    psi_scores[feature] = psi\n",
    "        #    print(f\"  {feature}: PSI = {psi:.4f}\")\n",
    "        \n",
    "        avg_psi = np.mean(list(psi_scores.values()))\n",
    "        print(f\"Average PSI: {avg_psi:.4f}\\n\")\n",
    "\n",
    "        print(\"STEP 5: Evaluating baseline model on drifted data...\")\n",
    "        \n",
    "        y_pred_baseline = baseline_model.predict(X_test_drifted)\n",
    "        y_pred_proba_baseline = baseline_model.predict_proba(X_test_drifted)[:, 1]\n",
    "        \n",
    "        baseline_metrics = {\n",
    "            'accuracy': accuracy_score(y_test_drifted, y_pred_baseline),\n",
    "            'roc_auc': roc_auc_score(y_test_drifted, y_pred_proba_baseline)\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úì Baseline Accuracy: {baseline_metrics['accuracy']:.4f}\")\n",
    "        print(f\"‚úì Baseline ROC-AUC: {baseline_metrics['roc_auc']:.4f}\\n\")\n",
    "\n",
    "        adapted_metrics = None\n",
    "        density_ratios = None\n",
    "        \n",
    "        if use_reweighting and adv_auc >= drift_threshold:\n",
    "            print(f\"STEP 6: Drift detected (AUC={adv_auc:.4f} >= {drift_threshold})!\")\n",
    "            print(\"         Applying density ratio reweighting...\\n\")\n",
    "            \n",
    "            # Estimate density ratios\n",
    "            density_ratios = estimate_density_ratio_adversarial(\n",
    "                X_train_original, \n",
    "                X_test_drifted,\n",
    "                preprocessor=preprocessor\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úì Density ratios computed\")\n",
    "            print(f\"  ‚Üí Mean weight: {density_ratios.mean():.3f}\")\n",
    "            print(f\"  ‚Üí Std weight: {density_ratios.std():.3f}\")\n",
    "            print(f\"  ‚Üí Min/Max weight: {density_ratios.min():.3f} / {density_ratios.max():.3f}\\n\")\n",
    "            \n",
    "            # Retrain with importance weighting\n",
    "            #from sklearn.linear_model import LogisticRegression\n",
    "            from sklearn.base import clone\n",
    "\n",
    "            base_classifier = baseline_model.named_steps['classifier']\n",
    "            adapted_classifier = clone(base_classifier)\n",
    "            \n",
    "            X_train_transformed = preprocessor.transform(X_train_original)\n",
    "\n",
    "            adapted_classifier.fit(X_train_transformed, y_train_original, sample_weight=density_ratios)\n",
    "            #adapted_model = LogisticRegression(\n",
    "            #    penalty='elasticnet',\n",
    "            #    solver='saga',\n",
    "            #    l1_ratio=0.5,\n",
    "            #    random_state=42,\n",
    "            #    max_iter=1000\n",
    "            #)\n",
    "            \n",
    "            # Create new pipeline with adapted model\n",
    "            adapted_pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', adapted_classifier)\n",
    "            ])\n",
    "            \n",
    "            # Fit with sample weights\n",
    "            # Note: We need to pass weights through the pipeline\n",
    "            #X_train_transformed = preprocessor.transform(X_train_original)\n",
    "            #adapted_model.fit(X_train_transformed, y_test_original[:len(X_train_original)], \n",
    "            #                 sample_weight=density_ratios)\n",
    "            \n",
    "            # Evaluate adapted model\n",
    "            y_pred_adapted = adapted_pipeline.predict(X_test_drifted)\n",
    "            y_pred_proba_adapted = adapted_pipeline.predict_proba(X_test_drifted)[:, 1]\n",
    "            \n",
    "            adapted_metrics = {\n",
    "                'accuracy': accuracy_score(y_test_drifted, y_pred_adapted),\n",
    "                'roc_auc': roc_auc_score(y_test_drifted, y_pred_proba_adapted)\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úì Adapted Model Accuracy: {adapted_metrics['accuracy']:.4f}\")\n",
    "            print(f\"‚úì Adapted Model ROC-AUC: {adapted_metrics['roc_auc']:.4f}\")\n",
    "            \n",
    "            improvement_acc = adapted_metrics['accuracy'] - baseline_metrics['accuracy']\n",
    "            improvement_auc = adapted_metrics['roc_auc'] - baseline_metrics['roc_auc']\n",
    "            \n",
    "            print(f\"\\n{'‚îÄ'*60}\")\n",
    "            print(f\"IMPROVEMENT: Accuracy = {improvement_acc:+.4f}, ROC-AUC = {improvement_auc:+.4f}\")\n",
    "            print(f\"{'‚îÄ'*60}\\n\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"STEP 6: No significant drift detected (AUC={adv_auc:.4f} < {drift_threshold})\")\n",
    "            print(\"         Skipping reweighting.\\n\")\n",
    "\n",
    "        print(\"STEP 7: Logging results to MLflow...\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"Adversarial-Drift-{drift_type}\") as run:\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"drift_type\", drift_type)\n",
    "            mlflow.log_param(\"drift_threshold\", drift_threshold)\n",
    "            mlflow.log_param(\"use_reweighting\", use_reweighting)\n",
    "            mlflow.log_param(\"parent_setup_run_id\", setup_run_id)\n",
    "            \n",
    "            # Log drift metrics\n",
    "            mlflow.log_metric(\"adversarial_auc\", adv_auc)\n",
    "            mlflow.log_metric(\"avg_psi\", avg_psi)\n",
    "            mlflow.log_metric(\"drift_severity_code\", \n",
    "                             {\"MINIMAL\": 0, \"MODERATE\": 1, \"SIGNIFICANT\": 2, \"SEVERE\": 3}[drift_severity])\n",
    "            \n",
    "            for feature, psi in psi_scores.items():\n",
    "                mlflow.log_metric(f\"psi_{feature}\", psi)\n",
    "            \n",
    "            # Log baseline metrics\n",
    "            mlflow.log_metric(\"baseline_accuracy\", baseline_metrics['accuracy'])\n",
    "            mlflow.log_metric(\"baseline_roc_auc\", baseline_metrics['roc_auc'])\n",
    "            \n",
    "            # Log adapted metrics if available\n",
    "            if adapted_metrics:\n",
    "                mlflow.log_metric(\"adapted_accuracy\", adapted_metrics['accuracy'])\n",
    "                mlflow.log_metric(\"adapted_roc_auc\", adapted_metrics['roc_auc'])\n",
    "                mlflow.log_metric(\"accuracy_improvement\", \n",
    "                                 adapted_metrics['accuracy'] - baseline_metrics['accuracy'])\n",
    "                mlflow.log_metric(\"roc_auc_improvement\", \n",
    "                                 adapted_metrics['roc_auc'] - baseline_metrics['roc_auc'])\n",
    "            \n",
    "            # Create and log visualizations\n",
    "            print(\"  Creating visualizations...\")\n",
    "            \n",
    "            # 1. Adversarial AUC plot (single point for now, but structured for batches)\n",
    "            auc_path = f\"adversarial_auc_{drift_type}.png\"\n",
    "            plot_adversarial_auc_over_batches([adv_auc], drift_type, auc_path)\n",
    "            mlflow.log_artifact(auc_path)\n",
    "            cleanup_files.append(auc_path)\n",
    "            \n",
    "            # 2. PSI scores plot\n",
    "            psi_path = f\"psi_scores_{drift_type}.png\"\n",
    "            plot_psi_scores(psi_scores, drift_type, psi_path)\n",
    "            mlflow.log_artifact(psi_path)\n",
    "            cleanup_files.append(psi_path)\n",
    "            \n",
    "            # 3. Performance comparison (if reweighting was applied)\n",
    "            if adapted_metrics:\n",
    "                perf_path = f\"performance_comparison_{drift_type}.png\"\n",
    "                plot_model_performance_comparison(baseline_metrics, adapted_metrics, \n",
    "                                                 drift_type, perf_path)\n",
    "                mlflow.log_artifact(perf_path)\n",
    "                cleanup_files.append(perf_path)\n",
    "            \n",
    "            # 4. Confusion matrices\n",
    "            cm_baseline_path = f\"cm_baseline_{drift_type}.png\"\n",
    "            plot_confusion_matrix(y_test_drifted, y_pred_baseline,\n",
    "                                f\"Baseline Model: {drift_type.capitalize()} Drift\",\n",
    "                                cm_baseline_path)\n",
    "            mlflow.log_artifact(cm_baseline_path)\n",
    "            cleanup_files.append(cm_baseline_path)\n",
    "            \n",
    "            if adapted_metrics:\n",
    "                cm_adapted_path = f\"cm_adapted_{drift_type}.png\"\n",
    "                plot_confusion_matrix(y_test_drifted, y_pred_adapted,\n",
    "                                    f\"Adapted Model: {drift_type.capitalize()} Drift\",\n",
    "                                    cm_adapted_path)\n",
    "                mlflow.log_artifact(cm_adapted_path)\n",
    "                cleanup_files.append(cm_adapted_path)\n",
    "            \n",
    "            # 5. Distribution shift plots (reuse from your notebook)\n",
    "            if drift_type in ['covariate']:\n",
    "                for feature in ['tenure', 'MonthlyCharges']:\n",
    "                    dist_path = f\"drift_distribution_{feature}_{drift_type}.png\"\n",
    "                    plot_drift_distribution(X_test_original, X_test_drifted, \n",
    "                                          feature, dist_path)\n",
    "                    mlflow.log_artifact(dist_path)\n",
    "                    cleanup_files.append(dist_path)\n",
    "            \n",
    "            print(f\"Logged {len(cleanup_files)} artifacts to MLflow\")\n",
    "            print(f\"MLflow Run ID: {run.info.run_id}\\n\")\n",
    "        \n",
    "        print(f\"{'='*80}\")\n",
    "        print(\"EXPERIMENT COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        # Return results\n",
    "        return {\n",
    "            'adversarial_auc': adv_auc,\n",
    "            'drift_severity': drift_severity,\n",
    "            'psi_scores': psi_scores,\n",
    "            'avg_psi': avg_psi,\n",
    "            'baseline_metrics': baseline_metrics,\n",
    "            'adapted_metrics': adapted_metrics,\n",
    "            'density_ratios': density_ratios\n",
    "        }\n",
    "    \n",
    "    finally:\n",
    "        # Cleanup local files\n",
    "        for f in cleanup_files:\n",
    "            if os.path.exists(f):\n",
    "                os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ea56bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ADVERSARIAL DRIFT DETECTION EXPERIMENT: COVARIATE DRIFT\n",
      "================================================================================\n",
      "\n",
      "STEP 1: Loading baseline model and data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [04:07<?, ?it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.13it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.38it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.92s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5634 training samples\n",
      "Loaded 1409 test samples\n",
      "\n",
      "STEP 2: Simulating covariate drift...\n",
      "Applied covariate drift to test data\n",
      "\n",
      "STEP 3: Running adversarial validation...\n",
      "Running validation on features\n",
      "Adversarial AUC Score: 0.9224\n",
      "  ‚Üí Drift Severity: SEVERE\n",
      "\n",
      "STEP 4: Calculating PSI scores per feature...\n",
      "Average PSI: 0.0476\n",
      "\n",
      "STEP 5: Evaluating baseline model on drifted data...\n",
      "‚úì Baseline Accuracy: 0.7757\n",
      "‚úì Baseline ROC-AUC: 0.7902\n",
      "\n",
      "STEP 6: Drift detected (AUC=0.9224 >= 0.7)!\n",
      "         Applying density ratio reweighting...\n",
      "\n",
      "‚úì Density ratios computed\n",
      "  ‚Üí Mean weight: 0.316\n",
      "  ‚Üí Std weight: 0.093\n",
      "  ‚Üí Min/Max weight: 0.300 / 2.785\n",
      "\n",
      "‚úì Adapted Model Accuracy: 0.7743\n",
      "‚úì Adapted Model ROC-AUC: 0.8021\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "IMPROVEMENT: Accuracy = -0.0014, ROC-AUC = +0.0119\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "STEP 7: Logging results to MLflow...\n",
      "  Creating visualizations...\n",
      "Saved visualization to adversarial_auc_covariate.png\n",
      "Saved visualization to psi_scores_covariate.png\n",
      "Saved visualization to performance_comparison_covariate.png\n",
      "Saved visualization to cm_baseline_covariate.png\n",
      "Saved visualization to cm_adapted_covariate.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:73: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_original[feature_name], label='Original Test Data', color='blue', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:74: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_drifted[feature_name], label='Drifted Test Data', color='red', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:73: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_original[feature_name], label='Original Test Data', color='blue', shade=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualization to drift_distribution_tenure_covariate.png\n",
      "Saved visualization to drift_distribution_MonthlyCharges_covariate.png\n",
      "Logged 11 artifacts to MLflow\n",
      "MLflow Run ID: 212683cd5a3848f18348a86315010d9c\n",
      "\n",
      "üèÉ View run Adversarial-Drift-covariate at: http://localhost:5000/#/experiments/3/runs/212683cd5a3848f18348a86315010d9c\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "================================================================================\n",
      "EXPERIMENT COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:74: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_drifted[feature_name], label='Drifted Test Data', color='red', shade=True)\n"
     ]
    }
   ],
   "source": [
    "#file_path = 'C:/Users/ldmag/Documents/GitHub/Code-Assignments-Projects/Projects/MLOps Drift Detection and Pipeline Optimization/data/Telco-Churn.csv'\n",
    "#run_id = run_baseline_training(file_path)\n",
    "\n",
    "results = run_adversarial_drift_experiment(setup_run_id=run_id, drift_type='covariate', drift_threshold=0.7, use_reweighting=True, drift_intensity=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "256eb425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ADVERSARIAL DRIFT DETECTION EXPERIMENT: COVARIATE DRIFT\n",
      "================================================================================\n",
      "\n",
      "STEP 1: Loading baseline model and data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [04:06<?, ?it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.46it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.19it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5634 training samples\n",
      "Loaded 1409 test samples\n",
      "\n",
      "STEP 2: Simulating covariate drift...\n",
      "Applied covariate drift to test data\n",
      "\n",
      "STEP 3: Running adversarial validation...\n",
      "Running validation on features\n",
      "Adversarial AUC Score: 0.8408\n",
      "  ‚Üí Drift Severity: SEVERE\n",
      "\n",
      "STEP 4: Calculating PSI scores per feature...\n",
      "Average PSI: 0.0283\n",
      "\n",
      "STEP 5: Evaluating baseline model on drifted data...\n",
      "‚úì Baseline Accuracy: 0.7864\n",
      "‚úì Baseline ROC-AUC: 0.7986\n",
      "\n",
      "STEP 6: Drift detected (AUC=0.8408 >= 0.7)!\n",
      "         Applying density ratio reweighting...\n",
      "\n",
      "‚úì Density ratios computed\n",
      "  ‚Üí Mean weight: 0.316\n",
      "  ‚Üí Std weight: 0.087\n",
      "  ‚Üí Min/Max weight: 0.300 / 2.530\n",
      "\n",
      "‚úì Adapted Model Accuracy: 0.7878\n",
      "‚úì Adapted Model ROC-AUC: 0.8142\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "IMPROVEMENT: Accuracy = +0.0014, ROC-AUC = +0.0156\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "STEP 7: Logging results to MLflow...\n",
      "  Creating visualizations...\n",
      "Saved visualization to adversarial_auc_covariate.png\n",
      "Saved visualization to psi_scores_covariate.png\n",
      "Saved visualization to performance_comparison_covariate.png\n",
      "Saved visualization to cm_baseline_covariate.png\n",
      "Saved visualization to cm_adapted_covariate.png\n",
      "Saved visualization to drift_distribution_tenure_covariate.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:73: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_original[feature_name], label='Original Test Data', color='blue', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:74: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_drifted[feature_name], label='Drifted Test Data', color='red', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:73: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_original[feature_name], label='Original Test Data', color='blue', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:74: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_drifted[feature_name], label='Drifted Test Data', color='red', shade=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualization to drift_distribution_MonthlyCharges_covariate.png\n",
      "Logged 11 artifacts to MLflow\n",
      "MLflow Run ID: 4adf16604e674ce99247cd7a86298b67\n",
      "\n",
      "üèÉ View run Adversarial-Drift-covariate at: http://localhost:5000/#/experiments/3/runs/4adf16604e674ce99247cd7a86298b67\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "================================================================================\n",
      "EXPERIMENT COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = run_adversarial_drift_experiment(setup_run_id=run_id, drift_type='covariate', drift_threshold=0.7, use_reweighting=True, drift_intensity=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d88f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ADVERSARIAL DRIFT DETECTION EXPERIMENT: COVARIATE DRIFT\n",
      "================================================================================\n",
      "\n",
      "STEP 1: Loading baseline model and data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [04:06<?, ?it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.62it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.56it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.43s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5634 training samples\n",
      "Loaded 1409 test samples\n",
      "\n",
      "STEP 2: Simulating covariate drift...\n",
      "Applied covariate drift to test data\n",
      "\n",
      "STEP 3: Running adversarial validation...\n",
      "Running validation on features\n",
      "Adversarial AUC Score: 0.8733\n",
      "  ‚Üí Drift Severity: SEVERE\n",
      "\n",
      "STEP 4: Calculating PSI scores per feature...\n",
      "Average PSI: 0.0355\n",
      "\n",
      "STEP 5: Evaluating baseline model on drifted data...\n",
      "‚úì Baseline Accuracy: 0.7842\n",
      "‚úì Baseline ROC-AUC: 0.7947\n",
      "\n",
      "STEP 6: Drift detected (AUC=0.8733 >= 0.7)!\n",
      "         Applying density ratio reweighting...\n",
      "\n",
      "‚úì Density ratios computed\n",
      "  ‚Üí Mean weight: 0.316\n",
      "  ‚Üí Std weight: 0.077\n",
      "  ‚Üí Min/Max weight: 0.300 / 1.714\n",
      "\n",
      "‚úì Adapted Model Accuracy: 0.7793\n",
      "‚úì Adapted Model ROC-AUC: 0.8155\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "IMPROVEMENT: Accuracy = -0.0050, ROC-AUC = +0.0208\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "STEP 7: Logging results to MLflow...\n",
      "  Creating visualizations...\n",
      "Saved visualization to adversarial_auc_covariate.png\n",
      "Saved visualization to psi_scores_covariate.png\n",
      "Saved visualization to performance_comparison_covariate.png\n",
      "Saved visualization to cm_baseline_covariate.png\n",
      "Saved visualization to cm_adapted_covariate.png\n",
      "Saved visualization to drift_distribution_tenure_covariate.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:73: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_original[feature_name], label='Original Test Data', color='blue', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:74: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_drifted[feature_name], label='Drifted Test Data', color='red', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:73: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_original[feature_name], label='Original Test Data', color='blue', shade=True)\n",
      "C:\\Users\\ldmag\\AppData\\Local\\Temp\\ipykernel_33296\\553103997.py:74: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(df_drifted[feature_name], label='Drifted Test Data', color='red', shade=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualization to drift_distribution_MonthlyCharges_covariate.png\n",
      "Logged 11 artifacts to MLflow\n",
      "MLflow Run ID: cb45078bcb064cefa9e142543c49f20b\n",
      "\n",
      "üèÉ View run Adversarial-Drift-covariate at: http://localhost:5000/#/experiments/3/runs/cb45078bcb064cefa9e142543c49f20b\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/3\n",
      "================================================================================\n",
      "EXPERIMENT COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = run_adversarial_drift_experiment(setup_run_id=run_id, drift_type='covariate', drift_threshold=0.7, use_reweighting=True, drift_intensity=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec6fdf",
   "metadata": {},
   "source": [
    "## Comparing across intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebc5e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_intensity_drift_experiment(setup_run_id, drift_type='covariate'):\n",
    "    \"\"\"\n",
    "    Run drift detection and adaptation experiments across multiple drift intensities.\n",
    "    \n",
    "    This creates a comprehensive evaluation showing:\n",
    "    1. How drift severity affects detection (adversarial AUC, PSI)\n",
    "    2. How baseline model degrades with increasing drift\n",
    "    3. Whether adaptation effectiveness scales with drift intensity\n",
    "    4. The bias-variance tradeoff of importance weighting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    setup_run_id : str\n",
    "        MLflow run ID from baseline training\n",
    "    drift_type : str\n",
    "        'covariate' or 'concept'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Results across all intensities\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MULTI-INTENSITY DRIFT EXPERIMENT: {drift_type.upper()} DRIFT\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Define intensity levels to test\n",
    "    intensities = [0.0, 0.2, 0.3, 0.5, 0.7, 0.9]\n",
    "    drift_fractions = [0.0, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "    \n",
    "    # Results storage\n",
    "    results = []\n",
    "    \n",
    "    # Setup MLflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"telco-multi-intensity-drift\")\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    local_download_path = \".\"\n",
    "    \n",
    "    # Load baseline assets once\n",
    "    print(\"Loading baseline model and data...\")\n",
    "    model_pipeline_uri = f\"runs:/{setup_run_id}/model_pipeline\"\n",
    "    baseline_model = mlflow.sklearn.load_model(model_pipeline_uri)\n",
    "    preprocessor = baseline_model.named_steps['preprocessor']\n",
    "    \n",
    "    for f in [\"X_train.csv\", \"y_train.csv\", \"X_test.csv\", \"y_test.csv\"]:\n",
    "        client.download_artifacts(setup_run_id, f, local_download_path)\n",
    "    \n",
    "    X_train_original = pd.read_csv(\"X_train.csv\")\n",
    "    y_train_original = pd.read_csv(\"y_train.csv\").squeeze()\n",
    "    X_test_original = pd.read_csv(\"X_test.csv\")\n",
    "    y_test_original = pd.read_csv(\"y_test.csv\").squeeze()\n",
    "    \n",
    "    test_data_original = X_test_original.copy()\n",
    "    test_data_original['Churn'] = y_test_original\n",
    "    \n",
    "    print(f\"‚úì Loaded {len(X_train_original)} training samples\")\n",
    "    print(f\"‚úì Loaded {len(X_test_original)} test samples\\n\")\n",
    "    \n",
    "    # Test each intensity level\n",
    "    for intensity, drift_fraction in zip(intensities, drift_fractions):\n",
    "        print(f\"\\n{'‚îÄ'*80}\")\n",
    "        print(f\"Testing Intensity: {intensity:.1f}, Drift Fraction: {drift_fraction:.1f}\")\n",
    "        print(f\"{'‚îÄ'*80}\\n\")\n",
    "        \n",
    "        # Simulate drift\n",
    "        if intensity == 0.0:\n",
    "            # No drift scenario\n",
    "            X_test_drifted = X_test_original.copy()\n",
    "            y_test_drifted = y_test_original.copy()\n",
    "        else:\n",
    "            if drift_type == 'covariate':\n",
    "                drifted_test_data = simulate_drift(\n",
    "                    test_data_original,\n",
    "                    drift_type='covariate',\n",
    "                    drift_fraction=drift_fraction,\n",
    "                    intensity=intensity,\n",
    "                    random_state=42\n",
    "                )\n",
    "            else:  # concept drift\n",
    "                drifted_test_data = simulate_drift(\n",
    "                    test_data_original,\n",
    "                    drift_type='concept',\n",
    "                    drift_fraction=drift_fraction,\n",
    "                    intensity=intensity,\n",
    "                    thresholds={\"tenure\": 12, \"MonthlyCharges\": 75},\n",
    "                    random_state=42\n",
    "                )\n",
    "            \n",
    "            X_test_drifted = drifted_test_data.drop('Churn', axis=1)\n",
    "            y_test_drifted = drifted_test_data['Churn']\n",
    "        \n",
    "        # Adversarial validation for drift detection\n",
    "        adv_auc, adv_classifier, feature_importances = adversarial_validation_score(\n",
    "            X_train_original,\n",
    "            X_test_drifted,\n",
    "            preprocessor=preprocessor\n",
    "        )\n",
    "        \n",
    "        # Calculate PSI\n",
    "        numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "        psi_scores = {}\n",
    "        for feature in numerical_features:\n",
    "            psi = calculate_psi(\n",
    "                X_train_original[feature].values,\n",
    "                X_test_drifted[feature].values\n",
    "            )\n",
    "            psi_scores[feature] = psi\n",
    "        avg_psi = np.mean(list(psi_scores.values()))\n",
    "        \n",
    "        # Evaluate baseline model\n",
    "        y_pred_baseline = baseline_model.predict(X_test_drifted)\n",
    "        y_pred_proba_baseline = baseline_model.predict_proba(X_test_drifted)[:, 1]\n",
    "        \n",
    "        baseline_acc = accuracy_score(y_test_drifted, y_pred_baseline)\n",
    "        baseline_auc = roc_auc_score(y_test_drifted, y_pred_proba_baseline)\n",
    "        \n",
    "        # Adaptation (only if drift detected)\n",
    "        adapted_acc = None\n",
    "        adapted_auc = None\n",
    "        ess_ratio = None\n",
    "        weight_cv = None\n",
    "        \n",
    "        if adv_auc >= 0.6:  # Threshold for attempting adaptation\n",
    "            try:\n",
    "                # Estimate density ratios\n",
    "                density_ratios = estimate_density_ratio_adversarial(\n",
    "                    X_train_original,\n",
    "                    X_test_drifted,\n",
    "                    preprocessor=preprocessor\n",
    "                )\n",
    "                \n",
    "                # Calculate weight diagnostics\n",
    "                mean_w = density_ratios.mean()\n",
    "                std_w = density_ratios.std()\n",
    "                weight_cv = std_w / mean_w\n",
    "                ess = (density_ratios.sum() ** 2) / (density_ratios ** 2).sum()\n",
    "                ess_ratio = ess / len(density_ratios)\n",
    "                \n",
    "                # Retrain with weights\n",
    "                from sklearn.base import clone\n",
    "                base_classifier = baseline_model.named_steps['classifier']\n",
    "                adapted_classifier = clone(base_classifier)\n",
    "                \n",
    "                X_train_transformed = preprocessor.transform(X_train_original)\n",
    "                adapted_classifier.fit(\n",
    "                    X_train_transformed,\n",
    "                    y_train_original,\n",
    "                    sample_weight=density_ratios\n",
    "                )\n",
    "                \n",
    "                adapted_pipeline = Pipeline(steps=[\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('classifier', adapted_classifier)\n",
    "                ])\n",
    "                \n",
    "                # Evaluate adapted model\n",
    "                y_pred_adapted = adapted_pipeline.predict(X_test_drifted)\n",
    "                y_pred_proba_adapted = adapted_pipeline.predict_proba(X_test_drifted)[:, 1]\n",
    "                \n",
    "                adapted_acc = accuracy_score(y_test_drifted, y_pred_adapted)\n",
    "                adapted_auc = roc_auc_score(y_test_drifted, y_pred_proba_adapted)\n",
    "                \n",
    "                print(f\"‚úì Adaptation completed (ESS ratio: {ess_ratio:.2%}, CV: {weight_cv:.2f})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† Adaptation failed: {str(e)}\")\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'intensity': intensity,\n",
    "            'drift_fraction': drift_fraction,\n",
    "            'adversarial_auc': adv_auc,\n",
    "            'avg_psi': avg_psi,\n",
    "            'baseline_accuracy': baseline_acc,\n",
    "            'baseline_roc_auc': baseline_auc,\n",
    "            'adapted_accuracy': adapted_acc,\n",
    "            'adapted_roc_auc': adapted_auc,\n",
    "            'accuracy_improvement': (adapted_acc - baseline_acc) if adapted_acc else 0,\n",
    "            'roc_auc_improvement': (adapted_auc - baseline_auc) if adapted_auc else 0,\n",
    "            'ess_ratio': ess_ratio,\n",
    "            'weight_cv': weight_cv\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nResults for intensity {intensity:.1f}:\")\n",
    "        print(f\"  Adversarial AUC: {adv_auc:.4f}\")\n",
    "        print(f\"  Average PSI: {avg_psi:.4f}\")\n",
    "        print(f\"  Baseline ROC-AUC: {baseline_auc:.4f}\")\n",
    "        if adapted_auc:\n",
    "            print(f\"  Adapted ROC-AUC: {adapted_auc:.4f}\")\n",
    "            print(f\"  Improvement: {adapted_auc - baseline_auc:+.4f}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Log comprehensive results to MLflow\n",
    "    with mlflow.start_run(run_name=f\"Multi-Intensity-{drift_type}\"):\n",
    "        mlflow.log_param(\"drift_type\", drift_type)\n",
    "        mlflow.log_param(\"num_intensities\", len(intensities))\n",
    "        \n",
    "        # Log summary table\n",
    "        results_df.to_csv(\"multi_intensity_results.csv\", index=False)\n",
    "        mlflow.log_artifact(\"multi_intensity_results.csv\")\n",
    "        \n",
    "        # Create comprehensive visualizations\n",
    "        create_multi_intensity_visualizations(results_df, drift_type)\n",
    "    \n",
    "    # Cleanup\n",
    "    for f in [\"X_train.csv\", \"y_train.csv\", \"X_test.csv\", \"y_test.csv\", \n",
    "              \"multi_intensity_results.csv\"]:\n",
    "        if os.path.exists(f):\n",
    "            os.remove(f)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"MULTI-INTENSITY EXPERIMENT COMPLETED!\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def create_multi_intensity_visualizations(results_df, drift_type):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations for multi-intensity experiment.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Detection Metrics vs Intensity\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(results_df['intensity'], results_df['adversarial_auc'], \n",
    "             marker='o', linewidth=2, markersize=8, label='Adversarial AUC', color='red')\n",
    "    ax1.plot(results_df['intensity'], results_df['avg_psi'], \n",
    "             marker='s', linewidth=2, markersize=8, label='Average PSI', color='orange')\n",
    "    ax1.axhline(y=0.7, color='gray', linestyle='--', alpha=0.5, label='Detection Threshold')\n",
    "    ax1.set_xlabel('Drift Intensity', fontsize=12)\n",
    "    ax1.set_ylabel('Detection Metric Value', fontsize=12)\n",
    "    ax1.set_title('Drift Detection Metrics vs Intensity', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Model Performance Degradation\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(results_df['intensity'], results_df['baseline_roc_auc'], \n",
    "             marker='o', linewidth=2, markersize=8, label='Baseline Model', color='steelblue')\n",
    "    ax2.plot(results_df['intensity'], results_df['adapted_roc_auc'], \n",
    "             marker='^', linewidth=2, markersize=8, label='Adapted Model', color='forestgreen')\n",
    "    ax2.set_xlabel('Drift Intensity', fontsize=12)\n",
    "    ax2.set_ylabel('ROC-AUC Score', fontsize=12)\n",
    "    ax2.set_title('Model Performance vs Drift Intensity', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Improvement from Adaptation\n",
    "    ax3 = axes[1, 0]\n",
    "    colors = ['green' if x > 0 else 'red' for x in results_df['roc_auc_improvement']]\n",
    "    ax3.bar(results_df['intensity'], results_df['roc_auc_improvement'], \n",
    "            color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax3.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax3.set_xlabel('Drift Intensity', fontsize=12)\n",
    "    ax3.set_ylabel('ROC-AUC Improvement', fontsize=12)\n",
    "    ax3.set_title('Adaptation Benefit vs Drift Intensity', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 4: Weight Quality Metrics\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4_twin = ax4.twinx()\n",
    "    \n",
    "    # Filter out None values\n",
    "    valid_data = results_df[results_df['ess_ratio'].notna()]\n",
    "    \n",
    "    ax4.plot(valid_data['intensity'], valid_data['ess_ratio'], \n",
    "             marker='o', linewidth=2, markersize=8, label='ESS Ratio', color='purple')\n",
    "    ax4_twin.plot(valid_data['intensity'], valid_data['weight_cv'], \n",
    "                  marker='s', linewidth=2, markersize=8, label='Weight CV', color='darkorange')\n",
    "    \n",
    "    ax4.set_xlabel('Drift Intensity', fontsize=12)\n",
    "    ax4.set_ylabel('Effective Sample Size Ratio', fontsize=12, color='purple')\n",
    "    ax4_twin.set_ylabel('Coefficient of Variation', fontsize=12, color='darkorange')\n",
    "    ax4.set_title('Weight Quality vs Drift Intensity', fontsize=14, fontweight='bold')\n",
    "    ax4.tick_params(axis='y', labelcolor='purple')\n",
    "    ax4_twin.tick_params(axis='y', labelcolor='darkorange')\n",
    "    \n",
    "    # Combine legends\n",
    "    lines1, labels1 = ax4.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax4_twin.get_legend_handles_labels()\n",
    "    ax4.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"multi_intensity_analysis_{drift_type}.png\", dpi=300)\n",
    "    mlflow.log_artifact(f\"multi_intensity_analysis_{drift_type}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"‚úì Saved multi-intensity visualization\")\n",
    "    \n",
    "    # Cleanup\n",
    "    if os.path.exists(f\"multi_intensity_analysis_{drift_type}.png\"):\n",
    "        os.remove(f\"multi_intensity_analysis_{drift_type}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bad8f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/09 22:15:42 INFO mlflow.tracking.fluent: Experiment with name 'telco-multi-intensity-drift' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MULTI-INTENSITY DRIFT EXPERIMENT: COVARIATE DRIFT\n",
      "================================================================================\n",
      "\n",
      "Loading baseline model and data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [04:06<?, ?it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.65it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.36s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.63it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 5634 training samples\n",
      "‚úì Loaded 1409 test samples\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Testing Intensity: 0.0, Drift Fraction: 0.0\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úì Adaptation completed (ESS ratio: 99.22%, CV: 0.09)\n",
      "\n",
      "Results for intensity 0.0:\n",
      "  Adversarial AUC: 0.7382\n",
      "  Average PSI: 0.0106\n",
      "  Baseline ROC-AUC: 0.8303\n",
      "  Adapted ROC-AUC: 0.8376\n",
      "  Improvement: +0.0072\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Testing Intensity: 0.2, Drift Fraction: 0.2\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úì Adaptation completed (ESS ratio: 94.51%, CV: 0.24)\n",
      "\n",
      "Results for intensity 0.2:\n",
      "  Adversarial AUC: 0.8218\n",
      "  Average PSI: 0.0303\n",
      "  Baseline ROC-AUC: 0.8162\n",
      "  Adapted ROC-AUC: 0.8231\n",
      "  Improvement: +0.0069\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Testing Intensity: 0.3, Drift Fraction: 0.3\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úì Adaptation completed (ESS ratio: 92.30%, CV: 0.29)\n",
      "\n",
      "Results for intensity 0.3:\n",
      "  Adversarial AUC: 0.8338\n",
      "  Average PSI: 0.0591\n",
      "  Baseline ROC-AUC: 0.8114\n",
      "  Adapted ROC-AUC: 0.8198\n",
      "  Improvement: +0.0084\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Testing Intensity: 0.5, Drift Fraction: 0.4\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úì Adaptation completed (ESS ratio: 94.34%, CV: 0.25)\n",
      "\n",
      "Results for intensity 0.5:\n",
      "  Adversarial AUC: 0.8733\n",
      "  Average PSI: 0.1142\n",
      "  Baseline ROC-AUC: 0.7947\n",
      "  Adapted ROC-AUC: 0.8155\n",
      "  Improvement: +0.0208\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Testing Intensity: 0.7, Drift Fraction: 0.5\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úì Adaptation completed (ESS ratio: 86.85%, CV: 0.39)\n",
      "\n",
      "Results for intensity 0.7:\n",
      "  Adversarial AUC: 0.9086\n",
      "  Average PSI: 0.2186\n",
      "  Baseline ROC-AUC: 0.7896\n",
      "  Adapted ROC-AUC: 0.8083\n",
      "  Improvement: +0.0187\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Testing Intensity: 0.9, Drift Fraction: 0.6\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úì Adaptation completed (ESS ratio: 83.10%, CV: 0.45)\n",
      "\n",
      "Results for intensity 0.9:\n",
      "  Adversarial AUC: 0.9405\n",
      "  Average PSI: 0.3969\n",
      "  Baseline ROC-AUC: 0.7814\n",
      "  Adapted ROC-AUC: 0.7914\n",
      "  Improvement: +0.0101\n",
      "‚úì Saved multi-intensity visualization\n",
      "üèÉ View run Multi-Intensity-covariate at: http://localhost:5000/#/experiments/4/runs/69a96ce2adf54f95aa9d9cecdb426419\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/4\n",
      "\n",
      "================================================================================\n",
      "MULTI-INTENSITY EXPERIMENT COMPLETED!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = run_multi_intensity_drift_experiment(\n",
    "    setup_run_id=run_id,\n",
    "    drift_type='covariate'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2535984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_doubly_robust_weights(X_train, y_train, X_test, preprocessor=None,\n",
    "                                    n_estimators=100, max_depth=3, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Estimate doubly robust importance weights for covariate shift adaptation.\n",
    "    \n",
    "    Combines:\n",
    "    1. Density ratio estimation (via adversarial validation)\n",
    "    2. Outcome model estimation (via cross-validation)\n",
    "    3. Bias correction term\n",
    "    \n",
    "    This provides robustness to misspecification in either the density ratio\n",
    "    or outcome model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training features\n",
    "    y_train : pd.Series or np.array\n",
    "        Training labels\n",
    "    X_test : pd.DataFrame\n",
    "        Test features (drifted)\n",
    "    preprocessor : ColumnTransformer\n",
    "        Feature preprocessor\n",
    "    n_estimators : int\n",
    "        Trees for gradient boosting discriminator\n",
    "    max_depth : int\n",
    "        Max depth for discriminator\n",
    "    cv_folds : int\n",
    "        Cross-validation folds for outcome model\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    np.array : Doubly robust importance weights\n",
    "    dict : Diagnostic information\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    from sklearn.base import clone\n",
    "    \n",
    "    print(\"  ‚Üí Estimating doubly robust importance weights...\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 1: Preprocess data\n",
    "    # =========================================================================\n",
    "    if 'customerID' in X_train.columns:\n",
    "        X_train = X_train.drop(columns=['customerID'])\n",
    "    if 'customerID' in X_test.columns:\n",
    "        X_test = X_test.drop(columns=['customerID'])\n",
    "    \n",
    "    if preprocessor is None:\n",
    "        preprocessor = get_preprocessor(X_train)\n",
    "    \n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Convert sparse to dense\n",
    "    if hasattr(X_train_transformed, 'toarray'):\n",
    "        X_train_transformed = X_train_transformed.toarray()\n",
    "    if hasattr(X_test_transformed, 'toarray'):\n",
    "        X_test_transformed = X_test_transformed.toarray()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 2: Estimate density ratios (propensity model)\n",
    "    # =========================================================================\n",
    "    print(\"  ‚Üí Step 1/3: Estimating density ratios...\")\n",
    "    \n",
    "    # Combine data for adversarial validation\n",
    "    X_combined = np.vstack([X_train_transformed, X_test_transformed])\n",
    "    y_domain = np.concatenate([\n",
    "        np.zeros(len(X_train_transformed)),\n",
    "        np.ones(len(X_test_transformed))\n",
    "    ])\n",
    "    \n",
    "    # Train discriminator\n",
    "    discriminator = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        subsample=0.8\n",
    "    )\n",
    "    discriminator.fit(X_combined, y_domain)\n",
    "    \n",
    "    # Estimate density ratios for training data\n",
    "    test_proba = discriminator.predict_proba(X_train_transformed)[:, 1]\n",
    "    epsilon = 1e-6\n",
    "    density_ratios = (test_proba + epsilon) / (1 - test_proba + epsilon)\n",
    "    density_ratios = np.clip(density_ratios, 0.1, 10)\n",
    "    \n",
    "    print(f\"     ‚úì Density ratios: mean={density_ratios.mean():.3f}, \"\n",
    "          f\"std={density_ratios.std():.3f}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 3: Estimate outcome model via cross-validation\n",
    "    # =========================================================================\n",
    "    print(\"  ‚Üí Step 2/3: Estimating outcome model (CV)...\")\n",
    "    \n",
    "    # Use same classifier type as baseline for outcome model\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    outcome_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "    \n",
    "    # Get out-of-fold predictions (unbiased estimates)\n",
    "    y_pred_cv = cross_val_predict(\n",
    "        outcome_model,\n",
    "        X_train_transformed,\n",
    "        y_train,\n",
    "        cv=cv_folds,\n",
    "        method='predict_proba',\n",
    "        n_jobs=-1\n",
    "    )[:, 1]  # Probability of positive class\n",
    "    \n",
    "    print(f\"     ‚úì CV predictions: mean={y_pred_cv.mean():.3f}, \"\n",
    "          f\"std={y_pred_cv.std():.3f}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 4: Compute doubly robust weights\n",
    "    # =========================================================================\n",
    "    print(\"  ‚Üí Step 3/3: Computing doubly robust correction...\")\n",
    "    \n",
    "    # Convert labels to array\n",
    "    y_train_array = np.array(y_train)\n",
    "    \n",
    "    # Compute residuals (prediction errors)\n",
    "    residuals = y_train_array - y_pred_cv\n",
    "    \n",
    "    # Doubly robust weight formula:\n",
    "    # w_DR(x) = w(x) * [1 + (y - ≈∑(x))]\n",
    "    # where w(x) is density ratio, ≈∑(x) is outcome model prediction\n",
    "    \n",
    "    dr_weights = density_ratios * (1 + residuals)\n",
    "    \n",
    "    # Normalize weights to sum to n (standard practice)\n",
    "    dr_weights = dr_weights / dr_weights.sum() * len(dr_weights)\n",
    "    \n",
    "    # Clip extreme values for stability\n",
    "    dr_weights = np.clip(dr_weights, 0.05, 15)\n",
    "    \n",
    "    print(f\"     ‚úì DR weights: mean={dr_weights.mean():.3f}, \"\n",
    "          f\"std={dr_weights.std():.3f}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 5: Calculate diagnostics\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Effective sample size\n",
    "    ess = (dr_weights.sum() ** 2) / (dr_weights ** 2).sum()\n",
    "    ess_ratio = ess / len(dr_weights)\n",
    "    \n",
    "    # Weight statistics\n",
    "    weight_cv = dr_weights.std() / dr_weights.mean()\n",
    "    \n",
    "    # Prediction quality (outcome model)\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    outcome_auc = roc_auc_score(y_train_array, y_pred_cv)\n",
    "    \n",
    "    diagnostics = {\n",
    "        'density_ratios_mean': density_ratios.mean(),\n",
    "        'density_ratios_std': density_ratios.std(),\n",
    "        'dr_weights_mean': dr_weights.mean(),\n",
    "        'dr_weights_std': dr_weights.std(),\n",
    "        'ess': ess,\n",
    "        'ess_ratio': ess_ratio,\n",
    "        'weight_cv': weight_cv,\n",
    "        'outcome_model_auc': outcome_auc,\n",
    "        'avg_residual': np.abs(residuals).mean()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n Diagnostics:\")\n",
    "    print(f\"     ‚Ä¢ ESS Ratio: {ess_ratio:.2%}\")\n",
    "    print(f\"     ‚Ä¢ Weight CV: {weight_cv:.3f}\")\n",
    "    print(f\"     ‚Ä¢ Outcome Model AUC: {outcome_auc:.4f}\")\n",
    "    print(f\"     ‚Ä¢ Avg Absolute Residual: {diagnostics['avg_residual']:.4f}\")\n",
    "    \n",
    "    return dr_weights, diagnostics\n",
    "\n",
    "\n",
    "def run_doubly_robust_experiment(setup_run_id, drift_type='covariate',\n",
    "                                   drift_threshold=0.7, compare_methods=True):\n",
    "    \"\"\"\n",
    "    Run experiment comparing standard importance weighting vs doubly robust.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    setup_run_id : str\n",
    "        MLflow run ID from baseline training\n",
    "    drift_type : str\n",
    "        'covariate' or 'concept'\n",
    "    drift_threshold : float\n",
    "        Adversarial AUC threshold for triggering adaptation\n",
    "    compare_methods : bool\n",
    "        If True, compares standard IW vs DR-IW\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Results comparing both methods\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DOUBLY ROBUST IMPORTANCE WEIGHTING EXPERIMENT: {drift_type.upper()} DRIFT\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Setup MLflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"telco-doubly-robust-drift\")\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    local_download_path = \".\"\n",
    "    cleanup_files = []\n",
    "    \n",
    "    try:\n",
    "        # =====================================================================\n",
    "        # STEP 1: Load Baseline Assets\n",
    "        # =====================================================================\n",
    "        print(\"STEP 1: Loading baseline model and data...\")\n",
    "        \n",
    "        model_pipeline_uri = f\"runs:/{setup_run_id}/model_pipeline\"\n",
    "        baseline_model = mlflow.sklearn.load_model(model_pipeline_uri)\n",
    "        preprocessor = baseline_model.named_steps['preprocessor']\n",
    "        \n",
    "        for f in [\"X_train.csv\", \"y_train.csv\", \"X_test.csv\", \"y_test.csv\"]:\n",
    "            client.download_artifacts(setup_run_id, f, local_download_path)\n",
    "            cleanup_files.append(f)\n",
    "        \n",
    "        X_train_original = pd.read_csv(\"X_train.csv\")\n",
    "        y_train_original = pd.read_csv(\"y_train.csv\").squeeze()\n",
    "        X_test_original = pd.read_csv(\"X_test.csv\")\n",
    "        y_test_original = pd.read_csv(\"y_test.csv\").squeeze()\n",
    "        \n",
    "        if 'customerID' in X_train_original.columns:\n",
    "            X_train_original = X_train_original.drop(columns=['customerID'])\n",
    "        if 'customerID' in X_test_original.columns:\n",
    "            X_test_original = X_test_original.drop(columns=['customerID'])\n",
    "        \n",
    "        test_data_original = X_test_original.copy()\n",
    "        test_data_original['Churn'] = y_test_original\n",
    "        \n",
    "        print(f\"‚úì Loaded {len(X_train_original)} training samples\")\n",
    "        print(f\"‚úì Loaded {len(X_test_original)} test samples\\n\")\n",
    "        \n",
    "        # =====================================================================\n",
    "        # STEP 2: Simulate Drift\n",
    "        # =====================================================================\n",
    "        print(f\"STEP 2: Simulating {drift_type} drift...\")\n",
    "        \n",
    "        if drift_type == 'covariate':\n",
    "            drifted_test_data = simulate_drift(\n",
    "                test_data_original,\n",
    "                drift_type='covariate',\n",
    "                drift_fraction=0.4,\n",
    "                intensity=0.5,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            drifted_test_data = simulate_drift(\n",
    "                test_data_original,\n",
    "                drift_type='concept',\n",
    "                drift_fraction=0.4,\n",
    "                intensity=0.5,\n",
    "                thresholds={\"tenure\": 12, \"MonthlyCharges\": 75},\n",
    "                random_state=42\n",
    "            )\n",
    "        \n",
    "        X_test_drifted = drifted_test_data.drop('Churn', axis=1)\n",
    "        y_test_drifted = drifted_test_data['Churn']\n",
    "        \n",
    "        print(f\"‚úì Applied {drift_type} drift to test data\\n\")\n",
    "        \n",
    "        # =====================================================================\n",
    "        # STEP 3: Drift Detection\n",
    "        # =====================================================================\n",
    "        print(\"STEP 3: Running drift detection...\")\n",
    "        \n",
    "        adv_auc, adv_classifier, feature_importances = adversarial_validation_score(\n",
    "            X_train_original,\n",
    "            X_test_drifted,\n",
    "            preprocessor=preprocessor\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Adversarial AUC: {adv_auc:.4f}\\n\")\n",
    "        \n",
    "        # =====================================================================\n",
    "        # STEP 4: Baseline Evaluation\n",
    "        # =====================================================================\n",
    "        print(\"STEP 4: Evaluating baseline model...\")\n",
    "        \n",
    "        y_pred_baseline = baseline_model.predict(X_test_drifted)\n",
    "        y_pred_proba_baseline = baseline_model.predict_proba(X_test_drifted)[:, 1]\n",
    "        \n",
    "        baseline_metrics = {\n",
    "            'accuracy': accuracy_score(y_test_drifted, y_pred_baseline),\n",
    "            'roc_auc': roc_auc_score(y_test_drifted, y_pred_proba_baseline)\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úì Baseline ROC-AUC: {baseline_metrics['roc_auc']:.4f}\\n\")\n",
    "        \n",
    "        # =====================================================================\n",
    "        # STEP 5: Adaptation with Different Methods\n",
    "        # =====================================================================\n",
    "        \n",
    "        results = {\n",
    "            'baseline': baseline_metrics,\n",
    "            'standard_iw': None,\n",
    "            'doubly_robust': None\n",
    "        }\n",
    "        \n",
    "        if adv_auc >= drift_threshold:\n",
    "            print(f\"STEP 5: Drift detected (AUC={adv_auc:.4f})!\")\n",
    "            print(\"         Testing adaptation methods...\\n\")\n",
    "            \n",
    "            # -----------------------------------------------------------------\n",
    "            # Method 1: Standard Importance Weighting\n",
    "            # -----------------------------------------------------------------\n",
    "            if compare_methods:\n",
    "                print(\"  [Method 1/2] Standard Importance Weighting...\")\n",
    "                \n",
    "                density_ratios_std = estimate_density_ratio_adversarial(\n",
    "                    X_train_original,\n",
    "                    X_test_drifted,\n",
    "                    preprocessor=preprocessor\n",
    "                )\n",
    "                \n",
    "                # Train model with standard IW\n",
    "                from sklearn.base import clone\n",
    "                classifier_std = clone(baseline_model.named_steps['classifier'])\n",
    "                X_train_transformed = preprocessor.transform(X_train_original)\n",
    "                \n",
    "                classifier_std.fit(\n",
    "                    X_train_transformed,\n",
    "                    y_train_original,\n",
    "                    sample_weight=density_ratios_std\n",
    "                )\n",
    "                \n",
    "                pipeline_std = Pipeline(steps=[\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('classifier', classifier_std)\n",
    "                ])\n",
    "                \n",
    "                # Evaluate\n",
    "                y_pred_std = pipeline_std.predict(X_test_drifted)\n",
    "                y_pred_proba_std = pipeline_std.predict_proba(X_test_drifted)[:, 1]\n",
    "                \n",
    "                std_iw_metrics = {\n",
    "                    'accuracy': accuracy_score(y_test_drifted, y_pred_std),\n",
    "                    'roc_auc': roc_auc_score(y_test_drifted, y_pred_proba_std),\n",
    "                    'improvement_acc': accuracy_score(y_test_drifted, y_pred_std) - baseline_metrics['accuracy'],\n",
    "                    'improvement_auc': roc_auc_score(y_test_drifted, y_pred_proba_std) - baseline_metrics['roc_auc']\n",
    "                }\n",
    "                \n",
    "                results['standard_iw'] = std_iw_metrics\n",
    "                \n",
    "                print(f\"     ‚úì Standard IW ROC-AUC: {std_iw_metrics['roc_auc']:.4f}\")\n",
    "                print(f\"       Improvement: {std_iw_metrics['improvement_auc']:+.4f}\\n\")\n",
    "            \n",
    "            # -----------------------------------------------------------------\n",
    "            # Method 2: Doubly Robust Importance Weighting\n",
    "            # -----------------------------------------------------------------\n",
    "            print(\"  [Method 2/2] Doubly Robust Importance Weighting...\")\n",
    "            \n",
    "            dr_weights, dr_diagnostics = estimate_doubly_robust_weights(\n",
    "                X_train_original,\n",
    "                y_train_original,\n",
    "                X_test_drifted,\n",
    "                preprocessor=preprocessor\n",
    "            )\n",
    "            \n",
    "            # Train model with DR weights\n",
    "            classifier_dr = clone(baseline_model.named_steps['classifier'])\n",
    "            \n",
    "            classifier_dr.fit(\n",
    "                X_train_transformed,\n",
    "                y_train_original,\n",
    "                sample_weight=dr_weights\n",
    "            )\n",
    "            \n",
    "            pipeline_dr = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', classifier_dr)\n",
    "            ])\n",
    "            \n",
    "            # Evaluate\n",
    "            y_pred_dr = pipeline_dr.predict(X_test_drifted)\n",
    "            y_pred_proba_dr = pipeline_dr.predict_proba(X_test_drifted)[:, 1]\n",
    "            \n",
    "            dr_metrics = {\n",
    "                'accuracy': accuracy_score(y_test_drifted, y_pred_dr),\n",
    "                'roc_auc': roc_auc_score(y_test_drifted, y_pred_proba_dr),\n",
    "                'improvement_acc': accuracy_score(y_test_drifted, y_pred_dr) - baseline_metrics['accuracy'],\n",
    "                'improvement_auc': roc_auc_score(y_test_drifted, y_pred_proba_dr) - baseline_metrics['roc_auc'],\n",
    "                **dr_diagnostics\n",
    "            }\n",
    "            \n",
    "            results['doubly_robust'] = dr_metrics\n",
    "            \n",
    "            print(f\"\\n     ‚úì Doubly Robust ROC-AUC: {dr_metrics['roc_auc']:.4f}\")\n",
    "            print(f\"       Improvement: {dr_metrics['improvement_auc']:+.4f}\\n\")\n",
    "            \n",
    "            # -----------------------------------------------------------------\n",
    "            # Comparison Summary\n",
    "            # -----------------------------------------------------------------\n",
    "            if compare_methods and results['standard_iw']:\n",
    "                print(f\"\\n{'‚îÄ'*60}\")\n",
    "                print(\"COMPARISON SUMMARY\")\n",
    "                print(f\"{'‚îÄ'*60}\")\n",
    "                print(f\"Baseline ROC-AUC:          {baseline_metrics['roc_auc']:.4f}\")\n",
    "                print(f\"Standard IW ROC-AUC:       {std_iw_metrics['roc_auc']:.4f} \"\n",
    "                      f\"({std_iw_metrics['improvement_auc']:+.4f})\")\n",
    "                print(f\"Doubly Robust ROC-AUC:     {dr_metrics['roc_auc']:.4f} \"\n",
    "                      f\"({dr_metrics['improvement_auc']:+.4f})\")\n",
    "                \n",
    "                if dr_metrics['roc_auc'] > std_iw_metrics['roc_auc']:\n",
    "                    advantage = dr_metrics['roc_auc'] - std_iw_metrics['roc_auc']\n",
    "                    print(f\"\\n‚úì Doubly Robust WINS by {advantage:+.4f} AUC points!\")\n",
    "                elif std_iw_metrics['roc_auc'] > dr_metrics['roc_auc']:\n",
    "                    advantage = std_iw_metrics['roc_auc'] - dr_metrics['roc_auc']\n",
    "                    print(f\"\\n‚úì Standard IW WINS by {advantage:+.4f} AUC points!\")\n",
    "                else:\n",
    "                    print(f\"\\n‚âà Methods perform equally\")\n",
    "                print(f\"{'‚îÄ'*60}\\n\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"STEP 5: No drift detected (AUC={adv_auc:.4f} < {drift_threshold})\\n\")\n",
    "        \n",
    "        # =====================================================================\n",
    "        # STEP 6: Log Results to MLflow\n",
    "        # =====================================================================\n",
    "        print(\"STEP 6: Logging results to MLflow...\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"DoublyRobust-{drift_type}\") as run:\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"drift_type\", drift_type)\n",
    "            mlflow.log_param(\"drift_threshold\", drift_threshold)\n",
    "            mlflow.log_param(\"compare_methods\", compare_methods)\n",
    "            \n",
    "            # Log drift metrics\n",
    "            mlflow.log_metric(\"adversarial_auc\", adv_auc)\n",
    "            \n",
    "            # Log baseline\n",
    "            mlflow.log_metric(\"baseline_roc_auc\", baseline_metrics['roc_auc'])\n",
    "            mlflow.log_metric(\"baseline_accuracy\", baseline_metrics['accuracy'])\n",
    "            \n",
    "            # Log standard IW if available\n",
    "            if results['standard_iw']:\n",
    "                mlflow.log_metric(\"std_iw_roc_auc\", results['standard_iw']['roc_auc'])\n",
    "                mlflow.log_metric(\"std_iw_improvement\", results['standard_iw']['improvement_auc'])\n",
    "            \n",
    "            # Log doubly robust\n",
    "            if results['doubly_robust']:\n",
    "                mlflow.log_metric(\"dr_roc_auc\", results['doubly_robust']['roc_auc'])\n",
    "                mlflow.log_metric(\"dr_improvement\", results['doubly_robust']['improvement_auc'])\n",
    "                mlflow.log_metric(\"dr_ess_ratio\", results['doubly_robust']['ess_ratio'])\n",
    "                mlflow.log_metric(\"dr_weight_cv\", results['doubly_robust']['weight_cv'])\n",
    "                mlflow.log_metric(\"outcome_model_auc\", results['doubly_robust']['outcome_model_auc'])\n",
    "            \n",
    "            # Create comparison visualization\n",
    "            if compare_methods and results['standard_iw'] and results['doubly_robust']:\n",
    "                create_method_comparison_plot(results, drift_type)\n",
    "            \n",
    "            print(f\"‚úì MLflow Run ID: {run.info.run_id}\\n\")\n",
    "        \n",
    "        print(f\"{'='*80}\")\n",
    "        print(\"DOUBLY ROBUST EXPERIMENT COMPLETED!\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    finally:\n",
    "        # Cleanup\n",
    "        for f in cleanup_files:\n",
    "            if os.path.exists(f):\n",
    "                os.remove(f)\n",
    "\n",
    "\n",
    "def create_method_comparison_plot(results, drift_type):\n",
    "    \"\"\"\n",
    "    Create visualization comparing Standard IW vs Doubly Robust.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Plot 1: ROC-AUC Comparison\n",
    "    ax1 = axes[0]\n",
    "    methods = ['Baseline', 'Standard IW', 'Doubly Robust']\n",
    "    auc_scores = [\n",
    "        results['baseline']['roc_auc'],\n",
    "        results['standard_iw']['roc_auc'],\n",
    "        results['doubly_robust']['roc_auc']\n",
    "    ]\n",
    "    colors = ['steelblue', 'orange', 'forestgreen']\n",
    "    \n",
    "    bars = ax1.bar(methods, auc_scores, color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax1.set_ylabel('ROC-AUC Score', fontsize=12)\n",
    "    ax1.set_title(f'Performance Comparison: {drift_type.capitalize()} Drift', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Plot 2: Improvement Comparison\n",
    "    ax2 = axes[1]\n",
    "    improvements = [\n",
    "        0,  # Baseline\n",
    "        results['standard_iw']['improvement_auc'],\n",
    "        results['doubly_robust']['improvement_auc']\n",
    "    ]\n",
    "    colors = ['gray' if x == 0 else 'green' if x > 0 else 'red' for x in improvements]\n",
    "    \n",
    "    bars = ax2.bar(methods, improvements, color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax2.set_ylabel('ROC-AUC Improvement', fontsize=12)\n",
    "    ax2.set_title('Improvement Over Baseline', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height != 0:\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:+.4f}', ha='center', \n",
    "                    va='bottom' if height > 0 else 'top', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"method_comparison_{drift_type}.png\", dpi=300)\n",
    "    mlflow.log_artifact(f\"method_comparison_{drift_type}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    if os.path.exists(f\"method_comparison_{drift_type}.png\"):\n",
    "        os.remove(f\"method_comparison_{drift_type}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82c74bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Part 1: Baseline Training ---\n",
      "Target 'Churn' encoded. Positive class ('Yes') is 1.\n",
      "MLflow Run ID: ea43fd86247b46cfa281c0ec738fb22f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\RDS-Project\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/11/10 19:27:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 0.7963\n",
      "Baseline Model ROC AUC: 0.8369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'telco-baseline' already exists. Creating a new version of this model...\n",
      "2025/11/10 19:27:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: telco-baseline, version 32\n",
      "Created version '32' of model 'telco-baseline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualization to confusion_matrix_baseline.png\n",
      "Logged model pipeline, parameters, metrics, visualizations, and data artifacts.\n",
      "üèÉ View run Baseline-Model-Setup at: http://localhost:5000/#/experiments/1/runs/ea43fd86247b46cfa281c0ec738fb22f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "\n",
      "================================================================================\n",
      "DOUBLY ROBUST IMPORTANCE WEIGHTING EXPERIMENT: COVARIATE DRIFT\n",
      "================================================================================\n",
      "\n",
      "STEP 1: Loading baseline model and data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [04:06<?, ?it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.41it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.74it/s]\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 5634 training samples\n",
      "‚úì Loaded 1409 test samples\n",
      "\n",
      "STEP 2: Simulating covariate drift...\n",
      "‚úì Applied covariate drift to test data\n",
      "\n",
      "STEP 3: Running drift detection...\n",
      "‚úì Adversarial AUC: 0.8733\n",
      "\n",
      "STEP 4: Evaluating baseline model...\n",
      "‚úì Baseline ROC-AUC: 0.7947\n",
      "\n",
      "STEP 5: Drift detected (AUC=0.8733)!\n",
      "         Testing adaptation methods...\n",
      "\n",
      "  [Method 1/2] Standard Importance Weighting...\n",
      "     ‚úì Standard IW ROC-AUC: 0.8155\n",
      "       Improvement: +0.0208\n",
      "\n",
      "  [Method 2/2] Doubly Robust Importance Weighting...\n",
      "  ‚Üí Estimating doubly robust importance weights...\n",
      "  ‚Üí Step 1/3: Estimating density ratios...\n",
      "     ‚úì Density ratios: mean=0.177, std=0.095\n",
      "  ‚Üí Step 2/3: Estimating outcome model (CV)...\n",
      "     ‚úì CV predictions: mean=0.269, std=0.241\n",
      "  ‚Üí Step 3/3: Computing doubly robust correction...\n",
      "     ‚úì DR weights: mean=0.997, std=0.674\n",
      "\n",
      " Diagnostics:\n",
      "     ‚Ä¢ ESS Ratio: 68.67%\n",
      "     ‚Ä¢ Weight CV: 0.675\n",
      "     ‚Ä¢ Outcome Model AUC: 0.8421\n",
      "     ‚Ä¢ Avg Absolute Residual: 0.2745\n",
      "\n",
      "     ‚úì Doubly Robust ROC-AUC: 0.7965\n",
      "       Improvement: +0.0018\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "COMPARISON SUMMARY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Baseline ROC-AUC:          0.7947\n",
      "Standard IW ROC-AUC:       0.8155 (+0.0208)\n",
      "Doubly Robust ROC-AUC:     0.7965 (+0.0018)\n",
      "\n",
      "‚úì Standard IW WINS by +0.0189 AUC points!\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "STEP 6: Logging results to MLflow...\n",
      "‚úì MLflow Run ID: 4ef9648ce20744259ea5f47bd493daa5\n",
      "\n",
      "üèÉ View run DoublyRobust-covariate at: http://localhost:5000/#/experiments/5/runs/4ef9648ce20744259ea5f47bd493daa5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/5\n",
      "================================================================================\n",
      "DOUBLY ROBUST EXPERIMENT COMPLETED!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Users/ldmag/Documents/GitHub/Code-Assignments-Projects/Projects/MLOps Drift Detection and Pipeline Optimization/data/Telco-Churn.csv'\n",
    "run_id = run_baseline_training(file_path)\n",
    "\n",
    "# Run doubly robust experiment\n",
    "results = run_doubly_robust_experiment(\n",
    "    setup_run_id=run_id,\n",
    "    drift_type='covariate',\n",
    "    drift_threshold=0.7,\n",
    "    compare_methods=True  # Compare with standard IW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd854ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RDS-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
