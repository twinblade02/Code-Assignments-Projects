{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu8QNsWRb_xp"
      },
      "source": [
        "# Assignment 4: Detecting and Mitigating Bias\n",
        "\n",
        "The goal of this tutorial is to introduce the basic functionality of AI Fairness 360 for detecting and mitigating bias. As before, we will work with the German Credit dataset. There are many metrics one can use to detect the presence of bias. Likewise, there are many different bias mitigation algorithms one can employ. AI Fairness 360 provides some of them most common metrics and algorithms.\n",
        "\n",
        "\n",
        "### Bias mitigation techniques\n",
        "\n",
        "We learnt about the different bias mitigation techniques in class called _pre-processing_, _in-processing_, and _post-processing_.\n",
        "\n",
        "\n",
        "We will use AI Fairness 360 (`aif360`) to detect and mitigate bias. We will look for bias in the creation of a machine learning model that predicts whether an applicant should be given credit based on various features from a typical credit application. The protected attribute will be \"Age\", with \"1\" (older than or equal to 25) and \"0\" (younger than 25) being the values for the _privileged_ and _unprivileged_ groups, respectively.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Install and import packages and modules\n",
        "2. Load dataset, split between train and test, and compute fairness metrics on original training dataset\n",
        "3. Mitigate bias using a pre-processing algorithm (reweighing)\n",
        "4. Mitigate bias using an in-processing algorithm (adversarial debiasing)\n",
        "5. Mitigate bias using a post-processing algorithm (equalized odds post processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note:\n",
        "\n",
        "This assignment was completed on Colab due to local errors with the Python environment."
      ],
      "metadata": {
        "id": "RLojkjyN0FKl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSvZzh_-ntSU"
      },
      "source": [
        "\n",
        "## 1. Import Statements\n",
        "\n",
        "First, we install the necessary packages. Then we import several components from the `aif360` package. We are relying on aif360 for this assignment, so please start early to make sure that the dependencies are resolved and that the pacakges load correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp9fRtsGfR4T",
        "outputId": "2891bc9a-8f4b-40bd-d6b0-3f3aec610f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.12/dist-packages (from numba) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "#!pip install numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ40cQE9fR4T",
        "outputId": "34ae57de-8980-45ee-b7f1-c28d97741539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (3.15.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (0.5.3)\n",
            "Collecting nvidia-cublas-cu12==12.5.3.2 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cublas_cu12-12.5.3.2-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.5.82 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.5.82 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.5.82 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.5.82 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.3.0.75 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.3.61 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cufft_cu12-11.2.3.61-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.6.82 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_curand_cu12-10.3.6.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.3.83 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.3.83-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.1.3 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cusparse_cu12-12.5.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.23.4 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.5.82 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow[and-cuda]) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow[and-cuda]) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow[and-cuda]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow[and-cuda]) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow[and-cuda]) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow[and-cuda]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow[and-cuda]) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.5.3.2-py3-none-manylinux2014_x86_64.whl (363.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.3/363.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (24.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (895 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.7/895.7 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl (577.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.2/577.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.3.61-py3-none-manylinux2014_x86_64.whl (192.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.6.82-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.3.83-py3-none-manylinux2014_x86_64.whl (130.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.1.3-py3-none-manylinux2014_x86_64.whl (217.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.6/217.6 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.8.0+cu126 requires nvidia-cublas-cu12==12.6.4.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-cuda-cupti-cu12==12.6.80; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-cuda-nvrtc-cu12==12.6.77; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-cuda-runtime-cu12==12.6.77; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-cudnn-cu12==9.10.2.21; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-cufft-cu12==11.3.0.4; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-curand-cu12==10.3.7.77; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-cusolver-cu12==11.7.1.2; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-cusparse-cu12==12.5.4.2; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-nccl-cu12==2.27.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.23.4 which is incompatible.\n",
            "torch 2.8.0+cu126 requires nvidia-nvjitlink-cu12==12.6.85; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.5.3.2 nvidia-cuda-cupti-cu12-12.5.82 nvidia-cuda-nvrtc-cu12-12.5.82 nvidia-cuda-runtime-cu12-12.5.82 nvidia-cudnn-cu12-9.3.0.75 nvidia-cufft-cu12-11.2.3.61 nvidia-curand-cu12-10.3.6.82 nvidia-cusolver-cu12-11.6.3.83 nvidia-cusparse-cu12-12.5.1.3 nvidia-nccl-cu12-2.23.4 nvidia-nvjitlink-cu12-12.5.82\n"
          ]
        }
      ],
      "source": [
        "#!pip install tensorflow[and-cuda]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bht1NBktfR4T",
        "outputId": "aebca4be-a03a-41d1-d861-01a836507c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aif360\n",
            "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from aif360) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from aif360) (1.16.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from aif360) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from aif360) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from aif360) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->aif360) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->aif360) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.17.0)\n",
            "Downloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aif360\n",
            "Successfully installed aif360-0.6.1\n"
          ]
        }
      ],
      "source": [
        "# No need to re-install if you already did so in Assignment 2\n",
        "#!pip install aif360"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install aif360[Reductions] aif360[inFairness]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8IuKB8bQgO2t",
        "outputId": "56634821-b9e3-4f8b-be26-51b828131e34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aif360[Reductions] in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from aif360[Reductions]) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from aif360[Reductions]) (1.16.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from aif360[Reductions]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from aif360[Reductions]) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from aif360[Reductions]) (3.10.0)\n",
            "Collecting fairlearn~=0.7 (from aif360[Reductions])\n",
            "  Downloading fairlearn-0.13.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting skorch (from aif360[inFairness])\n",
            "  Downloading skorch-1.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting inFairness>=0.2.2 (from aif360[inFairness])\n",
            "  Downloading inFairness-0.2.3-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: narwhals>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from fairlearn~=0.7->aif360[Reductions]) (2.8.0)\n",
            "Collecting scipy>=1.2.0 (from aif360[Reductions])\n",
            "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting POT>=0.8.0 (from inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading pot-0.9.6.post1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from inFairness>=0.2.2->aif360[inFairness]) (2.8.0+cu126)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360[Reductions]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360[Reductions]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360[Reductions]) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->aif360[Reductions]) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->aif360[Reductions]) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[Reductions]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[Reductions]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[Reductions]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[Reductions]) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[Reductions]) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[Reductions]) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[Reductions]) (3.2.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.12/dist-packages (from skorch->aif360[inFairness]) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from skorch->aif360[inFairness]) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360[Reductions]) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (12.6.77)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.0.3)\n",
            "Downloading fairlearn-0.13.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inFairness-0.2.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading skorch-1.2.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pot-0.9.6.post1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, POT, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, skorch, nvidia-cusolver-cu12, fairlearn, inFairness\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.2\n",
            "    Uninstalling scipy-1.16.2:\n",
            "      Successfully uninstalled scipy-1.16.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed POT-0.9.6.post1 fairlearn-0.13.0 inFairness-0.2.3 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.0.4 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.6.85 scipy-1.15.3 skorch-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia",
                  "scipy"
                ]
              },
              "id": "0ef085d84e254cf692efeca81adf8d89"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJxDwiuVb_xt",
        "outputId": "16b0e5df-4165-4c9b-af43-9460cfde5173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  vect_normalized_discounted_cumulative_gain = vmap(\n",
            "/usr/local/lib/python3.12/dist-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ],
      "source": [
        "# import all necessary packages\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "from numba import jit\n",
        "\n",
        "from aif360.datasets import GermanDataset, BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, DatasetMetric\n",
        "\n",
        "from aif360.algorithms.preprocessing import Reweighing, LFR, DisparateImpactRemover\n",
        "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
        "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
        "\n",
        "from aif360.explainers import MetricTextExplainer, MetricJSONExplainer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import json\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6726903e",
        "outputId": "f2709405-7674-4ebe-fb76-033819518449"
      },
      "source": [
        "# Need to insert a .doc file and the german.data file to use the Dataset class; this is only inserting the content of the doc file.\n",
        "file_path = '/usr/local/lib/python3.12/dist-packages/aif360/data/raw/german/german.doc'\n",
        "file_content = \"\"\"Description of the German credit dataset.\n",
        "\n",
        "1. Title: German Credit data\n",
        "\n",
        "2. Source Information\n",
        "\n",
        "Professor Dr. Hans Hofmann\n",
        "Institut f\"ur Statistik und \"Okonometrie\n",
        "Universit\"at Hamburg\n",
        "FB Wirtschaftswissenschaften\n",
        "Von-Melle-Park 5\n",
        "2000 Hamburg 13\n",
        "\n",
        "3. Number of Instances:  1000\n",
        "\n",
        "Two datasets are provided.  the original dataset, in the form provided\n",
        "by Prof. Hofmann, contains categorical/symbolic attributes and\n",
        "is in the file \"german.data\".\n",
        "\n",
        "For algorithms that need numerical attributes, Strathclyde University\n",
        "produced the file \"german.data-numeric\".  This file has been edited\n",
        "and several indicator variables added to make it suitable for\n",
        "algorithms which cannot cope with categorical variables.   Several\n",
        "attributes that are ordered categorical (such as attribute 17) have\n",
        "been coded as integer.    This was the form used by StatLog.\n",
        "\n",
        "\n",
        "6. Number of Attributes german: 20 (7 numerical, 13 categorical)\n",
        "   Number of Attributes german.numer: 24 (24 numerical)\n",
        "\n",
        "\n",
        "7.  Attribute description for german\n",
        "\n",
        "Attribute 1:  (qualitative)\n",
        "               Status of existing checking account\n",
        "               A11 :      ... <    0 DM\n",
        "               A12 : 0 <= ... <  200 DM\n",
        "               A13 :      ... >= 200 DM /\n",
        "                     salary assignments for at least 1 year\n",
        "               A14 : no checking account\n",
        "\n",
        "Attribute 2:  (numerical)\n",
        "              Duration in month\n",
        "\n",
        "Attribute 3:  (qualitative)\n",
        "              Credit history\n",
        "              A30 : no credits taken/\n",
        "                    all credits paid back duly\n",
        "              A31 : all credits at this bank paid back duly\n",
        "              A32 : existing credits paid back duly till now\n",
        "              A33 : delay in paying off in the past\n",
        "              A34 : critical account/\n",
        "                    other credits existing (not at this bank)\n",
        "\n",
        "Attribute 4:  (qualitative)\n",
        "              Purpose\n",
        "              A40 : car (new)\n",
        "              A41 : car (used)\n",
        "              A42 : furniture/equipment\n",
        "              A43 : radio/television\n",
        "              A44 : domestic appliances\n",
        "              A45 : repairs\n",
        "              A46 : education\n",
        "              A47 : (vacation - does\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to the file\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(file_content)\n",
        "\n",
        "print(f\"Content successfully written to {file_path}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content successfully written to /usr/local/lib/python3.12/dist-packages/aif360/data/raw/german/german.doc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQj5VqOSb_xt"
      },
      "source": [
        "## 2. Load Data, Specify Protected Attribute, and Split Data\n",
        "\n",
        "We will use the German Credit data, set the protected attribute to be age, create two variables to represent the privileged and unprivileged groups, and split the original dataset into training and test data subsets. Finally, we will build a typical machine learning workflow that involves training a machine learning model on the training dataset and use a test dataset to assess the model's efficacy (e.g., accuracy, fairness). For this dataset, we have a binary classification problem that predicts individuals as being a good or a bad credit risk.\n",
        "\n",
        "In this dataset, we consider older applicants (age >= 25) as the privileged group and younger applicants (age < 25) as the unprivileged group.\n",
        "\n",
        "We will use the preprocessed GermanDataset with one-hot encoded data provided by the aif360 package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JYB3PkStb_xv"
      },
      "outputs": [],
      "source": [
        "# note that we drop sex, which may also be a protected attribute\n",
        "dataset_orig = GermanDataset(protected_attribute_names=['age'],\n",
        "                             privileged_classes=[lambda x: x >= 25],\n",
        "                             features_to_drop=['personal_status', 'sex'])\n",
        "\n",
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
        "\n",
        "privileged_groups = [{'age': 1}]\n",
        "unprivileged_groups = [{'age': 0}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsFiFKReb_xw",
        "outputId": "aef4b4ee-cd54-4088-bb1b-c353f53dd73b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data shape:  (1000, 57)\n",
            "Train dataset shape:  (700, 57)\n",
            "Test dataset shape:  (300, 57)\n"
          ]
        }
      ],
      "source": [
        "print(\"Original data shape: \",dataset_orig.features.shape)\n",
        "print(\"Train dataset shape: \", dataset_orig_train.features.shape)\n",
        "print(\"Test dataset shape: \", dataset_orig_test.features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb2XKzDEfR4U"
      },
      "source": [
        "The object ```dataset_orig``` is an aif360 dataset, which has some useful methods and attributes that you can explore. More documentation is available at https://aif360.readthedocs.io/en/latest/modules/datasets.html.\n",
        "For now, we'll just transform the data into a pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W3Aonmt3b_xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6839540-4961-4ff0-c197-701dc93b6d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  (1000, 58)\n"
          ]
        }
      ],
      "source": [
        "df, dict_df = dataset_orig.convert_to_dataframe()\n",
        "print(\"Shape: \", df.shape)\n",
        "# print(df.columns)\n",
        "# df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kITY3AtDb_xz"
      },
      "source": [
        "## 3. Compute Fairness Metrics on Original Training Data\n",
        "Now that we have identified the protected attribute \"age\" and defined privileged and unprivileged values, we can use aif360 to detect bias in the dataset.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZLVzqlmwOXI"
      },
      "source": [
        "### Mean Outcomes\n",
        "\n",
        "Compare the base rates (i.e., percentage of favorable results) for the privileged and unprivileged groups and report the difference (unprivileged base rate - privileged base rate). This is implemented in the ```mean_difference``` method on the BinaryLabelDatasetMetric class, as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVQWXC8Ub_x0",
        "outputId": "1465b4da-6ce2-4ac9-a093-9dde85770d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training dataset\n",
            "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
          ]
        }
      ],
      "source": [
        "metric_orig_train = BinaryLabelDatasetMetric(\n",
        "     dataset_orig_train,\n",
        "     unprivileged_groups=unprivileged_groups,\n",
        "     privileged_groups=privileged_groups\n",
        "  )\n",
        "print(\"Original training dataset\")\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZufOXh9b_x0"
      },
      "source": [
        "### Disparate Impact\n",
        "We can calculate the ratio of (predicted) favorable outcomes for the unprivileged group compared to the privileged group as implemented in the ```disparate_impact``` method on the BinaryLabelDatasetMetric class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iw7g6Hjb_x0",
        "outputId": "0d668418-f7cf-461f-9ceb-a428c6d4e70f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training dataset\n",
            "Disparate Impact = 0.766430\n"
          ]
        }
      ],
      "source": [
        "print(\"Original training dataset\")\n",
        "print(\"Disparate Impact = %f\" % metric_orig_train.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBuA9UHrfR4V"
      },
      "source": [
        "**Note:** The fairness metrics above will vary depending upon the train-test split. If the magnitude of mean difference is less than 10%, try another split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcTiGnSob_x1"
      },
      "source": [
        "### Built-In Explainers\n",
        "\n",
        "```aif360``` has some useful explainers for the fairness metrics which can be used to interpret the fairness metric values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ERMXmj2pb_x1"
      },
      "outputs": [],
      "source": [
        "json_expl = MetricJSONExplainer(metric_orig_train)\n",
        "def format_json(json_str):\n",
        "    return json.dumps(json.loads(json_str, object_pairs_hook=OrderedDict),\n",
        "                      indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWuosH5pxVHe"
      },
      "source": [
        "Let's print the mean difference explainer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc0pIUPxdFl",
        "outputId": "3bd590e2-ddf9-4da0-a75f-a8f45bea58ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"metric\": \"Mean Difference\",\n",
            "  \"message\": \"Mean difference (mean label value on unprivileged instances - mean label value on privileged instances): -0.1699054740619017\",\n",
            "  \"numPositivesUnprivileged\": 63.0,\n",
            "  \"numInstancesUnprivileged\": 113.0,\n",
            "  \"numPositivesPrivileged\": 427.0,\n",
            "  \"numInstancesPrivileged\": 587.0,\n",
            "  \"description\": \"Computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 0.0\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(format_json(json_expl.mean_difference()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl-r2vpjxPFo"
      },
      "source": [
        "We can also print the disparate impact explainer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-FoLzMTxSGS",
        "outputId": "6a8e7d95-8ddd-4e75-f002-bdc3839b38a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"metric\": \"Disparate Impact\",\n",
            "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7664297113013201\",\n",
            "  \"numPositivePredictionsUnprivileged\": 63.0,\n",
            "  \"numUnprivileged\": 113.0,\n",
            "  \"numPositivePredictionsPrivileged\": 427.0,\n",
            "  \"numPrivileged\": 587.0,\n",
            "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(format_json(json_expl.disparate_impact()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcDleSrDJr_B"
      },
      "source": [
        "**Q1:** Using the explainers above, interpret the difference in means and disparate impact in the German Credit data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HV2t23yJ19P"
      },
      "source": [
        "The mean difference between unprivileged and privileged groups is given as `-0.169` which indicates that the unprivileged group receives a favourable outcome about 17% (rounded up) of the time as the privileged group. So this means that there is a disadvantage for the unprivileged group compared to the privileged group in that they receive a favourable outcome a lot less often.\n",
        "\n",
        "The disparate impact between the groups is calculated to be `0.766` - impying a benefit for the privileged group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjx_gX1afR4W"
      },
      "source": [
        "### Build a model on the training data\n",
        "\n",
        "Let's build a logistic regression model on this training data, predict credit risk for test data and compute the same fairness metrics over the model predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KO9sXDSafR4W"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
        "\n",
        "df_test, dict_df_test = dataset_orig_test.convert_to_dataframe()\n",
        "df_train, dict_df_train = dataset_orig_train.convert_to_dataframe()\n",
        "\n",
        "# Fit the model to the training data\n",
        "x_train = df_train.drop(['credit'], axis=1)\n",
        "y_train = df_train['credit']\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "x_test = df_test.drop(['credit'], axis=1)\n",
        "y_test = df_test['credit']\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "dataset_pred_test = dataset_orig_test.copy()\n",
        "dataset_pred_test.labels = y_pred.copy()\n",
        "\n",
        "metric_dataset_test = BinaryLabelDatasetMetric(\n",
        "    dataset_pred_test,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo4K_OQmfR4W",
        "outputId": "72ba45a2-5bb7-4a0c-9511-3422329e6899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = -0.303030\n",
            "Disparate Impact = 0.523810\n"
          ]
        }
      ],
      "source": [
        "# write code here to compute fairness metrics\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_test.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_dataset_test.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOEb_6sSfR4W"
      },
      "source": [
        "**Q2:** Using the fairness metric functions as before, report the bias observed in the model's predictions over test data. What do these values indicate? Are the model's predictions more biased or less biased compared to the bias observed in the training data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vfsUdvWfR4X"
      },
      "source": [
        "The difference in mean outcomes between groups is reported as `-0.303` which tells us that the unprivleged group is at a significant disadvatage - receiving only ~30% of favourable outcomes as often compared to the privileged groups. Furthermore, disparate impact is calculated to be `0.523` which tells us that the privileged group is still favoured. The value is positive, and `< 1` which indicates a bias towards the privileged group.\n",
        "\n",
        "Comparing the two sets and the metrics derived from them:\n",
        "\n",
        "| Set | Mu-Diff | Disparate Impact |\n",
        "| --- | --- | --- |\n",
        "| Original | -0.169 | 0.766 |\n",
        "| Predictions | -0.303 | 0.523 |\n",
        "\n",
        "Generally, if bias mitigation isn't considered prior to training a model on the dataset, we would expect the model to reflect the same biases in its predictions, if not amplify these biases in its predictions. The difference between the original dataset and the predictions are `-0.169 vs. -0.303`, which tells us that there is a larger \"gap\" between both groups, meaning that the bias has gotten worse. Similarly, disparate impact is `0.766 vs. 0.523` - given that the ideal value of `1` which indicates perfect parity, this has also worsened.\n",
        "\n",
        "The predictions are amplifying the bias observed in the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv-XTN2vfR4X"
      },
      "source": [
        "## 4. Bias Mitigation Techniques\n",
        "\n",
        "We learnt in class that there are several bias mitigation techniques namely, pre-processing, in-processing, and post-processing algorithms.\n",
        "\n",
        "_Pre-processing_ bias mitigation is performed at the data end, before the creation of the model. In other words, we transform the data such that a model learned on the transformed data produces less biased decisions.\n",
        "\n",
        "_In-processing_ bias mitigation methods focus on the model training stage, as compared to pre-processing which focuses on transforming the data prior to model training. This suite of methods includes incorporating a fairness constraint during model training, tweaking the model's objective function, and adversarial learning.\n",
        "\n",
        "_Post-processing_ bias mitigation focus on the model predictions after the model has been trained.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQIwiWcKb_x3"
      },
      "source": [
        "### 4.1 Bias Mitigation via Pre-Processing\n",
        "\n",
        "AI Fairness 360 implements several pre-processing mitigation algorithms. We will use the **reweighing algorithm**, which is implemented in the `Reweighing` class in the `aif360.algorithms.preprocessing` package. As discussed in class, this algorithm will transform the dataset by assigning weights to instances in each (group, label) combination to change the base rates and ensure fairness before classification. The idea is to apply appropriate weights to different tuples in the training data to reduce discrimination with respect to the protected attributes.\n",
        "\n",
        "You can find documentation for reweighting here:\n",
        "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.Reweighing.html\n",
        "\n",
        "Call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (```dataset_transf_train```):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CqBmaYXab_x3"
      },
      "outputs": [],
      "source": [
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "dataset_transf_train = RW.fit_transform(dataset_orig_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdkCX8Fd0zgN"
      },
      "source": [
        "We can print the weights. Each observation in the data should have a weight. For brevity, let's look at the weights for the first 10 rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5ISRhOwb_x3",
        "outputId": "d68bdd40-663b-4a9e-8bdd-7540b7a3421d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.678     ])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(dataset_transf_train.instance_weights)\n",
        "dataset_transf_train.instance_weights[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6wrI5Ab_x4"
      },
      "source": [
        "### Compute Fairness Metrics in Transformed Data\n",
        "\n",
        "We can check how effective the transformed data was in removing bias by calculating the metrics used for the original training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "W0IiIE8OfR4X"
      },
      "outputs": [],
      "source": [
        "metric_rw_train = BinaryLabelDatasetMetric(\n",
        "    dataset_transf_train,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFZh_-La6Eq8"
      },
      "source": [
        "Print the difference in mean outcomes and disparate impact in the transformed data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gim6DapUb_x4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115680d4-4a49-408e-e261-88df311e687c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
            "Disparate Impact = 1.000000\n"
          ]
        }
      ],
      "source": [
        "# write your code here\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_rw_train.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_rw_train.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1NdOcvCFmC8"
      },
      "source": [
        "**Q3:** How do these values compare to the difference in mean outcomes and disparate impact in the original data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aG_Glh7Frbc"
      },
      "source": [
        "Reweighing appears balance outcomes between both groups such that there is perfect parity between groups, and equal likelhood of outcomes. The metrics are at their ideal values - indicating no bias and perfect parity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7usWAfbfR4g"
      },
      "source": [
        "### Compute Fairness Metrics on Model Trained on Transformed Data\n",
        "\n",
        "In the following, we will train a model on the transformed data and compute the metrics over predictions made on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbN0uIKBfR4g"
      },
      "source": [
        "**Q4:**  How do you expect the fairness metrics would be over a model trained on the transformed data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvVdAGoyfR4g"
      },
      "source": [
        "I would expect that there would still be some bias and disparity reflected in the model's predictions even after reweighing, though their magnitude of difference over the previous model should have improved significantly after this step (depending on which model is being used)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVVqjII-fR4g"
      },
      "source": [
        "Since the instances now have weights, we will use a classifier that can incorporate instance weights. In this case, we will use a Naive Bayes classifier (more details here: https://scikit-learn.org/stable/modules/naive_bayes.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79HeIP44fR4g",
        "outputId": "b1a589e3-763d-4749-e25e-d9f118e24935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = -0.123737\n",
            "Disparate Impact = 0.810078\n"
          ]
        }
      ],
      "source": [
        "df_train_rw, dict_df_train_rw = dataset_transf_train.convert_to_dataframe()\n",
        "\n",
        "# Fit the model to the transformed training data\n",
        "x_train_rw = df_train_rw.drop(['credit'], axis=1)\n",
        "y_train_rw = df_train_rw['credit']\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(x_train_rw, y_train_rw)\n",
        "\n",
        "# Use the model to make predictions on the test data\n",
        "y_pred_rw = model.predict(x_test)\n",
        "\n",
        "dataset_pred_test_rw = dataset_orig_test.copy()\n",
        "dataset_pred_test_rw.labels = y_pred_rw.copy()\n",
        "\n",
        "# Construct the BinaryLabelDatasetMetric object over the test predictions\n",
        "metric_dataset_test_rw = BinaryLabelDatasetMetric(\n",
        "    dataset_pred_test_rw,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )\n",
        "\n",
        "# Print fairness metrics computed over test predictions\n",
        "# write code here\n",
        "\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_test_rw.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_dataset_test_rw.disparate_impact())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QDl4CmffR4g"
      },
      "source": [
        "**Q5:** Are your observations in line with what you expected in Q4 above? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iE73VvafR4h"
      },
      "source": [
        "Yes. The reported metrics are `-0.123` and `0.810` - there is some bias in the model, but they are much less severe than a model trained from data that was not reweighed during preprocessing; if we note the distance of the reported metrics from their ideal values, this observation much more apparent.\n",
        "\n",
        "This is likley due to Algorithmic bias: where models learn inter-feature relationships and feature-target relationships differently, depending on what is used. Our classifier is probably still picking up some correlations between the unprivileged or protected group and the target/independent variable; or either due to a proxy variable such as neighbourhood or zipcode information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXVCnouPfR4h"
      },
      "source": [
        "**Q6:** Instead of reweighing, one could also apply techniques such as suppression, i.e. removing sensitive attributes. Write code below to train a model that does not use any information on the sensitive attribute, use this model to make predictions over the test data, and then compute the fairness metrics over the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BljdxJzjfR4h",
        "outputId": "91840a8f-8b33-4eab-ba05-e4b98122d80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = -0.140152\n",
            "Disparate Impact = 0.781065\n"
          ]
        }
      ],
      "source": [
        "# write code here to implement suppression\n",
        "# !pip install BlackBoxAuditing\n",
        "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
        "\n",
        "SUPPRESSION = DisparateImpactRemover(repair_level=1.0, sensitive_attribute='age')\n",
        "dataset_transf_train = SUPPRESSION.fit_transform(dataset_orig_train)\n",
        "\n",
        "df_train_supp, dict_df_train_supp = dataset_transf_train.convert_to_dataframe()\n",
        "\n",
        "# Fit the model to the transformed training data\n",
        "x_train_supp = df_train_supp.drop(['credit'], axis=1)\n",
        "y_train_supp = df_train_supp['credit']\n",
        "\n",
        "# use GNB again\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(x_train_supp, y_train_supp)\n",
        "\n",
        "y_pred_supp = model.predict(x_test)\n",
        "\n",
        "dataset_pred_test_supp = dataset_orig_test.copy()\n",
        "dataset_pred_test_supp.labels = y_pred_supp.copy()\n",
        "\n",
        "metric_dataset_test_supp = BinaryLabelDatasetMetric(\n",
        "    dataset_pred_test_supp,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )\n",
        "\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_test_supp.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_dataset_test_supp.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlALDM2NfR4h"
      },
      "source": [
        "**Q7:** Interpret your results. How does the preprocessing technique in Q5 compare to the suppression technique?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysLOwT4NfR4h"
      },
      "source": [
        "From the metrics, it appears that suppression performs slightly worse than the reweighing technique. The disparate impact is slightly lower than reweighing, and similarly, the mean difference is a bit further from the ideal value of 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riLalr-WwDsG"
      },
      "source": [
        "### 4.2. Bias Mitigation via In-Processing\n",
        "\n",
        "In-processing methods focus on the model training stage, as compared to pre-processing which focuses on transforming the data prior to model training. Broadly speaking, contemporary in-processing methods are stronger than pre-processing methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUZKKFAo1R1v"
      },
      "source": [
        "### Adversarial Debiasing\n",
        "\n",
        "In this part of the notebook, we will use an in-processing algorithm, called _Adversarial Debiasing_, that we briefly discussed in class. From the aif360 documentation (https://aif360.readthedocs.io/en/v0.2.3/modules/inprocessing.html):\n",
        "\n",
        "> Adversarial debiasing is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary’s ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit.\n",
        "\n",
        "For intuition, you can think of adversarial debiasing as a model with two supervised learning tasks. The first task is to predict an outcome using the training data input. The second task, i.e. the adversary, is to predict a protected feature using these predictions and non-protected features in the training data input. The aim is to maximize the model's ability to carry out the first task (i.e. predict outcomes) while minimizing its ability to carry out the second task (i.e. predict protected features).\n",
        "\n",
        "We implement adversarial debiasing below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_rWLmHvwBFF",
        "outputId": "4a09a65f-7232-4d74-b0ed-f11f296c89f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.12/dist-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 84.117470; batch adversarial loss: 0.609595\n",
            "epoch 1; iter: 0; batch classifier loss: 60.385742; batch adversarial loss: 0.599298\n",
            "epoch 2; iter: 0; batch classifier loss: 68.519501; batch adversarial loss: 0.537759\n",
            "epoch 3; iter: 0; batch classifier loss: 49.546165; batch adversarial loss: 0.607168\n",
            "epoch 4; iter: 0; batch classifier loss: 44.690742; batch adversarial loss: 0.563261\n",
            "epoch 5; iter: 0; batch classifier loss: 76.991425; batch adversarial loss: 0.638900\n",
            "epoch 6; iter: 0; batch classifier loss: 82.345169; batch adversarial loss: 0.609121\n",
            "epoch 7; iter: 0; batch classifier loss: 35.181107; batch adversarial loss: 0.590382\n",
            "epoch 8; iter: 0; batch classifier loss: 23.353128; batch adversarial loss: 0.546886\n",
            "epoch 9; iter: 0; batch classifier loss: 48.510334; batch adversarial loss: 0.581755\n",
            "epoch 10; iter: 0; batch classifier loss: 40.626083; batch adversarial loss: 0.529961\n",
            "epoch 11; iter: 0; batch classifier loss: 33.520020; batch adversarial loss: 0.559916\n",
            "epoch 12; iter: 0; batch classifier loss: 48.180309; batch adversarial loss: 0.602141\n",
            "epoch 13; iter: 0; batch classifier loss: 36.247437; batch adversarial loss: 0.539764\n",
            "epoch 14; iter: 0; batch classifier loss: 26.766472; batch adversarial loss: 0.504492\n",
            "epoch 15; iter: 0; batch classifier loss: 30.199501; batch adversarial loss: 0.524947\n",
            "epoch 16; iter: 0; batch classifier loss: 43.651089; batch adversarial loss: 0.582869\n",
            "epoch 17; iter: 0; batch classifier loss: 29.688509; batch adversarial loss: 0.561050\n",
            "epoch 18; iter: 0; batch classifier loss: 29.514767; batch adversarial loss: 0.556305\n",
            "epoch 19; iter: 0; batch classifier loss: 45.165211; batch adversarial loss: 0.541402\n",
            "epoch 20; iter: 0; batch classifier loss: 22.177494; batch adversarial loss: 0.563383\n",
            "epoch 21; iter: 0; batch classifier loss: 25.666357; batch adversarial loss: 0.553275\n",
            "epoch 22; iter: 0; batch classifier loss: 24.841637; batch adversarial loss: 0.566568\n",
            "epoch 23; iter: 0; batch classifier loss: 17.044125; batch adversarial loss: 0.538835\n",
            "epoch 24; iter: 0; batch classifier loss: 32.336212; batch adversarial loss: 0.548902\n",
            "epoch 25; iter: 0; batch classifier loss: 16.653711; batch adversarial loss: 0.491344\n",
            "epoch 26; iter: 0; batch classifier loss: 32.915859; batch adversarial loss: 0.565752\n",
            "epoch 27; iter: 0; batch classifier loss: 24.519382; batch adversarial loss: 0.526871\n",
            "epoch 28; iter: 0; batch classifier loss: 22.844732; batch adversarial loss: 0.515229\n",
            "epoch 29; iter: 0; batch classifier loss: 24.987896; batch adversarial loss: 0.521269\n",
            "epoch 30; iter: 0; batch classifier loss: 17.550360; batch adversarial loss: 0.508682\n",
            "epoch 31; iter: 0; batch classifier loss: 15.496883; batch adversarial loss: 0.542538\n",
            "epoch 32; iter: 0; batch classifier loss: 20.180687; batch adversarial loss: 0.510389\n",
            "epoch 33; iter: 0; batch classifier loss: 16.334919; batch adversarial loss: 0.488055\n",
            "epoch 34; iter: 0; batch classifier loss: 17.212784; batch adversarial loss: 0.542969\n",
            "epoch 35; iter: 0; batch classifier loss: 12.537316; batch adversarial loss: 0.582146\n",
            "epoch 36; iter: 0; batch classifier loss: 24.532267; batch adversarial loss: 0.591994\n",
            "epoch 37; iter: 0; batch classifier loss: 22.816303; batch adversarial loss: 0.473594\n",
            "epoch 38; iter: 0; batch classifier loss: 25.509602; batch adversarial loss: 0.477863\n",
            "epoch 39; iter: 0; batch classifier loss: 14.254354; batch adversarial loss: 0.531210\n",
            "epoch 40; iter: 0; batch classifier loss: 32.642250; batch adversarial loss: 0.621663\n",
            "epoch 41; iter: 0; batch classifier loss: 23.414625; batch adversarial loss: 0.590171\n",
            "epoch 42; iter: 0; batch classifier loss: 9.367788; batch adversarial loss: 0.563862\n",
            "epoch 43; iter: 0; batch classifier loss: 16.750656; batch adversarial loss: 0.477817\n",
            "epoch 44; iter: 0; batch classifier loss: 8.520763; batch adversarial loss: 0.560960\n",
            "epoch 45; iter: 0; batch classifier loss: 6.927592; batch adversarial loss: 0.514411\n",
            "epoch 46; iter: 0; batch classifier loss: 9.168922; batch adversarial loss: 0.484712\n",
            "epoch 47; iter: 0; batch classifier loss: 6.260392; batch adversarial loss: 0.556361\n",
            "epoch 48; iter: 0; batch classifier loss: 8.629516; batch adversarial loss: 0.500178\n",
            "epoch 49; iter: 0; batch classifier loss: 5.971168; batch adversarial loss: 0.469753\n"
          ]
        }
      ],
      "source": [
        "# reset tensorflow graph\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "# start tensorflow session\n",
        "sess = tf.compat.v1.Session()\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# create AdversarialDebiasing model\n",
        "debiased_model = AdversarialDebiasing(\n",
        "    privileged_groups = privileged_groups,\n",
        "    unprivileged_groups = unprivileged_groups,\n",
        "    scope_name = 'debiased_classifier',\n",
        "    debias = True,\n",
        "    sess = sess)\n",
        "\n",
        "# fit the model to training data\n",
        "debiased_model.fit(dataset_orig_train)\n",
        "\n",
        "# make predictions on training and test data\n",
        "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
        "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)\n",
        "\n",
        "# metrics\n",
        "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(\n",
        "    dataset_debiasing_test,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )\n",
        "\n",
        "# Close session\n",
        "sess.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWJUD_1-1XOe"
      },
      "source": [
        "### Fairness Metrics under Adversarial Debiasing\n",
        "\n",
        "The adversarial debiasing algorithm has built-in methods for the difference in mean outcomes (called ```.mean_difference()```) and disparate impact (called ```.disparate_impact()```). Print these below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro-8nuS62NZx",
        "outputId": "74d94bd4-ea1d-4f79-dfb0-e38629cb8c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
            "Disparate Impact = 1.000000\n"
          ]
        }
      ],
      "source": [
        "# write your code here\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_dataset_debiasing_test.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIQcc23c7SNA"
      },
      "source": [
        "**Q8:** Interpret the difference in means and disparate impact for the predicted outcomes under adversarial debiasing. How do these compare to the metrics calculated in Q2 and Q5?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3MyIpCk7hnp"
      },
      "source": [
        "Disparate Impact and the difference in mean outcomes are at their ideal values `0, 1`. This indicates that there is little to no bias and perfect parity between the groups.\n",
        "\n",
        "| Approach                 | Mu-Diff | Disparate Impact |\n",
        "|---------------------------|-----------------|------------------|\n",
        "| LR Model       | -0.303       | 0.523        |\n",
        "| Reweighing           | -0.123       | 0.810         |\n",
        "| Adversarial Debiasing | 0        | 1         |\n",
        "\n",
        "It appears that adversarial debiasing is best suited to mitigating bias when compared to a plain model without interventions, and a preprocessing method like reweighing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpY2Vtm3fR4i"
      },
      "source": [
        "### 4.3. Bias Mitigation via Post-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjUeohblfR4i"
      },
      "source": [
        "In this last section, we will use one of the post-processing algorithms in AI Fairness 360 called as **equalized odds postprocessing**, which is implemented in the `EqOddsPostprocessing` class in the `aif360.algorithms.postprocessing` package. This technique solves a linear program to find probabilities with which to change output labels to optimize equalized odds.\n",
        "\n",
        "You can find documentation for reweighting here:\n",
        "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.postprocessing.EqOddsPostprocessing.html\n",
        "\n",
        "Call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (```dataset_post_train```):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yYWIy4jfR4i",
        "outputId": "501bd720-3e9e-4dda-8b9a-55f34ab235d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = -0.002525\n",
            "Disparate Impact = 0.995238\n"
          ]
        }
      ],
      "source": [
        "df_test, dict_df_test = dataset_orig_test.convert_to_dataframe()\n",
        "df_train, dict_df_train = dataset_orig_train.convert_to_dataframe()\n",
        "\n",
        "# Fit the model to the training data and predict for test data\n",
        "x_train = df_train.drop(['credit'], axis=1)\n",
        "y_train = df_train['credit']\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "x_test = df_test.drop(['credit'], axis=1)\n",
        "y_test = df_test['credit']\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# dataset_pred_test -- dataset with predictions stored in labels\n",
        "dataset_pred_test = dataset_orig_test.copy()\n",
        "# Reshape y_pred, EO object errors out if we do it like we did earlier\n",
        "dataset_pred_test.labels = y_pred.reshape(-1, 1).copy()\n",
        "\n",
        "# create Equalized Odds Post processing object\n",
        "eo_post = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "\n",
        "# fit the object to training data\n",
        "eo_post.fit(dataset_orig_test, dataset_pred_test)\n",
        "\n",
        "# make predictions on test data\n",
        "dataset_post_test = eo_post.predict(dataset_pred_test)\n",
        "\n",
        "\n",
        "# construct metrics object\n",
        "metric_dataset_post_test = BinaryLabelDatasetMetric(\n",
        "    dataset_post_test,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")\n",
        "\n",
        "# compute fairnesss metrics\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_post_test.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_dataset_post_test.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI67Im3jfR4i"
      },
      "source": [
        "**Q9:** Interpret the difference in fairness metrics for the predicted outcomes under this post-processing technique. How do these compare to the metrics calculated in Q2, Q5 and Q8?\n",
        "\n",
        "Mean outcomes are given as `-0.002` while disparate impact is `0.995`. These metrics tell us that there is close to no bias and very close perfect parity between the groups. These are close to the ideal values of 0 and 1 respectively, so we know that this method is also quite effective at mitigating bias.\n",
        "\n",
        "Comparing other approaches in the table below:\n",
        "\n",
        "| Approach                 | Mu-Diff | Disparate Impact |\n",
        "|---------------------------|-----------------|------------------|\n",
        "| LR Model       | -0.303       | 0.523         |\n",
        "| Reweighing            | -0.123       | 0.810         |\n",
        "| Adversarial Debiasing | 0        | 1         |\n",
        "| Equalized Odds   | -0.002 | 0.995 |\n",
        "\n",
        "Adversarial debaising and equalized odds are able to mitigate bias more effectively than a regular model trained without bias mitigation or just reweighting. Reweighting is also resonably good, but has a larger mean difference between groups that adversarial debiasing and equalized odds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl5lNOLGfR4i"
      },
      "source": [
        "# Submitting this Assignment Notebook\n",
        "\n",
        "Once complete, please submit your assignment notebook as an attachment under \\\"Assignments > Assignment 4\\\" on Brightspace. You can download a copy of your notebook using ```File > Download .ipynb```. Please ensure you submit the `.ipynb` file (and not a `.py` file).\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "temp-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}